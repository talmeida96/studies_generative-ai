<!DOCTYPE HTML>
<!--
	Editorial by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Introdução a Machine Learning e Redes Neurais</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css"/>
		<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.11.3/font/bootstrap-icons.min.css">
		<script src="https://cdn.jsdelivr.net/npm/swiffy-slider@1.6.0/dist/js/swiffy-slider.min.js" crossorigin="anonymous" defer></script>
		<script src="https://cdn.jsdelivr.net/pyodide/v0.18.1/full/pyodide.js"></script>
		<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/styles/default.min.css">
		<link href="https://cdn.jsdelivr.net/npm/swiffy-slider@1.6.0/dist/css/swiffy-slider.min.css" rel="stylesheet" crossorigin="anonymous">
		<link rel="stylesheet" href="assets/css/monokai-sublime.min.css">

		<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
		<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
	</head>
	</head>
	<style type="text/css">
        body {
            background-image: url("Background.png") !important;
            -webkit-background-size: 100% auto;
            -moz-background-size: 100% auto;
            -o-background-size: 100% auto;
            background-size: 100% auto;
        }
        .background-bottom {
            background-image: url("Background-2.png") !important;
            -webkit-background-size: 100% auto;
            -moz-background-size: 100% auto;
            -o-background-size: 100% auto;
            background-size: 100% auto;
			background-position: bottom;
			background-attachment: fixed, scroll;
  			background-repeat: no-repeat, repeat-y; 
        }
        p.indent {
            text-indent: 30px;
        }

        #sideNav {
			background-image: url("") !important;
            
        }
		.text-justify{
			text-align: justify;
		}
		.text-center{
			text-align: center;
		}
		
		</style>
		
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<div id="main">
						<div class="inner">

							<!-- Header -->
								<header id="header">
									<span class="logo"><strong>AKCIT -</strong> Introdução a <i>Machine Learning</i> e Redes Neurais</span>
									<ul class="icons">
										
										<li><a href="https://www.instagram.com/akcitoficial/" class="icon brands fa-instagram"><span class="label">Instagram</span></a></li>
										<li><a href="https://www.linkedin.com/company/centro-de-compet%C3%AAncia-embrapii-em-tecnologias-imersivas-akcit/" class="icon brands fa-linkedin"><span class="label">Linkedin</span></a></li>
									</ul>
								</header>

								<section>
									<div class="image main" id="capa">
										<img src="images/1. Capa_Introdução a Machine Learning e Redes Neurais.png" alt="">
									</div>
									<div class="image main" id="contracapa">
										<img src="images/2. Informações institucionais e Conselho editorial_Introdução a Machine Learning e Redes Neurais.png" alt="">
									</div>
									<div class="image main" id="folha">
										<img src="images/3. Folha de rosto_Introdução a Machine Learning e Redes Neurais.png" alt="">
									</div>
									<div class="image main" id="folha">
										<img src="images/5. Instituições_Introdução a Machine Learning e Redes Neurais.png" alt="">
									</div>
									</section>
									<section>
									
												<section class="resume-section p-3 p-lg-5 d-flex align-items-center" id="abreviaturas">
													
													
														<div class="w-100">
															<header class="main">
															<h1 class="mb-0">Lista de Abreviaturas e Siglas</h1>
														</header><br>
																<table class="table" >
																	<tbody>
																		<tr>
																			<td>
																				<p>1D</p>
																			</td>
																			<td>
																				<p>1 Dimensão</p>
																			</td>
																		</tr>
																		<tr>
																			<td>
																				<p>2D</p>
																			</td>
																			<td>
																				<p>2 Dimensões</p>
																			</td>
																		</tr>
																		<tr>
																			<td>
																				<p>3D</p>
																			</td>
																			<td>
																				<p>3 Dimensões</p>
																			</td>
																		</tr>
																		<tr>
																			<td>
																				<p>4D</p>
																			</td>
																			<td>
																				<p>4 Dimensões</p>
																			</td>
																		</tr>
																		<tr>
																			<td>
																				<p>AUC</p>
																			</td>
																			<td>
																				<p>Área Sob a Curva</p>
																			</td>
																		</tr>
																		<tr>
																			<td>
																				<p>BPTT<p>
																			</td>
																			<td>
																				<p><i>Backpropagation Through Time</i> - Retropropagação Através do Tempo
																				</p>
																			</td>
																		</tr>
																		<tr>
																			<td>
																				<p>CNN<p>
																			</td>
																			<td>
																				<p><i>Convolutional Neural Network</i> - Rede Neural Convolucional</p>
																			</td>
																		</tr>
																		<tr>
																			<td>
																				<p>CUDA<p>
																			</td>
																			<td>
																				<p><i>Compute Unified Device Architecture</i> - Arquitetura Unificada de Cálculo de Dispositivos</p>
																			</td>
																		</tr>
																		<tr>
																			<td>
																				<p>DBSCAN<p>
																			</td>
																			<td>
																				<p><i>Density-Based Spatial Clustering of Applications with Noise</i> - Agrupamento de Aplicações Baseado em Densidade com Ruído</p>
																			</td>
																		</tr>
																		<tr>
																			<td>
																				<p>DL<p>
																			</td>
																			<td>
																				<p><i>Deep Learning</i> - Aprendizado Profundo</p>
																			</td>
																		</tr>
																		<tr>
																			<td>
																				<p>GANs<p>
																			</td>
																			<td>
																				<p><i>Generative Adversarial Networks</i> - Redes Generativas Adversárias </p>
																			</td>
																		</tr>
																		<tr>
																			<td>
																				<p>GPUs<p>
																			</td>
																			<td>
																				<p><i>Graphics Processing Units</i> - Unidades de Processamento Gráfico</p>
																			</td>
																		</tr>
																		<tr>
																			<td>
																				<p>HOG<p>
																			</td>
																			<td>
																				<p><i>Histograms of Oriented Gradients</i> - Histogramas de Gradientes Orientados</p>
																			</td>
																		</tr>
																		<tr>
																			<td>
																				<p>HSV<p>
																			</td>
																			<td>
																				<p><i>Hue, Saturation and Value</i> - Matiz, Saturação e Valor</p>
																			</td>
																		</tr>
																		<tr>
																			<td>
																				<p>Hz<p>
																			</td>
																			<td>
																				<p>Hertz</p>
																			</td>
																		</tr>
																		<tr>
																			<td>
																				<p>IA<p>
																			</td>
																			<td>
																				<p>Inteligência Artificial</p>
																			</td>
																		</tr>
																		<tr>
																			<td>
																				<p>IID<p>
																			</td>
																			<td>
																				<p><i>Independent and Identically Distributed</i> - Independentes e Identicamente Distribuídos</p>
																			</td>
																		</tr>
																		<tr>
																			<td>
																				<p>kNN<p>
																			</td>
																			<td>
																				<p><i>k-Nearest Neighbors</i> - k-Vizinhos Mais Próximos</p>
																			</td>
																		</tr>
																		<tr>
																			<td>
																				<p>LASSO<p>
																			</td>
																			<td>
																				<p><i>Least Absolute Shrinkage and Selection Operator</i> - Operador de Encolhimento e Seleção Absoluto Mínimo</p>
																			</td>
																		</tr>
																		<tr>
																			<td>
																				<p>LDA<p>
																			</td>
																			<td>
																				<p><i>Linear Discriminant Analysis</i> - Análise Discriminante Linear</p>
																			</td>
																		</tr>
																		<tr>
																			<td>
																				<p>LightGBM<p>
																			</td>
																			<td>
																				<p><i>Light Gradient Boosting Machine</i> </p>
																			</td>
																		</tr>
																		<tr>
																			<td>
																				<p>MAE<p>
																			</td>
																			<td>
																				<p><i>Mean Absolute Error</i> - Erro Médio Absoluto</p>
																			</td>
																		</tr>
																		<tr>
																			<td>
																				<p>MFCC<p>
																			</td>
																			<td>
																				<p><i>Mel-Frequency Cepstral Coefficients</i> - Coeficientes Cepstrais de Frequência Mel</p>
																			</td>
																		</tr>
																		<tr>
																			<td>
																				<p>ML<p>
																			</td>
																			<td>
																				<p><i>Machine Learning</i> - Aprendizado de Máquina</p>
																			</td>
																		</tr>
																		<tr>
																			<td>
																				<p>MLP<p>
																			</td>
																			<td>
																				<p><i>Multi-Layer Perceptron</i> - Perceptron de Múltiplas Camadas</p>
																			</td>
																		</tr>
																		<tr>
																			<td>
																				<p>MSE<p>
																			</td>
																			<td>
																				<p><i>Mean Squared Error</i> - Erro Médio Quadrado</p>
																			</td>
																		</tr>
																		<tr>
																			<td>
																				<p>OCR<p>
																			</td>
																			<td>
																				<p>Reconhecimento Óptico de Caracteres - Reconhecimento Óptico de Caracteres</p>
																			</td>
																		</tr>
																		<tr>
																			<td>
																				<p>PCA<p>
																			</td>
																			<td>
																				<p><i>Principal Component Analysis</i> - Análise de Componentes Principais</p>
																			</td>
																		</tr>
																		<tr>
																			<td>
																				<p>PLN<p>
																			</td>
																			<td>
																				<p>Processamento de Linguagem Natural</p>
																			</td>
																		</tr>
																		<tr>
																			<td>
																				<p>QDA<p>
																			</td>
																			<td>
																				<p><i>Quadratic Discriminant Analysis</i> - Análise Discriminante Quadrática</p>
																			</td>
																		</tr>
																		<tr>
																			<td>
																				<p>RDA<p>
																			</td>
																			<td>
																				<p><i>Regularized Discriminant Analysis</i> - Análise Discriminante Regularizada</p>
																			</td>
																		</tr>
																		<tr>
																			<td>
																				<p>ReLU<p>
																			</td>
																			<td>
																				<p><i>Rectified Linear Unit</i> - Unidade Linear Retificada</p>
																			</td>
																		</tr>
																		<tr>
																			<td>
																				<p>RFE<p>
																			</td>
																			<td>
																				<p><i>Recursive Feature Elimination</i> - Eliminação Recursiva de Atributos</p>
																			</td>
																		</tr>
																		<tr>
																			<td>
																				<p>RGB<p>
																			</td>
																			<td>
																				<p><i>Red, Green and Blue</i> - Vermelho, Verde e Azul</p>
																			</td>
																		</tr>
																		<tr>
																			<td>
																				<p>RMSE<p>
																			</td>
																			<td>
																				<p><i>Root Mean Squared Error</i> - Raiz do Erro Médio Quadrado</p>
																			</td>
																		</tr>
																		<tr>
																			<td>
																				<p>RNAs<p>
																			</td>
																			<td>
																				<p><i>Artificial Neural Networks</i> - Redes Neurais Artificiais</p>
																			</td>
																		</tr>
																		<tr>
																			<td>
																				<p>RNN<p>
																			</td>
																			<td>
																				<p><i>Recurrent Neural Network</i> - Rede Neural Recorrente</p>
																			</td>
																		</tr>
																		<tr>
																			<td>
																				<p>ROC<p>
																			</td>
																			<td>
																				<p><i>Receiver Operating Characteristic</i> - Curva de Característica de Operação do Receptor</p>
																			</td>
																		</tr>
																		<tr>
																			<td>
																				<p>SGBD<p>
																			</td>
																			<td>
																				<p><i>Database Management Systems</i> - Sistemas de Gestão de Bancos de Dados</p>
																			</td>
																		</tr>
																		<tr>
																			<td>
																				<p>SSR<p>
																			</td>
																			<td>
																				<p><i>Sum of Squared Residuals</i> - Soma dos Quadrados dos Resíduos</p>
																			</td>
																		</tr>
																		<tr>
																			<td>
																				<p>SST<p>
																			</td>
																			<td>
																				<p><i>Total Sum of Squares</i> - Soma Total dos Quadrados</p>
																			</td>
																		</tr>
																		<tr>
																			<td>
																				<p>SUV<p>
																			</td>
																			<td>
																				<p><i>Sports Utility Vehicles</i> - Veículos Utilitários Desportivos</p>
																			</td>
																		</tr>
																		<tr>
																			<td>
																				<p>SVM<p>
																			</td>
																			<td>
																				<p><i>Support Vector Machines</i> - Máquinas de Vetores de Suporte</p>
																			</td>
																		</tr>
																		<tr>
																			<td>
																				<p>t-SNE<p>
																			</td>
																			<td>
																				<p><i>t-Distributed Stochastic Neighbor Embedding</i> - Embutimento Estocástico de Vizinhos Distribuídos t
																				</p>
																			</td>
																		</tr>
																		<tr>
																			<td>
																				<p>TF-IDF<p>
																			</td>
																			<td>
																				<p><i>Term Frequency-Inverse Document Frequency</i> - Frequência de Termos-Inversa Frequência de Documentos</p>
																			</td>
																		</tr>
																		<tr>
																			<td>
																				<p>TPUs<p>
																			</td>
																			<td>
																				<p><i>Tensor Processing Units</i> - Unidades de Processamento de Tensor</p>
																			</td>
																		</tr>
																		<tr>
																			<td>
																				<p>XGBoost<p>
																			</td>
																			<td>
																				<p><i>Extreme Gradient Boosting</i></p>
																			</td>
																		</tr>
																	</tbody>
																</table>
													</div>
												</section>
												<section class="resume-section p-3 p-lg-5 d-flex align-items-center" id="figuras_tabelas">
													<div class="w-100">
														<h1 class="mb-0">Lista de Figuras, Quadros e Tabelas</h1>
														
															<table class="table" >
																<tbody>
																	<tr>
																		<td style="border-top: 0px;">
																			<p><a class="nav-link js-scroll-trigger" href="#link-figura-01"><strong>Figura
																						1</strong> - Etapas de construção de um modelo de <i>machine learning</i></a></p>
																		</td>
																	</tr>
																	<tr>
																		<td style="border-top: 0px;">
																			<p><a class="nav-link js-scroll-trigger" href="#link-figura-02"><strong>Figura
																						2</strong> - Aplicações de <i>machine learning</i> em diferentes setores</a></p>
																		</td>
																	</tr>
																	<tr>
																		<td style="border-top: 0px;">
																			<p><a class="nav-link js-scroll-trigger" href="#link-figura-03"><strong>Figura
																						3</strong> - Estreita relação entre inteligência artificial, <i>machine learning</i> e <i>deep learning</i></a></p>
																		</td>
																	</tr>
																	<tr>
																		<td style="border-top: 0px;">
																			<p><a class="nav-link js-scroll-trigger" href="#link-figura-04"><strong>Figura
																						4</strong> - Série temporal com dados normais e uma anomalia em destaque</a></p>
																		</td>
																	</tr>
																	<tr>
																		<td style="border-top: 0px;">
																			<p><a class="nav-link js-scroll-trigger" href="#link-figura-05"><strong>Figura
																						5</strong> - Exemplo de reconhecimento de face</a></p>
																		</td>
																	</tr>
																	<tr>
																		<td style="border-top: 0px;">
																			<p><a class="nav-link js-scroll-trigger" href="#link-figura-06"><strong>Figura
																						6</strong> - Extração de características de uma imagem de íris</a></p>
																		</td>
																	</tr>
																	<tr>
																		<td style="border-top: 0px;">
																			<p><a class="nav-link js-scroll-trigger" href="#link-figura-07"><strong>Figura
																						7</strong> - Sequência ácido desoxirribonucleico (DNA)</a></p>
																		</td>
																	</tr>
																	<tr>
																		<td style="border-top: 0px;">
																			<p><a class="nav-link js-scroll-trigger" href="#link-figura-08"><strong>Figura
																						8</strong> - Árvore de decisão para escolha de um carro</a></p>
																		</td>
																	</tr>
																	<tr>
																		<td style="border-top: 0px;">
																			<p><a class="nav-link js-scroll-trigger" href="#link-figura-09"><strong>Figura
																						9</strong> - Disposição de objetos em um espaço vetorial de três dimensões</a></p>
																		</td>
																	</tr>
																	<tr>
																		<td style="border-top: 0px;">
																			<p><a class="nav-link js-scroll-trigger" href="#link-figura-10"><strong>Figura
																						10</strong> - Imagem de classe, objeto e característica</a></p>
																		</td>
																	</tr>
																	<tr>
																		<td style="border-top: 0px;">
																			<p><a class="nav-link js-scroll-trigger" href="#link-figura-11"><strong>Figura
																						11</strong> - Processo de reconhecimento de padrões em <i>machine learning</i></a></p>
																		</td>
																	</tr>
																	<tr>
																		<td style="border-top: 0px;">
																			<p><a class="nav-link js-scroll-trigger" href="#link-figura-12"><strong>Figura
																						12</strong> - Tipos de aprendizagem de máquina</a></p>
																		</td>
																	</tr>
																	<tr>
																		<td style="border-top: 0px;">
																			<p><a class="nav-link js-scroll-trigger" href="#link-figura-13"><strong>Figura
																						13</strong> - Treinamento de um algoritmo de aprendizagem supervisionada</a></p>
																		</td>
																	</tr>
																	<tr>
																		<td style="border-top: 0px;">
																			<p><a class="nav-link js-scroll-trigger" href="#link-figura-14"><strong>Figura
																						14</strong> - Treinamento de um algoritmo de aprendizagem não supervisionada</a></p>
																		</td>
																	</tr>
																	<tr>
																		<td style="border-top: 0px;">
																			<p><a class="nav-link js-scroll-trigger" href="#link-figura-15"><strong>Figura
																						15</strong> - Treinamento de um algoritmo de aprendizagem semi-supervisionada</a></p>
																		</td>
																	</tr>
																	<tr>
																		<td style="border-top: 0px;">
																			<p><a class="nav-link js-scroll-trigger" href="#link-figura-16"><strong>Figura
																						16</strong> - Treinamento de um algoritmo de aprendizagem por reforço</a></p>
																		</td>
																	</tr>
																	<tr>
																		<td style="border-top: 0px;">
																			<p><a class="nav-link js-scroll-trigger" href="#link-figura-17"><strong>Figura
																						17</strong> - Dados unidimensionais sobre altura (em cm)</a></p>
																		</td>
																	</tr>
																	<tr>
																		<td style="border-top: 0px;">
																			<p><a class="nav-link js-scroll-trigger" href="#link-figura-18"><strong>Figura
																						18</strong> - Dados bidimensionais que relacionam peso (em kg) e altura (em cm) de cinco pessoas</a></p>
																		</td>
																	</tr>
																	<tr></tr>
																		<td style="border-top: 0px;">
																			<p><a class="nav-link js-scroll-trigger" href="#link-figura-19"><strong>Figura
																						19</strong> - Dados tridimensionais que relacionam peso (em kg), altura (em cm) e idade (em anos) de cinco pessoas</a></p>
																		</td>
																	</tr>
																	<tr>
																		<td style="border-top: 0px;">
																			<p><a class="nav-link js-scroll-trigger" href="#link-figura-20"><strong>Figura
																						20</strong> - Espaços de características bidimensional denso (à esquerda) e tridimensional esparso (à direita)</a></p>
																		</td>
																	</tr>
																	<tr>
																		<td style="border-top: 0px;">
																			<p><a class="nav-link js-scroll-trigger" href="#link-figura-21"><strong>Figura
																						21</strong> - Espaço de características de peso e altura não normalizado (à esquerda) e normalizado (à direita)</a></p>
																		</td>
																	</tr>
																	<tr>
																		<td style="border-top: 0px;">
																			<p><a class="nav-link js-scroll-trigger" href="#link-figura-22"><strong>Figura
																						22</strong> - Transformação do espaço de características</a></p>
																		</td>
																	</tr>
																	<tr>
																		<td style="border-top: 0px;">
																			<p><a class="nav-link js-scroll-trigger" href="#link-figura-23"><strong>Figura
																						23</strong> - Exemplo tipo de fronteiras</a></p>
																		</td>
																	</tr>
																	<tr>
																		<td style="border-top: 0px;">
																			<p><a class="nav-link js-scroll-trigger" href="#link-figura-24"><strong>Figura
																						24</strong> - Na classificação binária utilizou-se uma função discriminante, na multi-classes, múltiplas  funções discriminantes são utilizadas</a></p>
																		</td>
																	</tr>
																	<tr>
																		<td style="border-top: 0px;">
																			<p><a class="nav-link js-scroll-trigger" href="#link-figura-25"><strong>Figura
																						25</strong> - Matriz de Covariância e as relações de co-dependência entre as variáveis</a></p>
																		</td>
																	</tr>
																	<tr>
																		<td style="border-top: 0px;">
																			<p><a class="nav-link js-scroll-trigger" href="#link-figura-26"><strong>Figura
																						26</strong> - Aplicação de transformações em vetor, (a) exemplo de autovalor e autovetor, (b) exemplo de um não autovetor e autovalor</a></p>
																		</td>
																	</tr>
																	<tr>
																		<td style="border-top: 0px;">
																			<p><a class="nav-link js-scroll-trigger" href="#link-figura-27"><strong>Figura
																						27</strong> - Exemplo de dados estruturados e não estruturados</a></p>
																		</td>
																	</tr>
																	<tr>
																		<td style="border-top: 0px;">
																			<p><a class="nav-link js-scroll-trigger" href="#link-figura-28"><strong>Figura
																						28</strong> - Exemplo de tipos de dados para diferentes modelos</a></p>
																		</td>
																	</tr>
																	<tr>
																		<td style="border-top: 0px;">
																			<p><a class="nav-link js-scroll-trigger" href="#link-figura-29"><strong>Figura
																						29</strong> - Exemplo de técnicas para criação de variáveis categóricas</a></p>
																		</td>
																	</tr>
																	<tr>
																		<td style="border-top: 0px;">
																			<p><a class="nav-link js-scroll-trigger" href="#link-figura-30"><strong>Figura
																						30</strong> - Exemplo divisão do conjunto de dados</a></p>
																		</td>
																	</tr>
																	<tr>
																		<td style="border-top: 0px;">
																			<p><a class="nav-link js-scroll-trigger" href="#link-figura-31"><strong>Figura
																						31</strong> - Exemplo <i>k-fold</i></a></p>
																		</td>
																	</tr>
																	<tr>
																		<td style="border-top: 0px;">
																			<p><a class="nav-link js-scroll-trigger" href="#link-figura-32"><strong>Figura
																						32</strong> - Exemplo dados desbalanceados</a></p>
																		</td>
																	</tr>
																	<tr>
																		<td style="border-top: 0px;">
																			<p><a class="nav-link js-scroll-trigger" href="#link-figura-33"><strong>Figura
																						33</strong> - Exemplo do funcionamento do <i>Synthetic Minority Over-sampling Technique</i> (SMOTE)</a></p>
																		</td>
																	</tr>
																	<tr>
																		<td style="border-top: 0px;">
																			<p><a class="nav-link js-scroll-trigger" href="#link-figura-34"><strong>Figura
																						34</strong> - Exemplo ajustes de curvas</a></p>
																		</td>
																	</tr>
																	<tr>
																		<td style="border-top: 0px;">
																			<p><a class="nav-link js-scroll-trigger" href="#link-figura-35"><strong>Figura
																						35</strong> - Exemplo R²</a></p>
																		</td>
																	</tr>
																	<tr>
																		<td style="border-top: 0px;">
																			<p><a class="nav-link js-scroll-trigger" href="#link-figura-36"><strong>Figura
																						36</strong> - Exemplo de erro quadrático médio (MSE)</a></p>
																		</td>
																	</tr>
																	<tr>
																		<td style="border-top: 0px;">
																			<p><a class="nav-link js-scroll-trigger" href="#link-figura-37"><strong>Figura
																						37</strong> - Exemplo de erro absoluto médio (MAE)</a></p>
																		</td>
																	</tr>
																	<tr>
																		<td style="border-top: 0px;">
																			<p><a class="nav-link js-scroll-trigger" href="#link-figura-38"><strong>Figura
																						38</strong> - Exemplo de raiz do erro quadrático médio (RMSE)</a></p>
																		</td>
																	</tr>
																	<tr>
																		<td style="border-top: 0px;">
																			<p><a class="nav-link js-scroll-trigger" href="#link-figura-39"><strong>Figura
																						39</strong> - Exemplo de Árvore de Regressão - Dados</a></p>
																		</td>
																	</tr>
																	<tr>
																		<td style="border-top: 0px;">
																			<p><a class="nav-link js-scroll-trigger" href="#link-figura-40"><strong>Figura
																						40</strong> - Exemplo de Árvore de Regressão - Árvore</a></p>
																		</td>
																	</tr>
																	<tr>
																	<td style="border-top: 0px;">
																		<p><a class="nav-link js-scroll-trigger" href="#link-figura-41"><strong>Figura
																					41</strong> - Comparação entre redes neurais, redes neurais recorrentes (RNN) e <i>feed-forward</i></a></p>
																	</td>
																</tr>
																<tr>
																	<td style="border-top: 0px;">
																		<p><a class="nav-link js-scroll-trigger" href="#link-figura-42"><strong>Figura
																					42</strong> - Exemplos de Aplicações de Classificação</a></p>
																	</td>
																</tr>
																<tr>
																	<td style="border-top: 0px;">
																		<p><a class="nav-link js-scroll-trigger" href="#link-figura-43"><strong>Figura
																					43</strong> - Exemplo de diferentes amostras de uma classe “gato”</a></p>
																	</td>
																</tr>
																<tr>
																	<td style="border-top: 0px;">
																		<p><a class="nav-link js-scroll-trigger" href="#link-figura-44"><strong>Figura
																					44</strong> - Mapa mental classificadores na literatura de aprendizado de máquina</a></p>
																	</td>
																</tr>
																<tr>
																	<td style="border-top: 0px;">
																		<p><a class="nav-link js-scroll-trigger" href="#link-figura-45"><strong>Figura
																					45</strong> - Exemplos das três espécies de flores Iris</a></p>
																	</td>
																</tr>
																<tr>
																	<td style="border-top: 0px;">
																		<p><a class="nav-link js-scroll-trigger" href="#link-figura-46"><strong>Figura
																					46</strong> - Distribuição das amostras de flores com base no comprimento e largura da Sépala</a></p>
																	</td>
																</tr>
																<tr>
																	<td style="border-top: 0px;">
																		<p><a class="nav-link js-scroll-trigger" href="#link-figura-47"><strong>Figura
																					47</strong> - Exemplo de aplicação do KNN em um novo dado</a></p>
																	</td>
																</tr>
																<tr>
																	<td style="border-top: 0px;">
																		<p><a class="nav-link js-scroll-trigger" href="#link-figura-48"><strong>Figura
																					48</strong> - Fronteira de discriminação de um KNN</a></p>
																	</td>
																</tr>
																<tr>
																	<td style="border-top: 0px;">
																		<p><a class="nav-link js-scroll-trigger" href="#link-figura-49"><strong>Figura
																					49</strong> - Matriz de confusão e seus componentes</a></p>
																	</td>
																</tr>
																<tr>
																	<td style="border-top: 0px;">
																		<p><a class="nav-link js-scroll-trigger" href="#link-figura-50"><strong>Figura
																					50</strong> - Exemplos de Curva ROC de diferentes classificadores</a></p>
																	</td>
																</tr>
																<tr>
																<td style="border-top: 0px;">
																	<p><a class="nav-link js-scroll-trigger" href="#link-figura-51"><strong>Figura
																				51</strong> - Exemplo de uma árvore de decisão sobre o problema de decidir sair de casa ou não</a></p>
																</td>
															</tr>
															<tr>
																<td style="border-top: 0px;">
																	<p><a class="nav-link js-scroll-trigger" href="#link-figura-52"><strong>Figura
																				52</strong> - Ilustração do efeito do Viés e Variância</a></p>
																</td>
															</tr>
															<tr>
																<td style="border-top: 0px;">
																	<p><a class="nav-link js-scroll-trigger" href="#link-figura-53"><strong>Figura
																				53</strong> - Mapa mental com os algoritmos de agrupamento</a></p>
																</td>
															</tr>
															<tr>
																<td style="border-top: 0px;">
																	<p><a class="nav-link js-scroll-trigger" href="#link-figura-54"><strong>Figura
																				54</strong> - Ilustração de um <i>K-means</i> aplicado com três agrupamentos</a></p>
																</td>
															</tr>
															<tr>
																<td style="border-top: 0px;">
																	<p><a class="nav-link js-scroll-trigger" href="#link-figura-55"><strong>Figura
																				55</strong> - Exemplos de aplicação do <i>K-means</i> e DBSCAN</a></p>
																</td>
															</tr>
															<tr>
																<td style="border-top: 0px;">
																	<p><a class="nav-link js-scroll-trigger" href="#link-figura-56"><strong>Figura
																				56</strong> - Exemplos de agrupamentos e índice de silhueta com uso do KNN com diferentes valores de <i>k</i></a></p>
																</td>
															</tr>
															<tr>
																<td style="border-top: 0px;">
																	<p><a class="nav-link js-scroll-trigger" href="#link-figura-57"><strong>Figura
																				57</strong> - Esquema de um neurônio artificial - <i>Perceptron</i></a></p>
																</td>
															</tr>
															<tr>
																<td style="border-top: 0px;">
																	<p><a class="nav-link js-scroll-trigger" href="#link-figura-58"><strong>Figura
																				58</strong> - Funções de ativação <i>step</i> e <i>sigmóide</i></a></p>
																</td>
															</tr>
															<tr>
																<td style="border-top: 0px;">
																	<p><a class="nav-link js-scroll-trigger" href="#link-figura-59"><strong>Figura
																				59</strong> - Esquema básico de um <i>Multi-Layer Perceptron</i></a></p>
																</td>
															</tr>
															<tr>
																<td style="border-top: 0px;">
																	<p><a class="nav-link js-scroll-trigger" href="#link-figura-60"><strong>Figura
																				60</strong> - Esquema básico de um <i>Multi-Layer Perceptron</i> com indicação de fluxo de dados no <i>feedforward</i> e <i>backpropagation</i></a></p>
																</td>
															</tr>
															<tr>
															<td style="border-top: 0px;">
																<p><a class="nav-link js-scroll-trigger" href="#link-figura-61"><strong>Figura
																			61</strong> - Exemplo de vetor gradiente em uma função com duas variáveis</a></p>
															</td>
														</tr>
														<tr>
															<td style="border-top: 0px;">
																<p><a class="nav-link js-scroll-trigger" href="#link-figura-62"><strong>Figura
																			62</strong> - Funções de ativação sigmóide e ReLU</a></p>
															</td>
														</tr>
														<tr>
															<td style="border-top: 0px;">
																<p><a class="nav-link js-scroll-trigger" href="#link-figura-63"><strong>Figura
																			63</strong> - Esquema básico de um <i>Multi-Layer Perceptron</i> ao receber uma imagem</a></p>
															</td>
														</tr>
														<tr>
															<td style="border-top: 0px;">
																<p><a class="nav-link js-scroll-trigger" href="#link-figura-64"><strong>Figura
																			64</strong> - Esquema de um campo receptivo de duas camadas convolucionais</a></p>
															</td>
														</tr>
														<tr>
															<td style="border-top: 0px;">
																<p><a class="nav-link js-scroll-trigger" href="#link-figura-65"><strong>Figura
																			65</strong> - Esquema da AlexNet</a></p>
															</td>
														</tr>
														<tr>
															<td style="border-top: 0px;">
																<p><a class="nav-link js-scroll-trigger" href="#link-figura-66"><strong>Figura
																			66</strong> - Exemplo de imagens do ImageNet</a></p>
															</td>
														</tr>
														<tr>
															<td style="border-top: 0px;">
																<p><a class="nav-link js-scroll-trigger" href="#link-figura-67"><strong>Figura
																			67</strong> - Visualização das convoluções obtidas ao treinar uma CNN</a></p>
															</td>
														</tr>
														<tr>
															<td style="border-top: 0px;">
																<p><a class="nav-link js-scroll-trigger" href="#link-figura-68"><strong>Figura
																			68</strong> - Visualização da atenção em um problema de tradução</a></p>
															</td>
														</tr>
														<tr>
															<td style="border-top: 0px;">
																<p><a class="nav-link js-scroll-trigger" href="#link-quadro-01"><strong>Quadro
																			1</strong> - Detecção, Previsão e Reconhecimento de <i>Machine Learning</i></a></p>
															</td>
														</tr>
														<tr>
															<td style="border-top: 0px;">
																<p><a class="nav-link js-scroll-trigger" href="#link-quadro-02"><strong>Quadro
																			2</strong> - Comparativo entre as métricas abordadas resume essa seção</a></p>
															</td>
														</tr>
														<tr>
															<td style="border-top: 0px;">
																<p><a class="nav-link js-scroll-trigger" href="#link-tabela-01"><strong>Tabela
																			1</strong> - Comparativo entre problemas de detecção, reconhecimento e previsão</a></p>
															</td>
														</tr>
														<tr>
															<td style="border-top: 0px;">
																<p><a class="nav-link js-scroll-trigger" href="#link-tabela-02"><strong>Tabela
																			2</strong> - Exemplos de classes e objetos pertencentes a elas</a></p>
															</td>
														</tr>
														<tr>
															<td style="border-top: 0px;">
																<p><a class="nav-link js-scroll-trigger" href="#link-tabela-03"><strong>Tabela
																			3</strong> - Resumo das vantagens e desvantagens dos algoritmos que usam funções discriminantes</a></p>
															</td>
														</tr>
														<tr>
															<td style="border-top: 0px;">
																<p><a class="nav-link js-scroll-trigger" href="#link-tabela-04"><strong>Tabela
																			4</strong> - Resumo dos Conjuntos de Dados Iris, MNIST e CIFAR-10</a></p>
															</td>
														</tr>
																</tbody>
															</table>
													</div>
												</section>
												
												<section class="resume-section p-3 p-lg-5 d-flex align-items-center" id="sumario">
													<div class="w-100">
														<h1 class="mb-0">Sumário</h1>
														
														<div class="list-group list-group-root well">
															<div style="width: 100%; ">
																<a href="#apresentacao" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; font-weight: bold;width:80%">Apresentação</a>
																<a href="#apresentacao" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">11</a>
															</div>
														</div>
														<div class="list-group list-group-root well">
															<div style="width: 100%; ">
																<a href="#uni1" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; font-weight: bold; width:80%">Unidade I - <i>Machine Learning</i></a>
																<a href="#uni1" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">12</a>
															</div>
														</div>
														<div class="list-group" style="margin-left: 20px;">
															<div style="width: 100%; ">
																<a href="#uni1-1" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">1.1 O que é Machine Learning?</a>
																<a href="#uni1-1" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">12</a>
															</div>
															<div class="list-group" style="margin-left: 20px;">
																<div style="width: 100%; ">
																	<a href="#uni1-1-1" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">1.1.1 Etapas de Construção de um Modelo de <i>Machine Learning</i></a>
																	<a href="#uni1-1-1" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">13</a>
																</div>
																<div class="list-group" style="margin-left: 20px;">
																	<div style="width: 100%; ">
																		<a href="#uni1-1-1-1" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">1.1.1.1 Coleta de dados</a>
																		<a href="#uni1-1-1-1" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">13</a>
																	</div>
																	<div style="width: 100%; ">
																		<a href="#uni1-1-1-2" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">1.1.1.2 Processamento de dados</a>
																		<a href="#uni1-1-1-2" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">13</a>
																	</div>
																	<div style="width: 100%; ">
																		<a href="#uni1-1-1-3" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">1.1.1.3 Treinamento de modelos</a>
																		<a href="#uni1-1-1-3" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">14</a>
																	</div>
																	<div style="width: 100%; ">
																		<a href="#uni1-1-1-4" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">1.1.1.4 Aplicação e tomada de decisão</a>
																		<a href="#uni1-1-1-4" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">14</a>
																	</div>
																</div>
															</div>
															<div class="list-group list-group-root well" style="width: 100%; ">
																<a href="#uni1-2" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">1.2 Aplicações de <i>Machine Learning</i></a>
																<a href="#uni1-2" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">16</a>
															</div>
															
															<div class="list-group list-group-root well" style="width: 100%; ">
																<a href="#uni1-3" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">1.3 Inteligência Artificial x <i>Machine Learning</i> x <i>Deep Learning</i></a>
																<a href="#uni1-3" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">17</a>
															</div>
																													
														</div>
														<div class="list-group list-group-root well">
															<div style="width: 100%; ">
																<a href="#uni2" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; font-weight: bold; width:80%">Unidade II - Detecção, reconhecimento e previsão</a>
																<a href="#uni2" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">20</a>
															</div>
														</div>
														<div class="list-group" style="margin-left: 20px;">
															<div style="width: 100%; ">
																<a href="#uni2-1" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">2.1 Detecção de padrões e anomalias</a>
																<a href="#uni2-1" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">20</a>
															</div>
															<div style="width: 100%; ">
																<a href="#uni2-2" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">2.2 Detecção, Previsão e Reconhecimento</a>
																<a href="#uni2-2" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">22</a>
															</div>
															
														</div>
														
														
														<div class="list-group list-group-root well">
															
															<div style="width: 100%; ">
																<a href="#uni3" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; font-weight: bold; width:80%">Unidade III - Reconhecimento de padrões</a>
																<a href="#uni3" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">25</a>
															</div>
														</div>
														<div class="list-group" style="margin-left: 20px;">
															<div style="width: 100%; ">
																<a href="#uni3-1" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">3.1 O que é reconhecimento?</a>
																<a href="#uni3-1" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">25</a>
															</div>
															<div class="list-group" style="margin-left: 20px;">
																<div style="width: 100%; ">
																	<a href="#uni3-1-1" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">3.1.1 Treinamento de modelos</a>
																	<a href="#uni3-1-1" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">26</a>
																</div>
															</div>													
															<div style="width: 100%; ">
																<a href="#uni3-2" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">3.2 Padrões</a>
																<a href="#uni3-2" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">27</a>
															</div>
															<div class="list-group" style="margin-left: 20px;">
																<div style="width: 100%; ">
																	<a href="#uni3-2-1" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">3.2.1 Arranjos de padrões</a>
																	<a href="#uni3-2-1" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">27</a>
																</div>
																<div style="width: 100%; ">
																	<a href="#uni3-2-2" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">3.2.2 Objetos e características</a>
																	<a href="#uni3-2-2" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">30</a>
																</div>
																<div style="width: 100%; "></div>
																	<a href="#uni3-2-3" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">3.2.3 Classes</a>
																	<a href="#uni3-2-3" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">31</a>
																</div>
															</div>	
														
														

														<div class="list-group list-group-root well">
															
															<div style="width: 100%; ">
																<a href="#uni4" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; font-weight: bold; width:80%">Unidade IV - Tipos de aprendizagem de máquina</a>
																<a href="#uni4" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">37</a>
															</div>
														</div>
														<div class="list-group" style="margin-left: 20px;">
															<div style="width: 100%; ">
																<a href="#uni4-1" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">4.1 Aprendizagem Supervisionada</a>
																<a href="#uni4-1" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">38</a>
															</div>
															<div style="width: 100%; ">
																<a href="#uni4-2" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">4.2 Aprendizagem Não Supervisionada</a>
																<a href="#uni4-2" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">39</a>
															</div>
															
															<div style="width: 100%; ">
																<a href="#uni4-3" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">4.3 Aprendizagem Semi-Supervisionada</a>
																<a href="#uni4-3" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">40</a>
															</div>	
															<div style="width: 100%; ">
																<a href="#uni4-4" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">4.4 Aprendizagem por reforço</a>
																<a href="#uni4-4" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">41</a>
															</div>
															
														</div>
														
														<div class="list-group list-group-root well">
															
															<div style="width: 100%; ">
																<a href="#uni5" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; font-weight: bold; width:80%">Unidade V - Espaço de características</a>
																<a href="#uni5" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">45</a>
															</div>
														</div>
														<div class="list-group" style="margin-left: 20px;">
														<div style="width: 100%; ">
															<a href="#uni5-1" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">5.1 Extração de características</a>
															<a href="#uni5-1" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">45</a>
															
														</div>

														<div style="width: 100%; ">
															<a href="#uni5-2" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">5.2 Seleção de características</a>
															<a href="#uni5-2" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">46</a>
														
														</div>
														<div style="width: 100%; ">
															<a href="#uni5-3" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">5.3 Características vs. dimensionalidade</a>
															<a href="#uni5-3" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">47</a>
														
														</div>
														<div style="width: 100%; ">
															<a href="#uni5-4" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">5.4 Maldição da dimensionalidade</a>
															<a href="#uni5-4" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">50</a>
														
														</div>
														<div style="width: 100%; ">
															<a href="#uni5-5" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">5.5 Normalização do espaço de características</a>
															<a href="#uni5-5" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">51</a>
														
														</div>
														<div style="width: 100%; ">
															<a href="#uni5-6" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">5.6 Transformação do espaço de características</a>
															<a href="#uni5-6" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">53</a>
														
														</div>
														<div style="width: 100%; ">
															<a href="#uni5-7" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">5.7 Redução da dimensionalidade</a>
															<a href="#uni5-7" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">54</a>
														
														</div>
														<div style="width: 100%; ">
															<a href="#uni5-8" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">5.8 Seleção de características vs. redução da dimensionalidade</a>
															<a href="#uni5-8" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">55</a>
														</div>
														
													</div>
													<div class="list-group list-group-root well">
															
														<div style="width: 100%; ">
															<a href="#uni6" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; font-weight: bold; width:80%">Unidade VI - Funções discriminantes</a>
															<a href="#uni6" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">57</a>
														</div>
													</div>
													<div class="list-group" style="margin-left: 20px;">
														<div style="width: 100%; ">
															<a href="#uni6-1" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">6.1 Introdução</a>
															<a href="#uni6-1" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">57</a>
														</div>
														<div style="width: 100%; ">
															<a href="#uni6-2" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">6.2 Aplicações</a>
															<a href="#uni4-2" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">57</a>
														</div>
														
														<div style="width: 100%; ">
															<a href="#uni6-3" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">6.3 Conceitos Importantes</a>
															<a href="#uni4-3" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">58</a>
														</div>	
														<div class="list-group" style="margin-left: 20px;">
															<div style="width: 100%; ">
																<a href="#uni6-3-1" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">6.3.1 Espaço de características</a>
																<a href="#uni6-3-1" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">59</a>
															</div>
															<div style="width: 100%; ">
																<a href="#uni6-3-2" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">6.3.2 Fronteiras de decisão</a>
																<a href="#uni6-3-2" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">59</a>
															</div>
															<div style="width: 100%; ">
																<a href="#uni6-3-3" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">6.3.3 Classificação binária vs. multiclasse</a>
																<a href="#uni6-3-3" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">60</a>
															</div>
														</div>
														<div style="width: 100%; ">
															<a href="#uni6-4" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">6.4 Principais Algoritmos</a>
															<a href="#uni6-4" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">61</a>
														</div>
														<div class="list-group" style="margin-left: 20px;">
															<div style="width: 100%; ">
																<a href="#uni6-4-1" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">6.4.1 Conceitos Matemáticos Importantes</a>
																<a href="#uni6-4-1" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">61</a>
															</div>
														<div class="list-group" style="margin-left: 20px;">
															<div style="width: 100%; ">
																<a href="#uni6-4-1-2" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">6.4.1.1 Matriz de covariância ou de dispersão</a>
																<a href="#uni6-4-1-2" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">61</a>
															</div>
															<div style="width: 100%; ">
																<a href="#uni6-4-1-3" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">6.4.1.2 Autovetores e Autovalores</a>
																<a href="#uni6-4-1-3" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">63</a>
															</div>
															</div>
															<div style="width: 100%; ">
																<a href="#uni6-4-2" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">6.4.2 Análise Discriminante Linear (LDA)</a>
																<a href="#uni6-4-2" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">64</a>
															</div>
															<div style="width: 100%; ">
																<a href="#uni6-4-3" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">6.4.3 Análise Discriminante Quadrática (QDA)</a>
																<a href="#uni6-4-3" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">67</a>
															</div>
															<div style="width: 100%; ">
																<a href="#uni6-4-4" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">6.4.4 Análise Discriminante Regularizada (RDA)</a>
																<a href="#uni6-4-4" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">69</a>
															</div>
														</div>
														<div style="width: 100%; ">
															<a href="#uni6-5" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">6.5 Notebook Colab</a>
															<a href="#uni6-5" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">70</a>
														</div>
														
													</div>
													<div class="list-group list-group-root well">
															
														<div style="width: 100%; ">
															<a href="#uni7" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; font-weight: bold; width:80%">Unidade VII - Conjuntos de dados</a>
															<a href="#uni7" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">73</a>
														</div>
													</div>
													<div class="list-group" style="margin-left: 20px;">
														<div style="width: 100%; ">
															<a href="#uni7-1" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">7.1 A Importância dos Dados para a Construção de Modelos de ML</a>
															<a href="#uni7-1" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">73</a>
														</div>
														<div style="width: 100%; ">
															<a href="#uni7-2" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">7.2 Dados Estruturados vs. Dados Não Estruturados</a>
															<a href="#uni7-2" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">74</a>
														</div>
														
														<div style="width: 100%; ">
															<a href="#uni7-3" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">7.3 Conjuntos de Dados Supervisionados, Não Supervisionados e Semi-supervisionados</a>
															<a href="#uni7-3" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">76</a>
														</div>	
														<div style="width: 100%; ">
															<a href="#uni7-4" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:85%">7.4 Limpeza de Dados (Tratamento de Valores Ausentes, Outliers, Erros de Digitação)</a>
															<a href="#uni7-4" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">78</a>
														</div>
														<div style="width: 100%; ">
															<a href="#uni7-5" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">7.5 Pré-processamento (Normalização, Codificação de Variáveis Categóricas)</a>
															<a href="#uni7-5" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">80</a>
														</div>	
														<div style="width: 100%; ">
															<a href="#uni7-6" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">7.6 Seleção e Engenharia de Características (Feature Selection e Feature Engineering)</a>
															<a href="#uni7-6" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">82</a>
														</div>	
														<div style="width: 100%; ">
															<a href="#uni7-7" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">7.7 Divisão em Conjuntos de Treino, Validação e Teste</a>
															<a href="#uni7-7" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">83</a>
														</div>	
														<div style="width: 100%; ">
															<a href="#uni7-8" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">7.8 Dados Desbalanceados e Técnicas para Balanceamento</a>
															<a href="#uni7-8" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">85</a>
														</div>
														<div class="list-group" style="margin-left: 20px;">
															<div style="width: 100%; ">
																<a href="#uni7-8-1" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">7.8.1 - Técnica de oversampling</a>
																<a href="#uni7-8-1" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">87</a>
															</div>
															<div style="width: 100%; ">
																<a href="#uni7-8-2" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">7.8.2 - Técnica de undersampling</a>
																<a href="#uni7-8-2" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">89</a>
															</div>
														</div>
														<div style="width: 100%; ">
															<a href="#uni7-9" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">7.9 Subajuste (Underfitting) e Sobreajuste (Overfitting)</a>
															<a href="#uni7-9" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">89</a>
														</div>	
														<div style="width: 100%; ">
															<a href="#uni7-10" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">7.10 Notebook Colab</a>
															<a href="#uni7-10" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">91</a>
														</div>		
														
													</div>
													<div class="list-group list-group-root well">
															
														<div style="width: 100%; ">
															<a href="#uni8" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; font-weight: bold; width:80%">Unidade VIII - Regressão</a>
															<a href="#uni8" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">93</a>
														</div>
													</div>
													<div class="list-group" style="margin-left: 20px;">
														<div style="width: 100%; ">
															<a href="#uni8-1" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">8.1 Métricas de Avaliação</a>
															<a href="#uni8-1" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">94</a>
														</div>
														<div class="list-group" style="margin-left: 20px;">
															<div style="width: 100%; ">
																<a href="#uni8-1-1" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">8.1.1 Coeficiente de Determinação R2</a>
																<a href="#uni8-1-1" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">94</a>
															</div>
															<div style="width: 100%; ">
																<a href="#uni8-1-2" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">8.1.2 Erro Quadrático Médio (MSE)</a>
																<a href="#uni8-1-2" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">95</a>
															</div>
															<div style="width: 100%; ">
																<a href="#uni8-1-3" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">8.1.3 Erro Absoluto Médio (MAE)</a>
																<a href="#uni8-1-3" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">97</a>
															</div>
															<div style="width: 100%; ">
																<a href="#uni8-1-4" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">8.1.4 Raiz do Erro Quadrático Médio (RMSE)</a>
																<a href="#uni8-1-4" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">98</a>
															</div>
														</div>
														<div style="width: 100%; ">
															<a href="#uni8-2" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">8.2 Tipos de Regressão</a>
															<a href="#uni8-2" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">101</a>
														</div>
														<div class="list-group" style="margin-left: 20px;">
															<div style="width: 100%; ">
																<a href="#uni8-2-1" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">8.2.1 Regressão Linear</a>
																<a href="#uni8-2-1" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">101</a>
															</div>
															<div style="width: 100%; ">
																<a href="#uni8-2-2" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">8.2.2 Regressão Ridge, Lasso e Elastic Net</a>
																<a href="#uni8-2-2" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">101</a>
															</div>
															<div style="width: 100%; ">
																<a href="#uni8-2-3" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">8.2.3 Árvores de Regressão</a>
																<a href="#uni8-2-3" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">104</a>
															</div>
															<div style="width: 100%; ">
																<a href="#uni8-2-4" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">8.2.4 RNN (Recurrent Neural Network) ou Rede Neural Recorrente</a>
																<a href="#uni8-2-4" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">107</a>
															</div>
														</div>
														<div style="width: 100%; ">
															<a href="#uni8-3" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">8.3 Notebook Colab</a>
															<a href="#uni8-3" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">108</a>
														</div>	
														
													</div>
													
													<div class="list-group list-group-root well">
															
														<div style="width: 100%; ">
															<a href="#uni9" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; font-weight: bold; width:80%">Unidade IX - Classificação</a>
															<a href="#uni9" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">114</a>
														</div>
													</div>
													<div class="list-group" style="margin-left: 20px;">
														<div style="width: 100%; ">
															<a href="#uni9-1" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">9.1 Classificadores</a>
															<a href="#uni9-1" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">114</a>
														</div>
														<div class="list-group" style="margin-left: 20px;">
															<div style="width: 100%; ">
																<a href="#uni9-1-1" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">9.1.1 KNN: k-Nearest Neighbors</a>
																<a href="#uni9-1-1" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">116</a>
															</div>
														</div>
														<div style="width: 100%; ">
															<a href="#uni9-2" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">9.2 Avaliação de Classificadores</a>
															<a href="#uni9-2" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">119</a>
														</div>
														
														<div class="list-group" style="margin-left: 20px;">
															<div style="width: 100%; ">
																<a href="#uni9-2-1" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">9.2.1 Métricas para Classificação</a>
																<a href="#uni9-2-1" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">120</a>
															</div>
															<div class="list-group" style="margin-left: 20px;">
																<div style="width: 100%; ">
																	<a href="#uni9-2-1-1" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">9.2.1.1 Acurácia</a>
																	<a href="#uni9-2-1-1" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">121</a>
																</div>
																<div style="width: 100%; ">
																	<a href="#uni9-2-1-2" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">9.2.1.2 Precisão</a>
																	<a href="#uni9-2-1-2" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">122</a>
																</div>
																<div style="width: 100%; ">
																	<a href="#uni9-2-1-3" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">9.2.1.3 Recall</a>
																	<a href="#uni9-2-1-3" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">122</a>
																</div>
																<div style="width: 100%; ">
																	<a href="#uni9-2-1-4" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">9.2.1.4 F1-score</a>
																	<a href="#uni9-2-1-4" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">122</a>
																</div>
																<div style="width: 100%; ">
																	<a href="#uni9-2-1-5" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">9.2.1.5 Matriz de confusão</a>
																	<a href="#uni9-2-1-5" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">123</a>
																</div>
																<div style="width: 100%; ">
																	<a href="#uni9-2-1-6" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">9.2.1.6 Acurácia em Detecção de Fraude</a>
																	<a href="#uni9-2-1-6" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">123</a>
																</div>
																<div style="width: 100%; ">
																	<a href="#uni9-2-1-7" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">9.2.1.7 Precisão em Diagnóstico Médico (Detecção de Câncer)</a>
																	<a href="#uni9-2-1-7" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">124</a>
																</div>
																<div style="width: 100%; ">
																	<a href="#uni9-2-1-8" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">9.2.1.8 F1-Score em Detecção de Spam</a>
																	<a href="#uni9-2-1-8" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">124</a>
																</div>
																<div style="width: 100%; ">
																	<a href="#uni9-2-1-9" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">9.2.1.9 Curva ROC</a>
																	<a href="#uni9-2-1-9" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">124</a>
																</div>
															</div>
														</div>
														<div style="width: 100%; ">
															<a href="#uni9-3" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">9.3 Classificadores Modernos</a>
															<a href="#uni9-3" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">126</a>
														</div>	
														<div class="list-group" style="margin-left: 20px;">
															<div style="width: 100%; ">
																<a href="#uni9-3-1" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">9.3.1 XGBoost</a>
																<a href="#uni9-3-1" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">127</a>
															</div>
															<div style="width: 100%; ">
																<a href="#uni9-3-2" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">9.3.2 LightGBM</a>
																<a href="#uni9-3-2" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">128</a>
															</div>
														</div>
														<div style="width: 100%; ">
															<a href="#uni9-4" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">9.4 Notebook Colab</a>
															<a href="#uni9-4" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">129</a>
														</div>
														
													</div>
													<div class="list-group list-group-root well">
															
														<div style="width: 100%; ">
															<a href="#uni10" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; font-weight: bold; width:80%">Unidade X - Agrupamento</a>
															<a href="#uni10" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">132</a>
														</div>
													</div>
													<div class="list-group" style="margin-left: 20px;">
														<div style="width: 100%; ">
															<a href="#uni10-1" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">10.1 K-Means</a>
															<a href="#uni10-1" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">133</a>
														</div>
														<div style="width: 100%; ">
															<a href="#uni10-2" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">10.2 DBSCAN</a>
															<a href="#uni10-2" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">134</a>
														</div>
														
														<div style="width: 100%; ">
															<a href="#uni10-3" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">10.3 Avaliação de Agrupamentos</a>
															<a href="#uni10-3" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">135</a>
														</div>	
														<div style="width: 100%; ">
															<a href="#uni10-4" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">10.4 Notebook Colab</a>
															<a href="#uni10-4" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">136</a>
														</div>
														
													</div>
													<div class="list-group list-group-root well">
															
														<div style="width: 100%; ">
															<a href="#uni11" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; font-weight: bold; width:80%">Unidade XI - Redes Neurais</a>
															<a href="#uni11" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">137</a>
														</div>
													</div>
													<div class="list-group" style="margin-left: 20px;">
														<div style="width: 100%; ">
															<a href="#uni11-1" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">11.1 Neurônio Artificial</a>
															<a href="#uni11-1" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">138</a>
														</div>
														<div style="width: 100%; ">
															<a href="#uni11-2" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">11.2 Multi-Layer Perceptron</a>
															<a href="#uni11-2" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">140</a>
														</div>
														
														<div style="width: 100%; ">
															<a href="#uni11-3" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">11.3 Deep Learning</a>
															<a href="#uni11-3" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">145</a>
														</div>	
														<div class="list-group" style="margin-left: 20px;">
															<div style="width: 100%; ">
																<a href="#uni10-1" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">11.3.1 CNNs: Redes Neurais Convolucionais</a>
																<a href="#uni10-1" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">146</a>
															</div>
															<div style="width: 100%; ">
																<a href="#uni10-2" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">11.3.2 Transformer</a>
																<a href="#uni10-2" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">150</a>
															</div>
															
															<div style="width: 100%; ">
																<a href="#uni10-3" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">11.3.3 Rede Neurais Generativas</a>
																<a href="#uni10-3" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">151</a>
															</div>	
															<div style="width: 100%; ">
																<a href="#uni10-4" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">11.3.4 Frameworks para DL</a>
																<a href="#uni10-4" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">152</a>
															</div>
														</div>

													</div>
													<div class="list-group list-group-root well">
															
														<div style="width: 100%; ">
															<a href="#uni12" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; font-weight: bold; width:80%">Unidade XII - Encerramento</a>
															<a href="#uni12" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">154</a>
														</div>
													</div>
													<div class="list-group" style="margin-left: 20px;">
														<div style="width: 100%; ">
															<a href="#uni12-1" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; width:80%">12.1 Considerações Finais</a>
															<a href="#uni12-1" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">154</a>
														</div>
													</div>
												<div class="list-group list-group-root well">
															
													<div style="width: 100%; ">
														<a href="#referencias" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; font-weight: bold; width:80%">Referências</a>
														<a href="#referencias" class="list-group-item nav-link js-scroll-trigger" style="display: inline-block; float: right;">155</a>
													</div>
												</div>
											
											</div>
													
												</section>
												<hr class="m-0">

												<section class="resume-section p-3 p-lg-5 d-flex align-items-center" id="apresentacao">
													<div class="w-100">
														<h1 class="mb-0">Apresentação </h1>
														</br>
														<p class="lead mb-3 text-justify ">Prezado(a) Participante,</p>
													
														<p class="lead mb-3 text-justify indent">Seja bem-vindo(a) ao Microcurso <b>Introdução a Machine Learning e Redes Neurais</b>!</p>
														<p class="lead mb-3 text-justify indent">Este microcurso faz parte da Coleção Formação e Capacitação do Centro de Competências Imersivas, uma parceria entre a Embrapii e a Universidade Federal de Goiás (UFG).</p>
														<p class="lead mb-3 text-justify indent">Neste Microcurso, você será introduzido aos conceitos fundamentais de <i>machine learning</i>, aprendendo a construir modelos, desde a coleta e o processamento de dados até a 
															aplicação prática em problemas reais. Começaremos com uma visão geral do aprendizado de máquina, explorando suas principais etapas e diferenciando-o de outras áreas da inteligência artificial.</p>
														<p class="lead mb-3 text-justify indent">À medida que avançamos, aprofundaremos em técnicas de reconhecimento de padrões, essenciais para desenvolver modelos precisos. Abordaremos os diferentes tipos de 
															aprendizado de máquina e exploraremos o espaço de características, discutindo como selecionar e transformar dados para otimizar o desempenho dos modelos.</p>
														<p class="lead mb-3 text-justify indent">Na etapa final, exploraremos técnicas avançadas, como funções discriminantes e as aplicações práticas de regressão e classificação, além de uma introdução às Redes Neurais. 
															Você terá a oportunidade de aprender sobre arquiteturas neurais modernas, compreender seus princípios e ver como aplicá-las em problemas que ilustram o potencial dessas tecnologias.</p>
														<p class="lead mb-3 text-justify indent">Este microcurso oferece uma visão abrangente e prática que o prepara para os desafios do aprendizado de máquina, equipando você com as ferramentas e o 
															conhecimento necessários para seguir em frente na sua jornada na Inteligência Artificial.</p>
														<p class="lead mb-3 text-justify indent">Desejamos a você uma excelente jornada de aprendizado!</p>
														<div align="center" >
															<div class="image fit" style="width: 40%;"><img src="Robozinho/roboAmorRoxoComCubo.png" alt="" /></div>
														</div>
														
													</div>
													<br>
												</section>
												<hr class="m-0">
												<section>
													<div class="image main" id="capa_uni1">
														<img src="images/6. Unidade_1_Introdução a Machine Learning e Redes Neurais.png" alt="">
													</div>
													</section>
													
													<section class="resume-section p-3 p-lg-5 d-flex align-items-center" id="uni1">
									<header class="main">
										<div class="w-100">
											<h1 class="mb-0" id="uni1">Unidade I - <i>Machine Learning</i></h1>
										</div></header>
										
										<h2 class="mb-0" id="uni1-1">1.1 O que é <i>Machine Learning?</i></h2>
										
										<p class="lead mb-3 text-justify indent"><i>Machine Learning</i> (ML), ou aprendizado de máquina, é uma subárea da Inteligência Artificial (IA) 
											que se concentra em desenvolver algoritmos e técnicas que permitem aos computadores aprender e fazer previsões ou tomar decisões 
											com base em dados. Em vez de serem explicitamente programados para realizar uma tarefa, os sistemas de ML são treinados em 
											grandes volumes de dados e são capazes de melhorar seu desempenho ao longo do tempo.
										</p>
										<p class="lead mb-3 text-justify indent">No contexto de ML, diferentemente de aplicações utilitárias, 
											algoritmos são métodos ou conjuntos de regras que os sistemas de computador seguem para realizar tarefas 
											específicas de aprendizado. Diferente da programação tradicional, onde o comportamento do software é definido 
											por um conjunto de instruções explícitas codificadas por programadores, os algoritmos de ML permitem que os 
											sistemas de computador aprendam padrões e tendências diretamente dos dados.</p>
										
										<p class="lead mb-3 text-justify indent">Para entendermos melhor os algoritmos utilizados em ML, para além de um simples ciclo de processamento 
											de dados, listamos abaixo algumas características que os diferenciam:</p>
										
											<ol style="margin-left: 1cm;" class="lead mb-3 text-justify indent">
												<li><b>Aprendizado baseado em dados</b>: os algoritmos de ML utilizam dados para construir modelos matemáticos. 
													Esses modelos são ajustados durante um processo chamado treinamento, onde o algoritmo analisa os dados de 
													entrada e ajusta seus parâmetros internos para minimizar a diferença entre suas previsões e os resultados reais.</li>
												<li><b>Capacidade de generalização</b>: um bom algoritmo de ML deve ser capaz de generalizar o conhecimento adquirido 
													durante o treinamento para novos dados, ou seja, deve fazer previsões precisas sobre dados que não foram usados 
													durante o treinamento.</li>
												<li><b>Melhoria contínua</b>: os sistemas de ML podem melhorar seu desempenho ao longo do tempo conforme são expostos 
													a mais dados. Essa melhoria contínua é alcançada através de técnicas de atualização de modelos, que ajustam 
													continuamente os parâmetros do algoritmo conforme novos dados são disponibilizados.</li>
												<li><b>Tomada de decisões</b>: com base nos padrões aprendidos, os algoritmos de ML podem fazer previsões ou 
													tomar decisões. Por exemplo, em um sistema de recomendação, um algoritmo pode prever quais produtos 
													um usuário pode gostar com base em seu histórico de compras e comportamento de navegação.</li>
											</ol>
											<h3 class="mb-0" id="uni1-1-1">1.1.1 Etapas de Construção de um Modelo de <i>Machine Learning</i></h3>
											<p class="lead mb-3 text-justify indent">A transformação de dados brutos em decisões inteligentes utilizando ML é 
												um processo sistemático que envolve várias etapas essenciais, desde a coleta inicial dos dados até a aplicação 
												prática de modelos treinados. Cada etapa desempenha um papel crucial na construção de modelos que podem aprender 
												com os dados e fazer previsões ou tomar decisões com base neles. A seguir, explicamos as principais etapas desse processo.</p>
											<h3 class="mb-0" id="uni1-1-1-1">1.1.1.1 Coleta de dados</h3>
											<p class="lead mb-3 text-justify indent">A primeira etapa é a coleta de dados brutos, que são os dados não processados 
												coletados diretamente da fonte. Esses dados podem vir de diversas fontes, como sensores, logs de atividades, 
												interações de usuários, registros financeiros, dados de redes sociais, entre outros. A qualidade e a quantidade 
												dos dados coletados são fundamentais, pois eles formam a base sobre a qual todo o processo de ML será construído. 
												Essa etapa é importante pois:</p>
											<ul style="margin-left: 1cm;" class="lead mb-3 text-justify indent">
												<li>A coleta adequada garante que os dados capturem as informações relevantes para o problema que se deseja resolver.</li>
												<li>Dados variados e de alta qualidade aumentam a capacidade do modelo de generalizar e fazer previsões precisas.</li>
											</ul>
											<h3 class="mb-0" id="uni1-1-1-2">1.1.1.2 Processamento de dados</h3>
											<p class="lead mb-3 text-justify indent">Após a coleta, os dados brutos passam por um processo de limpeza e preparação, 
												conhecido como pré-processamento. Esta etapa envolve a remoção de ruídos, tratamento de valores ausentes, transformação 
												de variáveis categóricas, normalização, e extração de características. O objetivo é transformar os dados brutos em um 
												formato estruturado e adequado para a modelagem. Essa etapa é dividida nas seguintes sub-etapas:</p>
											<ul style="margin-left: 1cm;" class="lead mb-3 text-justify indent">
												<li><b>Limpeza de dados</b>: Remoção de inconsistências, duplicatas e valores ausentes.</li>
												<li><b>Transformação de dados</b>: Conversão de dados categóricos em numéricos, normalização e padronização.</li>
												<li><b>Extração de características</b>: Identificação e seleção de atributos relevantes que ajudarão na construção do modelo.</li>
											</ul>
											<p class="lead mb-3 text-justify indent">Podemos destacar os seguintes pontos que tornam essa etapa igualmente importante:</p>
											<ul style="margin-left: 1cm;" class="lead mb-3 text-justify indent">
												<li>Dados bem processados reduzem a complexidade do modelo e aumentam sua precisão.</li>
												<li>Ajuda a prevenir problemas como o <i>overfitting</i> (sobreajuste) e melhora a performance do modelo.</li>
											</ul>
											<h3 class="mb-0" id="uni1-1-1-3">1.1.1.3 Treinamento de modelos</h3>
											<p class="lead mb-3 text-justify indent">Nesta etapa, os dados processados são utilizados para treinar o modelo de ML. 
												O treinamento envolve a aplicação de algoritmos que aprendem a partir dos dados, ajustando parâmetros internos para 
												minimizar o erro de previsão. Durante o treinamento, o modelo é exposto a exemplos rotulados (em aprendizado supervisionado) 
												ou a padrões nos dados (em aprendizado não supervisionado) para identificar as relações subjacentes. 
												São sub-etapas a serem destacadas?</p>
											<ul style="margin-left: 1cm;" class="lead mb-3 text-justify indent">
												<li><b>Divisão dos dados</b>: Os dados são divididos em conjuntos de treinamento e teste para avaliar a performance do modelo.</li>
												<li><b>Treinamento</b>: O modelo é ajustado iterativamente para melhorar sua capacidade de prever os resultados corretos.</li>
												<li><b>Validação</b>: Técnicas como validação cruzada são usadas para garantir que o modelo não se ajuste excessivamente aos dados de treinamento (<i>overfitting</i>).</li>
											</ul>
											<p class="lead mb-3 text-justify indent">Algumas questões devem ser levadas em consideração para execução dessa etapa, sendo elas:</p>
											<ul style="margin-left: 1cm;" class="lead mb-3 text-justify indent">
												<li>Um bom treinamento é crucial para que o modelo aprenda os padrões corretos nos dados.</li>
												<li>O modelo deve ser capaz de generalizar bem para novos dados que ele não tenha visto durante o treinamento.</li>
											</ul>
											<h3 class="mb-0" id="uni1-1-1-4">1.1.1.4 Aplicação e tomada de decisão</h3>
											<p class="lead mb-3 text-justify indent">Depois que o modelo é treinado e validado, ele é aplicado em novos dados para fazer previsões ou tomar decisões. 
												Nesta fase, o modelo é implementado em um ambiente de produção onde ele pode ser usado para automatizar processos, prever resultados futuros, 
												ou tomar decisões baseadas em dados em tempo real. São exemplos de aplicações em ambientes de produção reais:</p>
											<ul style="margin-left: 1cm;" class="lead mb-3 text-justify indent">
												<li><b>Detecção de fraudes</b>: Identificação de transações suspeitas em sistemas financeiros.</li>
												<li><b>Recomendação de produtos</b>: Sugestão de produtos personalizados para usuários em plataformas de <i>e-commerce</i> (comércio digital).</li>
												<li><b>Previsão de demandas</b>: Estimativa de demanda futura para otimização de estoques.</li>
											</ul>
											<p class="lead mb-3 text-justify indent">Mesmo sendo as duas últimas etapas do processo de construção de um modelo de ML, ainda podemos destacar pontos de atenção visando garantir o sucesso do projeto:</p>
											<ul style="margin-left: 1cm;" class="lead mb-3 text-justify indent">
												<li>A aplicação bem-sucedida do modelo permite que as organizações tomem decisões mais informadas, rápidas e precisas.</li>
												<li>Modelos implementados em produção podem melhorar continuamente à medida que recebem novos dados e feedback.</li>
											</ul>
											<p class="lead mb-3 text-justify indent">Portanto, a evolução de dados brutos para a tomada de decisão inteligente em ML é um 
												processo interativo e dinâmico, que exige atenção cuidadosa em cada etapa. Desde a coleta de dados até a aplicação do modelo, 
												cada fase contribui para o desenvolvimento de soluções que não só aprendem com os dados, mas também melhoram a eficiência e a 
												precisão na tomada de decisões. Este processo, ilustrado na Figura 1, é fundamental para transformar grandes volumes de dados 
												em <i>insights</i> (percepções) acionáveis, permitindo que as organizações respondam de forma eficaz a desafios e oportunidades em tempo real.</p>
												<p class="lead mb-3 text-center" id="link-figura-01"><b>Figura 1</b> - Etapas de construção de um modelo de <i>machine learning</i></p>
												<div align="center">
													<span class="image fit" style="width: 70%;"><img src="images/Figura 1 - Etapas de construção de um modelo de ML.png" alt="" /></span>
													<p class="lead mb-2 text-center"><small> Fonte: adaptado de <a href="https://miro.medium.com/v2/resize:fit:720/format:webp/1*c32H3XbSopdo27Y8h9q5ow.png">Waltrick, 2020</a>.</small></p>
												</div>
											<p class="lead mb-3 text-justify indent">Também podemos compreender os algoritmos de ML dividindo-os quanto ao tipo de aprendizado, que discutiremos com mais detalhes adiante:</p>
											<ol style="margin-left: 1cm;" class="lead mb-3 text-justify indent">
												<li><b>Algoritmos supervisionados</b>: nestes algoritmos, o modelo é treinado com um conjunto de dados rotulados, ou seja, os dados de entrada são acompanhados por 
													resultados desejados. Exemplos incluem regressão linear e classificadores de árvore de decisão.</li>
												<li><b>Algoritmos não-supervisionados</b>: o modelo é treinado com dados que não possuem rótulos. O objetivo é encontrar padrões ou 
													estruturas subjacentes nos dados. Exemplos incluem algoritmos de agrupamentos como <i>k-means</i> e métodos de redução de dimensionalidade 
													como Análise de Componentes Principais (PCA).</li>
												<li><b>Algoritmos semi-supervisionados</b>: estes algoritmos utilizam uma combinação de dados rotulados e não rotulados para o treinamento. Eles são particularmente úteis quando a rotulagem de dados é cara ou demorada.</li>
												<li><b>Algoritmos de aprendizado por reforço</b>: baseados em um sistema de recompensas e punições, esses algoritmos aprendem a tomar decisões sequenciais para maximizar uma recompensa cumulativa. Um exemplo comum é o treinamento de agentes de IA para jogar jogos de vídeo.</li>
											</ol>
											<p class="lead mb-3 text-justify indent">Citamos algumas técnicas como classificação, regressão e agrupamentos para explicar os algoritmos de ML com exemplos. 
												Neste microcurso, você terá a oportunidade de desenvolver, testar e melhorar cada uma dessas técnicas no decorrer das unidades; até lá, abaixo citamos alguns exemplos de aplicações desses algoritmos:</p>
											<ul style="margin-left: 1cm;" class="lead mb-3 text-justify indent">
												<li><b>Classificação</b>: diferenciar emails em "spam" e "não spam".</li>
												<li><b>Regressão</b>: prever o preço de uma casa com base em suas características.</li>
												<li><b>Agrupamentos</b>: agrupar clientes com comportamentos de compra semelhantes para campanhas de marketing direcionadas.</li>
												<li><b>Recomendações</b>: sugerir filmes ou produtos com base nas preferências do usuário.</li>
											</ul>
											<p class="lead mb-3 text-justify indent">Os algoritmos são a base do aprendizado de máquina, permitindo que sistemas computacionais façam previsões e 
												tomem decisões informadas a partir de grandes volumes de dados. Eles são fundamentais para a criação de sistemas inteligentes que podem evoluir e 
												melhorar continuamente, ampliando as capacidades da IA.</p>

										<h2 class="mb-0" id="uni1-2">1.2 Aplicações de <i>Machine Learning</i></h2>
										<p class="lead mb-3 text-justify indent">As aplicações de ML são vastas e se estendem por diversos setores (Figura 2). Alguns exemplos incluem:</p>
										<ol style="margin-left: 1cm;" class="lead mb-3 text-justify indent">
											<li><b>Reconhecimento de imagem</b>: utilizado em sistemas de segurança, diagnósticos médicos (radiologia) e redes sociais para reconhecimento facial;</li>
											<li><b>Processamento de Linguagem Natural (PLN)</b>: aplicado em assistentes virtuais, tradução automática, análise de sentimentos e <i>chatbots</i>;</li>
											<li><b>Sistemas de recomendação</b>: utilizado por empresas como Netflix, Amazon e Spotify para sugerir produtos, filmes ou músicas com base nas preferências do usuário;</li>
											<li><b>Previsão de mercado</b>: usado em finanças para prever preços de ações, analisar risco de crédito e detectar fraudes;</li>
											<li><b>Veículos autônomos</b>: utilizam ML para processar informações sensoriais e tomar decisões em tempo real sobre navegação e segurança;</li>
											<li><b>Saúde</b>: aplicado em diagnósticos, personalização de tratamentos e predição de surtos de doenças.</li>
										</ol>
										<p class="lead mb-3 text-center" id="link-figura-02"><b>Figura 2</b> - Aplicações de <i>machine learning</i> em diferentes setores</p>
												<div align="center">
													<span class="image fit" style="width: 70%;"><img src="images/Figura 2 - Aplicações de ML em diferentes setores.png" alt="" /></span>
													<p class="lead mb-2 text-center"><small>Fonte: Autoria própria.</small></p>
												</div>
										<h2 class="mb-0" id="uni1-3">1.3 Inteligência Artificial x <i>Machine Learning</i> x <i>Deep Learning</i></h2>
										<p class="lead mb-3 text-justify indent">É importante entender a relação entre IA, ML e <i>Deep Learning</i> (DL) ou Aprendizagem Profunda. 
											Apesar de apresentadas na Figura 3 como áreas independentes com interseções com suas correlatas, não temos um limite claro onde 
											cada uma começa e termina. Para fins didáticos, vamos explicá-las separadamente:</p>
										<ol style="margin-left: 1cm;" class="lead mb-3 text-justify indent">
											<li><b>Inteligência Artificial</b>: trata-se de um campo amplo da ciência da computação que visa criar sistemas capazes de realizar tarefas que 
												normalmente requerem inteligência humana. Isso inclui raciocínio, aprendizado, percepção, e interação.</li>
											<li><b><i>Machine Learning</i></b>: é  um subcampo da IA focado no desenvolvimento de algoritmos que permitem às máquinas aprender a partir de dados 
												e melhorar com a experiência. Em vez de serem explicitamente programadas para cada tarefa, as máquinas usam dados para identificar padrões e tomar decisões.</li>
											<li><b><i>Deep Learning</i></b>: é uma subárea de ML que utiliza Redes Neurais Artificiais (RNAs) com muitas camadas (profundas) para modelar e aprender representações 
												de dados complexos. DL tem sido particularmente eficaz em tarefas como reconhecimento de imagem, PLN e jogo autônomo.</li>
										</ol>
										<p class="lead mb-3 text-center" id="link-figura-03"><b>Figura 3</b> - Estreita relação entre inteligência artificial, <i>machine learning</i> e <i>deep learning</i></p>
												<div align="center">
													<span class="image fit" style="width: 70%;"><img src="images/Figura 3 - Estreita relação entre IA, ML e DL.png" alt="" /></span>
													<p class="lead mb-2 text-center"><small>Fonte: Adaptada de <a href="https://www.ufsm.br/app/uploads/sites/791/2021/05/img1.png">Medeiros, 2019</a>.</small></p>
												</div>
												<p><span class="image right" style="width: 25%;"><img src="Robozinho/roboCuriosoLapisRoxo.png" alt="" /></span></p>
													<div class="box2">
														<h3 class="mb-0" id="1-relembrar">Para relembrar…</h3>
														<p class="lead mb-3 text-justify"><font color="#19032B">&#10132 </font>ML é uma subárea da IA que desenvolve algoritmos capazes de aprender e melhorar a partir de dados, em vez de serem explicitamente programados.</p>
														<p class="lead mb-3 text-justify"><font color="#19032B">&#10132 </font>As aplicações de ML são vastas e incluem reconhecimento de imagem, PLN, sistemas de recomendação, previsão de mercado, veículos autônomos e diagnósticos médicos.</p>
														<p class="lead mb-3 text-justify"><font color="#19032B">&#10132 </font>É crucial diferenciar entre IA, ML e DL: IA é o campo geral que busca criar sistemas inteligentes; ML é uma subárea de IA focada em algoritmos de 
															aprendizado a partir de dados; e DL é uma subárea de ML que utiliza Redes Neurais Profundas (DL) para modelar dados complexos. Juntos, esses conceitos formam a base para a compreensão e aplicação de tecnologias inteligentes em diversas áreas.</p>
														</div>
														<p><span class="image left" style="width: 25%;"><img src="Robozinho/roboCuriosoLupaRoxoEsquerda.png" alt="" /></span></p>
													<div class="box3">
														<h3 class="mb-0" id="uni1-saiba-mais">Saiba mais…</h3>
													<ul class="lead mb-3 text-justify indent">
														<li>Artigo: "<a href="https://www.ibm.com/topics/machine-learning"><i>What is machine learning</i>?</a>" (IBM). Um artigo introdutório que explica o que é ML, como funciona e onde é aplicado.</li>
														<li>Artigo: "<a href="https://machinelearningmastery.com/a-tour-of-machine-learning-algorithms/"><i>A tour of machine learning algorithms</i></a>", de Jason Brownlee (<i>Machine Learning Mastery</i>). 
															Um artigo abrangente que descreve diferentes tipos de algoritmos de ML, suas características e aplicações.</li>
													</ul>	
													</div>
									
								</section>
										
								<hr class="m-0">
								<section>
									<div class="image main" id="capa_uni2">
										<img src="images/6. Unidade_2_Introdução a Machine Learning e Redes Neurais.png" alt="">
									</div>
									</section>
									<hr class="m-0">
									<section class="resume-section p-3 p-lg-5 d-flex align-items-center" id="uni1">
										<header class="main">
											<div class="w-100">
												<h1 class="mb-0" id="uni2">Unidade II - Detecção, reconhecimento e previsão</h1>
											</div></header>
										<h2 class="mb-0" id="uni2-1">2.1 Detecção de padrões e anomalias</h2>
										<p class="lead mb-3 text-justify indent">A detecção de padrões e anomalias é uma das principais tarefas no pré-processamento de dados e uma aplicação crucial em ML. Identificar padrões envolve encontrar regularidades ou estruturas repetitivas nos dados. No contexto de reconhecimento de padrões, "regularidades" ou "estruturas repetitivas" referem-se a padrões recorrentes e consistentes que podem ser identificados em conjuntos de dados. Essas regularidades são fundamentais para o aprendizado de máquina e o reconhecimento de padrões porque fornecem a base para a criação de modelos que podem generalizar para novos dados. Esses padrões recorrentes podem se manifestar como correlações entre variáveis, tendências ao longo do tempo, ou agrupamentos de dados com características semelhantes. Uma vez encontrados esses padrões, eles podem ser usados para criar modelos que façam previsões ou classifiquem novos dados. Exemplos de regularidades incluem:</p>
										<ol style="margin-left: 1cm;" class="lead mb-3 text-justify indent">
											<li><b>Séries temporais</b>: em dados de séries temporais, como medições de temperatura ao longo do tempo, uma regularidade pode ser uma tendência de aumento ou diminuição. Padrões sazonais, como aumento de vendas de determinados produtos durante feriados, também são estruturas repetitivas.</li>
											<li><b>Imagens</b>: no reconhecimento de imagens, estruturas repetitivas podem ser características como bordas, texturas ou formas específicas que aparecem consistentemente em imagens de um determinado objeto ou classe de objetos.</li>
											<li><b>Texto</b>: em NLP, podem ser frequências de palavras, padrões de coocorrência de palavras, ou estruturas sintáticas que aparecem repetidamente em um corpus de texto.</li>
											<li><b>Dados tabulares</b>: em dados de clientes, por exemplo, podem ser comportamentos de compra, como a tendência de certos grupos demográficos a comprar produtos específicos. Padrões de uso, como horários de acesso a um serviço, também são estruturas repetitivas.</li>
										</ol>
										<p class="lead mb-3 text-justify indent">Como já discutimos, a identificação de regularidades ou estruturas repetitivas nos dados é fundamental para o reconhecimento de padrões. Essas regularidades são a base sobre a qual modelos de aprendizado são construídos, permitindo que os sistemas façam previsões, classifiquem dados e tomem decisões informadas. A seguir, citamos 3 situações em que a identificação de regularidades é aplicada:</p>
										<ol style="margin-left: 1cm;" class="lead mb-3 text-justify indent">
											<li><b>Modelagem</b>: identificar regularidades permite a criação de modelos que capturam relações consistentes. Por exemplo, um modelo de regressão linear pode capturar a relação entre a temperatura e a demanda por eletricidade.</li>
											<li><b>Generalização</b>: modelos que capturam regularidades nos dados de treinamento são capazes de generalizar para novos dados. Isso significa que o modelo pode fazer previsões precisas ou categorizações baseadas em dados não vistos, pois as regularidades subjacentes continuam presentes.</li>
											<li><b>Redução de ruído</b>: identificar estruturas repetitivas ajuda a separar os sinais relevantes do ruído 
												nos dados. Isso permite que os modelos de reconhecimento de padrões se concentrem nas informações importantes e 
												ignorem variações aleatórias, frequentemente chamadas de <i>outliers</i>.</li>
										</ol>
										<p class="lead mb-3 text-justify indent">Anomalias, por outro lado, são dados que não seguem o comportamento esperado ou padrão (veja Figura 4). Detectar anomalias é essencial para identificar erros, fraudes ou eventos raros. Por exemplo, na detecção de fraudes em transações financeiras, um sistema de ML pode aprender os padrões normais de gastos de um usuário e detectar transações que não se encaixam nesses padrões. Em manutenção preditiva, anomalias podem indicar falhas iminentes em máquinas ou equipamentos, permitindo intervenções antes que ocorram falhas catastróficas.</p>
										<p class="lead mb-3 text-center" id="link-figura-04"><b>Figura 4</b> - Série temporal com dados normais e uma anomalia em destaque</p>
												<div align="center">
													<span class="image fit" style="width: 70%;"><img src="images/Figura 4 - Série temporal com dados normais e uma anomalia em destaque.png" alt="" /></span>
													<p class="lead mb-2 text-center"><small>Fonte: Adaptada de <a href="https://miro.medium.com/v2/resize:fit:697/1*O3lOgPwuHP7Vfc1T6NDRrQ.png">Pandya, Jadeja, Degadwala, 2022</a>.</small></p>
												</div>
										<h2 class="mb-0" id="uni2-2">2.2 Detecção, Previsão e Reconhecimento</h2>
										<p class="lead mb-3 text-justify indent">Em ML, os termos "detecção", "reconhecimento" e "previsão" referem-se a diferentes tipos de tarefas que os algoritmos podem executar. Cada um desses conceitos tem suas próprias características e aplicações específicas. Exploramos cada um deles em detalhes no Quadro 1.</p>
										<p class="lead mb-3 text-center" id="link-quadro-01"><b>Quadro 1</b> - Detecção, Previsão e Reconhecimento de <i>Machine Learning</i></p>
												<div align="center">
													<span class="image fit" style="width: 70%;"><img src="images/Quadro 1 .1- Detecção, Previsão e Reconhecimento de Machine Learning.png" alt="" /></span>
													<span class="image fit" style="width: 70%;"><img src="images/Quadro 1.2 - Detecção, Previsão e Reconhecimento de Machine Learning.png" alt="" /></span>
													<span class="image fit" style="width: 70%;"><img src="images/Quadro 1.3 - Detecção, Previsão e Reconhecimento de Machine Learning.png" alt="" /></span>
													<p class="lead mb-2 text-center"><small>Fonte: Autoria própria.</small></p>
												</div>
										<p class="lead mb-3 text-justify indent">Para sintetizar essas diferenças, abaixo, na Tabela 1, estão estruturadas as características de cada abordagem.</p>
										<p class="lead mb-3 text-center" id="link-tabela-01"><b>Tabela 1</b> - Comparativo entre problemas de detecção, reconhecimento e previsão</p>
										<div align="center">
											<span class="image fit" style="width: 70%;"><img src="images/Tabela1.png" alt="" /></span>
											<p class="lead mb-2 text-center"><small>Fonte: Autoria própria.</small></p>
										</div>
										<p><span class="image right" style="width: 25%;"><img src="Robozinho/roboCuriosoLapisRoxo.png" alt="" /></span></p>
										<div class="box2">
											<h3 class="mb-0" id="2-relembrar">Para relembrar…</h3>
											<p class="lead mb-3 text-justify"><font color="#19032B">&#10132 </font>No pré-processamento de dados, a detecção de padrões e anomalias desempenha um papel crucial, permitindo identificar regularidades e <i>outliers</i> nos dados.</p>
											<p class="lead mb-3 text-justify"><font color="#19032B">&#10132 </font>As tarefas de detecção, reconhecimento e previsão são fundamentais em ML, ajudando a identificar a presença de características específicas, reconhecer entidades e prever resultados futuros.</p>
											<p class="lead mb-3 text-justify"><font color="#19032B">&#10132 </font>Essas tarefas são aplicadas em diversas áreas, desde a detecção de fraudes até a previsão de demanda, e são essenciais para a criação de modelos de ML precisos e confiáveis.</p>
											</div>
											<p><span class="image left" style="width: 25%;"><img src="Robozinho/roboCuriosoLupaRoxoEsquerda.png" alt="" /></span></p>
										<div class="box3">
											<h3 class="mb-0" id="uni2-saiba-mais">Saiba mais…</h3>
										<ul class="lead mb-3 text-justify indent">
											<li><a href="https://towardsdatascience.com/">Artigos sobre diversos tópicos em ciência de dados e <i>machine learning</i></a>.</li>
											<li><a href="https://distill.pub/">Um site que explora conceitos complexos de <i>machine learning</i> de forma visual e intuitiva</a>.</li>
										</ul>	
										</div>
									
									</section>
										<hr class="m-0">
									<section>
										<div class="image main" id="capa_uni3">
											<img src="images/6. Unidade_3_Introdução a Machine Learning e Redes Neurais.png" alt="">
										</div>
										</section>
										<hr class="m-0">
										<section class="resume-section p-3 p-lg-5 d-flex align-items-center" id="uni1">
											<header class="main">
												<div class="w-100">
													<h1 class="mb-0" id="uni3">Unidade III - Reconhecimento de padrões</h1>
												</div></header>
												<h2 class="mb-0" id="uni3-1">3.1 O que é reconhecimento?</h2>
												<p class="lead mb-3 text-justify indent">Reconhecimento é o processo de identificar ou perceber algo que já é conhecido ou familiar. Já o reconhecimento de padrões é definido por Theodoridis & Koutroumbas (2009) como a ciência do estudo da organização dos dados e pode ser realizada a partir de objetos representados em diversos tipos de dados como textos, áudios, sinais, vídeos, entre outros.</p>
												<p class="lead mb-3 text-justify indent">No contexto de ML e IA, reconhecimento refere-se à capacidade dos sistemas computacionais de identificar padrões específicos, objetos ou entidades em dados que correspondem a exemplos previamente aprendidos. Isso pode incluir: reconhecimento de imagens, onde um sistema identifica objetos ou pessoas em uma foto; reconhecimento de fala, onde uma máquina entende palavras e frases faladas; e reconhecimento de texto, onde um sistema identifica e extrai informações de documentos escritos. O processo de reconhecimento é fundamental para diversas aplicações, onde a habilidade de perceber semelhanças, mesmo na presença de variações, é crucial para o funcionamento eficaz do sistema.</p>
												<p class="lead mb-3 text-justify indent">Abaixo listamos alguns exemplos de aplicações do processo de reconhecimento de padrões:</p>
												<ul style="margin-left: 1cm;" class="lead mb-3 text-justify indent">
													<li><b>Reconhecimento facial</b>: sistemas que identificam indivíduos com base em características faciais que são semelhantes aos rostos presentes em um banco de dados, mesmo que haja pequenas variações como ângulos diferentes ou mudanças na expressão facial (Figura 5).</li>
													<li><b>Reconhecimento de voz</b>: assistentes virtuais que compreendem e respondem a comandos de voz ao identificar padrões de fala semelhantes aos exemplos treinados, mesmo que a entonação ou o ritmo da fala variem.</li>
													<li><b>Reconhecimento de texto</b>: ferramentas que extraem informações relevantes de documentos ao identificar padrões de letras e palavras semelhantes aos treinados em sistemas Reconhecimento Óptico de Caracteres (OCR), mesmo que a fonte ou a formatação do texto seja diferente.</li>
												</ul>
												<p class="lead mb-3 text-center" id="link-figura-05"><b>Figura 5</b> - Exemplo de reconhecimento de face</p>
										<div align="center">
											<span class="image fit" style="width: 50%;"><img src="images/Figura 5 - Exemplo de reconhecimento de face.jpg" alt="" /></span>
											<p class="lead mb-2 text-center"><small>Fonte: Banco de imagens Canva.</small></p>
										</div>
												<h3 class="mb-0" id="uni3-1-1">3.1.1 Treinamento de modelos</h3>
												<p class="lead mb-3 text-justify indent">Mas você deve estar pensando: na prática, como ocorre o reconhecimento de algo? Vamos detalhar todo esse processo mas, descrevendo de uma forma direta, em ML, o reconhecimento é realizado por meio da aproximação de um modelo previamente treinado.</p>
												<p class="lead mb-3 text-justify indent">De forma simples, um modelo em ML é um conjunto de regras ou um sistema matemático que foi produzido durante a etapa de treinamento para fazer previsões ou tomar decisões com base em dados. Pense nele como uma fórmula que aprende a partir de exemplos fornecidos e é capaz de aplicar esse aprendizado a novos dados.</p>
												<p class="lead mb-3 text-justify indent">Para reconhecer novos dados, o sistema utiliza o modelo que foi treinado com dados conhecidos. Durante o treinamento, o modelo aprende a identificar padrões e características nos dados de entrada. Quando um novo dado é apresentado, o modelo compara esse dado com os padrões aprendidos e faz uma previsão ou classificação com base na similaridade. E essa similaridade é uma medida numérica de quão parecidos dois itens são entre si, determinando o grau de semelhança entre eles.</p>
												<p class="lead mb-3 text-justify indent">Por exemplo, em reconhecimento facial, um modelo é treinado com milhares de imagens de rostos diferentes. O modelo aprende as características faciais, como a distância entre os olhos, a forma do nariz e a linha do queixo. Quando uma nova imagem de rosto é apresentada, o modelo analisa essas características e tenta encontrar uma correspondência com os rostos conhecidos.</p>
												<p class="lead mb-3 text-justify indent">Os modelos são treinados com grandes volumes de dados históricos, e é essa quantidade de informação que torna possível fazer previsões e identificar padrões em novos dados.</p>
												<p class="lead mb-3 text-justify indent">Agora que você sabe o que é e como é realizado o reconhecimento, vamos introduzir o próximo conceito: padrões.</p>
												<h2 class="mb-0" id="uni3-2">3.2 Padrões</h2>
												<p class="lead mb-3 text-justify indent">Padrão, em um primeiro momento, pode ser entendido como uma sequência ou grupo de fenômenos que se repetem em forma, comportamento, frequência, etc. Entretanto, no contexto de ML, o padrão tem outro significado. Vamos entender o padrão e outros conceitos que permearão todo o curso.</p>
												<p class="lead mb-3 text-justify indent">Um padrão é uma descrição quantitativa ou estrutural de um objeto que permite identificar e reconhecer características recorrentes dentro de um conjunto de dados. O que antes poderíamos chamar de padrão, na verdade, chamamos de similaridade: explicando melhor, quando observamos algo que se repete de forma parecida, vemos uma similaridade de padrões; isso porque os padrões, no contexto de ML, são agrupamentos de valores de características dos objetos dessa observação; e quando dizemos que há uma similaridade entre esses padrões quer dizer que os valores das características desses objetos tendem a ser próximos.</p>
												<p class="lead mb-3 text-justify indent">Abaixo listamos situações em que podemos observar similaridade de valores e/ou comportamentos:</p>
												<ul style="margin-left: 1cm;" class="lead mb-3 text-justify indent">
													<li><b>numérico</b>: Sequências de números que seguem uma determinada regra, como a sequência de Fibonacci.</li>
													<li><b>visual</b>: Formas ou cores recorrentes em imagens, como a estrutura de folhas de uma planta ou características faciais em fotos.</li>
													<li><b>comportamental</b>: Ações ou eventos que ocorrem repetidamente, como hábitos de compra de consumidores.</li>
												</ul>
												<h3 class="mb-0" id="uni3-2-1">3.2.1 Arranjos de padrões</h3>
												<p class="lead mb-3 text-justify indent">Em todas essas situações descritas nos exemplos anteriores, as observações podem ser representadas por meio de um conjunto de valores, organizados em arranjos de padrões (Bishop, 2006), ou seja, estruturas de dados com valores de características (Theodoridis & Koutroumbas, 2009). Uma vez representadas em forma de arranjos de padrões, essas observações podem ser categorizadas em classes de padrões conforme suas propriedades em comum. E esse é um dos objetivos do reconhecimento de padrões: agrupar observações similares, baseado no valor de suas características.</p>
												<p class="lead mb-3 text-justify indent">Na prática, os padrões podem ser organizados de várias maneiras, dependendo das características e da natureza dos dados. Dois dos principais arranjos de padrões são vetores e descrições estruturais como cadeias e árvores:</p>
												<p class="lead mb-3 text-justify indent">Vetores são descrições quantitativas dos objetos, representando os dados em uma forma numérica e ordem fixa. Possuem 2 características principais:</p>
												<ul style="margin-left: 1cm;" class="hollow-circle lead mb-3 text-justify indent">
													<li><b>Dimensões</b>: cada vetor possui várias dimensões ou atributos, que são as características mensuráveis do objeto.</li>
													<li><b>Espaço vetorial</b>: os vetores são representados em um espaço multidimensional onde cada dimensão corresponde a um atributo.</li>
												</ul>
												<p class="lead mb-3 text-justify indent">Abaixo listamos alguns exemplos de tipos de dados e suas respectivas formas de representação em forma de vetor:</p>
												<ul style="margin-left: 1cm;" class="hollow-circle lead mb-3 text-justify indent">
													<li><b>Imagem</b>: um vetor pode representar os valores de intensidade de pixel de uma imagem.</li>
													<li><b>Texto</b>: um vetor de frequência de palavras, onde cada dimensão representa a contagem de uma palavra específica no texto.</li>
													<li><b>Áudio</b>: um vetor de características como frequência, amplitude e duração.</li>
												</ul>
												<p class="lead mb-3 text-justify indent">A Figura 6 ilustra o processo de criação de um vetor de 4 características a partir de uma imagem de uma íris.</p>
												<p class="lead mb-3 text-center" id="link-figura-06"><b>Figura 6</b> - Extração de características de uma imagem de íris</p>
										<div align="center">
											<span class="image fit" style="width: 70%;"><img src="images/Figura 6 - Extração de características de uma imagem de íris.png" alt="" /></span>
											<p class="lead mb-2 text-center"><small>Fonte: Adaptada de <a href="https://www.mdpi.com/sensors/sensors-21-07408/article_deploy/html/images/sensors-21-07408-g002-550.jpg">Khade <i>et al</i>., 2021</a>.</small></p>
										</div>
										<p class="lead mb-3 text-justify indent">Cadeias e árvores são descrições estruturais que capturam a relação entre diferentes partes dos dados. Cadeias são sequências lineares de elementos conectados de forma ordenada, por exemplo:</p>
										<ul style="margin-left: 1cm;" class="hollow-circle lead mb-3 text-justify indent">
											<li><b>Texto</b>: cadeias de caracteres ou palavras em uma frase.</li>
											<li><b>DNA</b>: sequências de nucleotídeos (Figura7).</li>
										</ul>
												<p class="lead mb-3 text-center" id="link-figura-07"><b>Figura 7</b> - Sequência de ácido desoxirribonucleico (DNA)</p>
										<div align="center">
											<span class="image fit" style="width: 70%;"><img src="images/Figura 7 - Sequência de DNA.png" alt="" /></span>
											<p class="lead mb-2 text-center"><small>Fonte: Adaptada de <a href="https://blog.mendelics.com.br/wp-content/uploads/2021/10/Sequenciamento-Sanger-Capa.png">Mendelikes, 2023</a>.</small></p>
										</div>
												<p class="lead mb-3 text-justify indent">Árvores são estruturas hierárquicas onde os dados são organizados em nós, com um nó raiz e ramificações para outros nós, por exemplo:</p>
												<ul style="margin-left: 1cm;" class="hollow-circle lead mb-3 text-justify indent">
													<li><b>Árvores de decisão</b>: utilizadas em algoritmos de classificação e regressão.</li>
													<li><b>Estruturas de dados</b>: árvores binárias utilizadas em bancos de dados e algoritmos de busca.</li>
												</ul>
												<p class="lead mb-3 text-justify indent">A Figura 8 ilustra um algoritmo de recomendação de tipo de carro baseado na composição familiar e preferências do usuário.</p>
												<p class="lead mb-3 text-center" id="link-figura-08"><b>Figura 8</b> - Árvore de decisão para escolha de um carro</p>
										<div align="center">
											<span class="image fit" style="width: 70%;"><img src="images/Figura 8 - Árvore de decisão para escolha de um carro.png" alt="" /></span>
											<p class="lead mb-2 text-center"><small>Fonte: Adaptada de <a href="https://miro.medium.com/v2/resize:fit:1400/1*sAXOZrFTYFhRce3LfNjxJA.png">Araujo, 2020</a>.</small></p>
										</div>
												<h3 class="mb-0" id="uni3-2-2">3.2.2 Objetos e características</h3>
												<p class="lead mb-3 text-justify indent">Note que usamos o termo “observações” para se referir aos exemplos dados nas seções. Entretanto, vamos introduzir o termo usual: objeto. Um objeto em reconhecimento de padrões é uma entidade ou unidade de dados que possui características específicas (Mitchell, 1997) que podem ser analisadas para identificar regularidades. Esses objetos podem ser imagens, textos, sons, ou qualquer outra forma de dados estruturados ou não estruturados.</p>
												<p class="lead mb-3 text-justify indent">Explicando melhor, as características são propriedades mensuráveis ou categóricas de um objeto (Mitchell, 1997), como cor, forma, intensidade de pixel (em imagens), palavras ou frases (em textos), frequência e amplitude (em sinais de áudio). E quando falamos de classes (de padrões), estamos nos referindo a um grupo de objetos ou dados que possuem características ou atributos semelhantes. Esses padrões são agrupados porque compartilham propriedades que os tornam similares entre si. A seguir listamos alguns exemplos dessas propriedades nos diferentes domínios  de imagem, texto e áudio:</p>
												<ul style="margin-left: 1cm;" class="lead mb-3 text-justify indent">
													<li><b>Imagem:</b></li>
													<ul class="hollow-circle lead mb-3 text-justify indent">
														<li><b>Cor</b>: representada por valores de cores <i>Red, Green and Blue (RGB), Hue, 
															Saturation and Value</i> (HSV) e etc. que indicam as cores vemelho, verde e azul e a tonalidade, saturação e brilho.</li>
														<li><b>Forma</b>: contornos e geometria que definem a estrutura de objetos, como círculos, quadrados ou polígonos.</li>
														<li><b>Intensidade de Pixel</b>: valores de brilho ou intensidade em cada pixel da imagem, que podem ser usados para detectar contrastes e detalhes.</li>
														<li><b>Textura</b>: padrões e variações na intensidade de pixel que indicam a superfície e a aparência de um objeto.</li>
													</ul>
													<li><b>Texto:</b></li>
													<ul class="hollow-circle lead mb-3 text-justify indent">
														<li><b>Palavras</b>: conjuntos de letras ou caracteres que formam unidades de significado.</li>
														<li><b>Frases</b>: agrupamentos de palavras que constroem sentenças com significado completo.</li>
														<li><b>Repetições</b>: palavras ou termos que aparecem repetidamente em um texto, úteis para análise de tópicos ou sentimentos.</li>
													</ul>
													<li><b>Áudio:</b></li>
													<ul class="hollow-circle lead mb-3 text-justify indent">
														<li><b>Frequência</b>: número de ciclos por segundo de uma onda sonora, medida em Hertz (Hz), essencial para identificar notas musicais e timbres.</li>
														<li><b>Amplitude</b>: intensidade ou volume da onda sonora, que determina a percepção de volume e potência do som.</li>
														<li><b>Tempo</b>: duração dos sons ou intervalos entre eventos sonoros, relevante para a análise de ritmo e tempo.</li>
													</ul>
												</ul>
												<h3 class="mb-0" id="uni3-2-3">3.2.3 Classes</h3>
												<p class="lead mb-3 text-justify indent">Uma classe é um rótulo ou categoria que define um grupo de objetos ou instâncias que compartilham características ou atributos comuns. As classes são usadas principalmente em tarefas de classificação, onde o objetivo é atribuir um rótulo de classe a uma nova instância com base em suas características.</p>
												<p class="lead mb-3 text-justify indent">Quando pretendemos determinar quais objetos pertencem à mesma classe, o compartilhamento dessas propriedades, características ou atributos similares muda conforme contexto que o algoritmo está atuando, por exemplo:</p>
												<ul style="margin-left: 1cm;" class="lead mb-3 text-justify indent">
													<li><b>Imagens de gatos</b>: têm propriedades comuns como orelhas pontudas, olhos grandes e pelos macios.</li>
													<li><b>Textos sobre tecnologia</b>: compartilham termos e jargões técnicos, como "algoritmo", IA e ML.</li>
													<li><b>Músicas</b>: podem ter frequências, ritmos e estruturas semelhantes.</li>
												</ul>
												<p class="lead mb-3 text-justify indent">Na Figura 9, utilizamos um exemplo de representação dos objetos em um espaço vetorial e podemos entender como encontramos similaridade entre objetos baseado na proximidade de suas características. É possível identificar que se trata de um plano 3 Dimensões (3D): isso significa que cada objeto é representado por um vetor de características com 3 valores quaisquer. Também temos 3 agrupamentos de objetos e dizemos que estes pertencem a uma das classes: quadrado, triângulo ou círculo. Em cada uma dessas classes, os objetos estão mais próximos entre si do que de objetos de outras classes. Como esses objetos são representados por vetores com 3 valores, cada um deles indica um ponto no plano 3D. A partir desses pontos podemos calcular a distância entre eles e determinar quais estão mais próximos e, portanto, pertencem à mesma classe. Essa é uma das muitas formas de se reconhecer padrões e veremos algumas delas durante o curso. O objetivo de mostrar esse cenário é apresentar conceitos importantes que são aplicados em quaisquer algoritmos de ML. Vamos relembrá-los:</p>
											
												<p class="lead mb-3 text-center" id="link-figura-09"><b>Figura 9</b> - Disposição de objetos em um espaço vetorial de três dimensões</p>
										<div align="center">
											<span class="image fit" style="width: 70%;"><img src="images/Figura 9 - Disposição de objetos em um espaço vetorial de 3 dimensões.png" alt="" /></span>
											<p class="lead mb-2 text-center"><small>Fonte: Adaptada de <a href="https://media.springernature.com/lw685/springer-static/image/chp%3A10.1007%2F978-3-642-53751-6_44/MediaObjects/321332_1_En_44_Fig2_HTML.gif">Lu, Wu, Kita, 2014</a>.</small></p>
										</div>
												<ul style="margin-left: 1cm;" class="lead mb-3 text-justify indent">
													<li><b>Objetos</b>: entidades ou instâncias de dados que possuem propriedades específicas e podem ser definidos em diferentes contextos, como imagens, textos, áudios, entre outros.</li>
													<li><b>Características</b>: propriedades ou atributos mensuráveis que descrevem os objetos e permitem diferenciá-los uns dos outros.</li>
													<li><b>Classes</b>: grupos ou conjuntos de objetos que compartilham um conjunto comum de características ou atributos. Representam categorias ou tipos específicos de objetos.</li>
												</ul>
												<p class="lead mb-3 text-justify indent">A Figura 10 exemplifica o caso de vários objetos de uma mesma classe Carro. Apesar de possuírem diferenças entre si, compartilham de um mesmo conjunto de características como quantidade de rodas, presença de farol, capacidade de passageiros, velocidade máxima, entre outras, mesmo com valores diferentes para cada uma dessas características.</p>
												<p class="lead mb-3 text-center" id="link-figura-10"><b>Figura 10</b> - Imagem de classe, objeto e característica</p>
												<div align="center">
													<span class="image fit" style="width: 70%;"><img src="images/Figura 10 - Imagem de classe, objeto e característica_.png" alt="" /></span>
													<p class="lead mb-2 text-center"><small>Fonte: Adaptada de <a href="https://www.scaler.com/topics/images/difference-between-class-and-object_thumbnail.webp">Scaler, 2024</a>.</small></p>
												</div>
												<p class="lead mb-3 text-justify indent">Abaixo, na Tabela 2, listamos alguns exemplos de classes e objetos. Esses exemplos ilustram como objetos diferentes podem compartilhar características semelhantes que os agrupam na mesma classe.</p>
												<p class="lead mb-3 text-center" id="link-tabela-02"><b>Tabela 2</b> - Exemplos de classes e objetos pertencentes a elas</p>
												<div align="center">
													<span class="image fit" style="width: 70%;"><img src="images/Tabela 2.png" alt="" /></span>
													<p class="lead mb-2 text-center"><small>Fonte: Autoria própria.</small></p>
												</div>
												<p class="lead mb-3 text-justify indent">Para que ocorra o reconhecimento de padrões com o objetivo de agrupar ou categorizar esses objetos, são necessárias algumas etapas a serem seguidas descritas na Figura 11:</p>
												<ul style="margin-left: 1cm;" class="lead mb-3 text-justify indent">
													<li><b>Pré-processamento</b>: preparação dos objetos para análise, como normalização e remoção de ruído (conceitos que discutiremos adiante), e extração de características relevantes.</li>
													<li><b>Seleção de características</b>: identificação das propriedades mais significativas dos objetos que ajudarão na análise e reconhecimento.</li>
													<li><b>Classificação e agrupamento</b>: uso de algoritmos para classificar ou agrupar os objetos com base nas características extraídas.</li>
												</ul>
												<p class="lead mb-3 text-center" id="link-figura-11"><b>Figura 11</b> - Processo de reconhecimento de padrões em <i>machine learning</i></p>
												<div align="center">
													<span class="image fit" style="width: 70%;"><img src="images/Figura 11 - Processo de reconhecimento de padrões em ML_.png" alt="" /></span>
													<p class="lead mb-2 text-center"><small>Fonte: Adaptada de <a href="https://paginas.fe.up.pt/~jmsa/recpad/rec_pa2.gif">Marquês de Sá, 2000</a>.</small></p>
												</div>
												<p class="lead mb-3 text-justify indent">Então, resumindo, até agora aprendemos que em ML trabalhamos técnicas de reconhecimento de padrões, ou seja, podemos categorizar ou agrupar objetos em classes por meio da similaridade de suas características representadas em vetores de dados (padrões).</p>
												<p class="lead mb-3 text-justify indent">Falaremos com mais detalhes sobre os tipos de algoritmos de aprendizagem de máquina e sobre o espaço vetorial, também conhecido como espaço de características nas próximas unidades.</p>
												<p><span class="image right" style="width: 25%;"><img src="Robozinho/roboCuriosoLapisRoxo.png" alt="" /></span></p>
												<div class="box2">
													<h3 class="mb-0" id="3-relembrar">Para relembrar…</h3>
													<p class="lead mb-3 text-justify"><font color="#19032B">&#10132 </font>O reconhecimento em ML refere-se à habilidade de identificar e categorizar objetos ou padrões com base em características previamente aprendidas. Este processo envolve a percepção de semelhanças entre os novos dados e os modelos já treinados, utilizando inferência baseada em conceitos aprendidos no passado. Em termos práticos, isso significa que o sistema de reconhecimento pode identificar rostos em imagens, detectar palavras em áudios ou classificar textos em categorias específicas, dependendo dos dados de treinamento e das características extraídas.</p>
													<p class="lead mb-3 text-justify"><font color="#19032B">&#10132 </font>Além disso, discutimos a importância das propriedades ou características mensuráveis dos objetos, como cor, forma e intensidade de pixel em imagens, palavras ou frases em textos, e frequência e amplitude em sinais de áudio. Esses atributos são essenciais para a análise e classificação de dados. Também abordamos os principais arranjos de padrões utilizados na prática, como vetores para descrições quantitativas e cadeias e árvores para descrições estruturais.</p>
												</div>
												
												<p><span class="image left" style="width: 25%;"><img src="Robozinho/roboCuriosoLupaRoxoEsquerda.png" alt="" /></span></p>
												<div class="box3">
													<h3 class="mb-0" id="uni3-saiba-mais">Saiba mais…</h3>
												<ul class="lead mb-3 text-justify indent">
													<li><a href="https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf">
														Uma referência clássica para fundamentos em reconhecimento de padrões e aprendizado de máquinas</a>.</li>
													
													<li><a href="https://deepmind.google/">Site da Google DeepMind, que publica pesquisas inovadoras e artigos sobre avanços em IA, incluindo reconhecimento de padrões e previsão</a>.</li>
													
												</ul>	
												</div>
												
									</section>
											<hr class="m-0">
										<section>
											<div class="image main" id="capa_uni4">
												<img src="images/6. Unidade_4_Introdução a Machine Learning e Redes Neurais.png" alt="">
											</div>
										</section>
										<hr class="m-0">
										<section class="resume-section p-3 p-lg-5 d-flex align-items-center">
											<div class="w-100">
												<h1 class="mb-0" id="uni4">Unidade IV - Tipos de aprendizagem de máquina</h1>
											</div></header>
											
											<p class="lead mb-3 text-justify indent">Nesta unidade, vamos explorar os principais tipos de aprendizagem de máquina: supervisionada, não supervisionada, semi-supervisionada e por reforço. Vamos explicar cada um deles, utilizando metáforas para facilitar a compreensão, e apresentaremos exemplos para cada tipo.</p>
											<p class="lead mb-3 text-justify indent">No vasto campo da aprendizagem de máquina, conhecer os diferentes tipos de aprendizagem é crucial para aplicar a abordagem mais adequada a cada situação. Compreender as nuances entre a aprendizagem supervisionada, não supervisionada, semi-supervisionada e por reforço permite que você escolha a técnica que melhor se adapta aos dados disponíveis e ao problema que deseja resolver. Cada método possui suas próprias vantagens e limitações, e a escolha correta pode significar a diferença entre o sucesso e o fracasso de um projeto. Portanto, dominar esses conceitos não apenas aprimora sua capacidade de desenvolver soluções eficazes, mas também otimiza o uso dos recursos disponíveis, tornando suas análises e previsões mais precisas e eficientes.</p>
											<p class="lead mb-3 text-justify indent">Os diferentes tipos de aprendizagem de máquina possuem processos de treinamento distintos, refletindo suas abordagens únicas para lidar com dados. Vamos antecipar a diferença entre eles e discutiremos com mais detalhes cada um adiante.</p>
											<p class="lead mb-3 text-justify indent">Na aprendizagem supervisionada, o treinamento envolve dados rotulados que orientam o modelo para fazer previsões precisas. 
												A aprendizagem não supervisionada, por outro lado, busca descobrir padrões ocultos em dados não rotulados sem orientação explícita. A aprendizagem 
												semi-supervisionada combina ambos os métodos, utilizando um pequeno conjunto de dados rotulados e um grande conjunto de dados não rotulados para 
												melhorar a precisão. Já a aprendizagem por reforço envolve a interação contínua com um ambiente, onde o modelo aprende através de recompensas e punições. 
												Cada tipo de aprendizagem adapta-se a diferentes cenários e desafios, destacando a importância de entender suas características e aplicações específicas. 
												No mapa mental apresentado na Figura 12 sintetiza esses tipos de aprendizado.</p>
											<p class="lead mb-3 text-center" id="link-figura-12"><b>Figura 12</b> - Tipos de aprendizagem de máquina</p>
												<div align="center">
													<span class="image fit" style="width: 70%;"><img src="images/Figura 12 - Tipos de aprendizagem de máquina.png" alt="" /></span>
													<p class="lead mb-2 text-center"><small>Fonte: Autoria própria.</small></p>
												</div>
											<h2 class="mb-0" id="uni4-1">4.1 Aprendizagem Supervisionada</h2>
											<p class="lead mb-3 text-justify indent">Na aprendizagem supervisionada, o modelo é treinado com um conjunto de dados rotulados, ou seja, cada entrada possui uma saída correspondente. Em outras palavras, cada objeto utilizado no treinamento possui a informação sobre qual classe ele pertence. O objetivo é fazer com que o modelo aprenda a mapear entradas (arranjos de padrões) para saídas corretas (classes), permitindo que ele faça previsões sobre novos dados.</p>
											<p class="lead mb-3 text-justify indent">Para entender melhor, imagine que você está ensinando uma criança a reconhecer frutas. Você mostra a ela várias frutas (entradas) e diz o nome de cada uma (saídas). Com o tempo, a criança aprende a associar a aparência da fruta ao seu nome. Se você mostrar uma maçã vermelha ou uma verde, a criança dirá "maçã" pois ambas compartilham de características que as tornam similares entre si, mesmo sendo de variedades distintas, e as diferencia de outras frutas.</p>
											<p class="lead mb-3 text-justify indent">De forma simplifica, o processo de treinamento de um modelo utilizando aprendizagem supervisionada pode ser descrito em 4 passos na Figura 13:</p>
											<p class="lead mb-3 text-center" id="link-figura-13"><b>Figura 13</b> - Treinamento de um algoritmo de aprendizagem supervisionada</p>
												<div align="center">
													<span class="image fit" style="width: 70%;"><img src="images/Figura 13 - Treinamento de um algoritmo de aprendizagem supervisionada.png" alt="" /></span>
													<p class="lead mb-2 text-center"><small>Fonte: Autoria própria.</small></p>
												</div>
											<p class="lead mb-3 text-justify indent">A classificação de emails como spam ou não-spam é um outro exemplo clássico de um problema de aprendizagem supervisionada. O objetivo é criar um modelo de ML que possa classificar automaticamente emails recebidos em duas classes ou categorias: <b>spam</b> (e-mail indesejado) e <b>não-spam</b> (e-mail legítimo):</p>
											<ul style="margin-left: 1cm;" class="lead mb-3 text-justify indent">
												<li><b>Dados de entrada</b>: texto dos emails.</li>
												<li><b>Dados de saída</b>: rótulos indicando se o email é spam ou não-spam.</li>
												<li><b>Modelo</b>: algoritmo de classificação ex.: <i>Naive Bayes</i> e <i>Support Vector Machines</i> (SVM).</li>
											</ul>
												<h2 class="mb-0" id="uni4-2">4.2 Aprendizagem Não Supervisionada</h2>
												<p class="lead mb-3 text-justify indent">Na aprendizagem não supervisionada não há uma medida de resultado (Hastie <i>et al</i>., 2009), o modelo trabalha com dados não rotulados. O objetivo é encontrar padrões ou agrupamentos nos dados sem orientação explícita sobre o que procurar.</p>
												<p class="lead mb-3 text-justify indent">Na aprendizagem não supervisionada, não há uma medida de resultado, e o objetivo é descrever as associações e padrões entre um conjunto de medidas de entrada.</p>
												<p class="lead mb-3 text-justify indent">Pense em um biólogo em trabalho de campo para identificar espécies nativas. Ele não tem um mapa (rótulos), mas pode observar as árvores e plantas ao seu redor. Com o tempo, ele percebe que certas áreas da floresta têm árvores semelhantes e as agrupa mentalmente.</p>
												<p class="lead mb-3 text-justify indent">Com exceção dos dados não rotulados, as etapas para treinar um modelo utilizando um algoritmo de aprendizagem não supervisionado, em linhas gerais, são as mesmas do aprendizado supervisionado (Figura 14):</p>										
												<p class="lead mb-3 text-center" id="link-figura-14"><b>Figura 14</b> - Treinamento de um algoritmo de aprendizagem não supervisionada</p>
												<div align="center">
													<span class="image fit" style="width: 70%;"><img src="images/Figura 14.png" alt="" /></span>
													<p class="lead mb-2 text-center"><small>Fonte: Autoria própria.</small></p>
												</div>
												<p class="lead mb-3 text-justify indent">Imagine que uma empresa deseja entender melhor seus clientes para oferecer produtos e serviços mais direcionados. 
													Para isso, quer agrupar os clientes em segmentos de mercado distintos com base em suas características e comportamentos. Não se sabe quantos ou quais 
													serão os segmentos de mercado. Esse tipo de problema é conhecido como agrupamento (ou <i>clustering</i>). Essa abordagem permite à empresa entender melhor 
													seus clientes, resultando em estratégias mais eficazes e aumento da satisfação e lealdade do cliente:</p>
												<ul style="margin-left: 1cm;" class="lead mb-3 text-justify indent">
													<li><b>Dados de entrada</b>: informações sobre clientes (ex.: idade, renda, histórico de compras).</li>
													<li><b>Dados de saída</b>: agrupamentos de clientes com características semelhantes.</li>
													<li><b>Modelo</b>: algoritmo de clustering, ex.: <i>K-means</i> e <i>Density-Based Spatial Clustering of Applications with Noise</i> (DBSCAN).</li>
												</ul>
												<h2 class="mb-0" id="uni4-3">4.3 Aprendizagem Semi-Supervisionada</h2>
												<p class="lead mb-3 text-justify indent">A aprendizagem semi-supervisionada é um meio-termo entre a aprendizagem supervisionada e a não supervisionada (Chapelle <i>et al</i>., 2006). Ela utiliza uma pequena quantidade de dados rotulados e uma grande quantidade de dados não rotulados. O modelo aproveita os dados rotulados para aprender e, em seguida, refinar seu conhecimento com os dados não rotulados.</p>
												<p class="lead mb-3 text-justify indent">Imagine um estudante que recebe algumas respostas corretas de um professor (dados rotulados) e, em seguida, tenta completar o restante da tarefa por conta própria usando essas respostas como referência.</p>
												<p class="lead mb-3 text-justify indent">Nas etapas de treinamento, incluímos o treinamento inicial e rodadas de refinamento para melhorar a acurácia do modelo (Figura 15):</p>
												<p class="lead mb-3 text-center" id="link-figura-15"><b>Figura 15</b> - Treinamento de um algoritmo de aprendizagem semi-supervisionada</p>
												<div align="center">
													<span class="image fit" style="width: 70%;"><img src="images/Figura 15.png" alt="" /></span>
													<p class="lead mb-2 text-center"><small>Fonte: Adaptada de <a href="https://pt.vecteezy.com/arte-vetorial/11993726-elementos-infograficos-de-4-etapas-para-conteudo-diagrama-fluxograma-etapas-pecas-linha-do-tempo-fluxo-de-trabalho-grafico">Vecteezy, 2024</a>.</small></p>
												</div>
												<p class="lead mb-3 text-justify indent">Agora, veja a seguinte situação: imagine que temos uma coleção de documentos de texto de um fórum online onde os usuários discutem uma ampla variedade de tópicos. Queremos classificar esses documentos em categorias específicas, como "Tecnologia", "Saúde", "Educação", etc. No entanto, só temos rótulos para um pequeno subconjunto dos documentos (talvez apenas 10% do total), enquanto a maioria dos documentos não está rotulada. A quantidade de documentos rotulados é pequena, o que torna difícil treinar um modelo de classificação tradicional com bom desempenho. Temos uma grande quantidade de documentos não rotulados que, se utilizados corretamente, podem melhorar a performance do modelo. Entretanto, a variação nos tópicos discutidos nos documentos pode ser ampla, tornando a classificação mais complexa.</p>
												<ul style="margin-left: 1cm;" class="lead mb-3 text-justify indent">
													<li><b>Dados de entrada</b>: texto dos documentos.</li>
													<li><b>Dados de saída</b>: etiquetas indicando a categoria dos documentos (rotulados).</li>
													<li><b>Modelo</b>: algoritmo semi-supervisionado (ex.: <i>Semi-Supervised</i> SVM).</li>
												</ul>
												
												<h2 class="mb-0" id="uni4-4">4.4 Aprendizagem por reforço</h2>
												<p class="lead mb-3 text-justify indent">Na aprendizagem por reforço, o modelo aprende a tomar decisões ao interagir com um ambiente. 
													Ele recebe recompensas ou punições com base nas ações que realiza, e o objetivo é maximizar a recompensa total ao longo do tempo.  
													Em outras palavras, problemas de aprendizagem por reforço envolvem aprender o que fazer - como mapear situações para ações - de 
													modo a maximizar um sinal de recompensa numérica (Hastie <i>et al</i>., 2009). É muito utilizado em jogos, robótica e sistemas autônomos.</p>
												<p class="lead mb-3 text-justify indent">Pense que você deseja treinar um cão a buscar uma bola. Quando o cão traz a bola de volta, você o recompensa com um petisco (recompensa). Se ele corre na direção errada, você não entrega o petisco (punição). Com o tempo, o cão aprende a buscar a bola corretamente para ganhar mais petiscos.</p>
												<p class="lead mb-3 text-justify indent">As etapas do processo de treinamento no caso de aprendizagem por reforço seguem outra lógica em relação às demais (Figura 16):</p>
												<p class="lead mb-3 text-center" id="link-figura-16"><b>Figura 16</b> - Treinamento de um algoritmo de aprendizagem por reforço</p>
												<div align="center">
													<span class="image fit" style="width: 70%;"><img src="images/Figura 16.png" alt="" /></span>
													<p class="lead mb-2 text-center"><small>Fonte: Autoria própria</small></p>
												</div>
												<p class="lead mb-3 text-justify indent">Em um problema de aprendizagem por reforço aplicado a um jogo eletrônico de xadrez, o agente (um programa de IA) aprende a jogar xadrez interagindo com o ambiente (o tabuleiro de xadrez). O objetivo do agente é maximizar uma recompensa ao longo do tempo, que neste caso é ganhar a partida de xadrez. O agente é o jogador de xadrez controlado pelo algoritmo de aprendizagem por reforço. Esse agente deve aprender a tomar decisões sobre qual movimento fazer em cada estado do jogo. O ambiente é o próprio tabuleiro de xadrez e o estado atual do jogo, incluindo a posição de todas as peças e o histórico de movimentos. Cada estado representa uma configuração específica do tabuleiro de xadrez. Por exemplo, a posição inicial das peças no início do jogo é um estado, e qualquer configuração resultante de uma série de movimentos subsequentes também é um estado. As ações são todos os movimentos válidos que o agente pode fazer a partir de um determinado estado. No xadrez, isso inclui movimentar qualquer peça para qualquer posição permitida pelas regras do jogo. Por fim, a recompensa é um valor numérico que o agente recebe após realizar uma ação. No xadrez, uma recompensa positiva pode ser atribuída para capturar uma peça adversária, colocar o rei adversário em xeque-mate, ou ganhar a partida. Recompensas negativas podem ser atribuídas para perder uma peça, colocar o próprio rei em xeque, ou perder a partida:</p>
											<ul style="margin-left: 1cm;" class="lead mb-3 text-justify indent">
												<li><b>Dados de entrada</b>: estado atual do tabuleiro.</li>
												<li><b>Dados de saída</b>: ação do agente (ex.: movimento de uma peça).</li>
												<li><b>Modelo</b>: algoritmo de aprendizagem por reforço (ex.: <i>Q-Learning, Deep Q-Network</i>).</li>
											</ul>
											<p><span class="image right" style="width: 25%;"><img src="Robozinho/roboCuriosoLupaRoxoEsquerda.png" alt="" /></span></p>
											<div class="box2">
												<h3 class="mb-0" id="uni4-saiba-mais">Saiba mais…</h3>
											
												<p class="lead mb-3 text-justify"><a href="https://www.researchgate.net/publication/43121576_A_Review_of_Machine_Learning_Algorithms_for_Text-Documents_Classification">
													<font color="#19032B">&#10132 </font>Artigo que revisa várias técnicas de aprendizagem de máquina aplicadas à classificação de documentos de texto</a>.</p>
												
												<p class="lead mb-3 text-justify"><a href="https://web.stanford.edu/class/psych209/Readings/SuttonBartoIPRLBook2ndEd.pdf">
													<font color="#19032B">&#10132 </font>Livro-texto fundamental para entender os conceitos e aplicações da aprendizagem por reforço</a>.</p>
										
											</div>
											<p><span class="image left" style="width: 25%;"><img src="Robozinho/roboCuriosoLapisRoxo.png" alt="" /></span></p>
											<div class="box3">
												<h3 class="mb-0" id="4-relembrar">Para relembrar…</h3>
												<p class="lead mb-3 text-justify"><font color="#19032B">&#10132 </font>Nesta unidade, abordamos os diferentes tipos de aprendizagem: supervisionada, não supervisionada, semi-supervisionada e por reforço. Para cada tipo, fornecemos uma explicação detalhada, metáforas para facilitar a compreensão e exemplos práticos. Discutimos também como os dados são manipulados e processados durante o treinamento de cada tipo de aprendizagem.</p>
												<p class="lead mb-3 text-justify"><font color="#19032B">&#10132 </font>Também destacamos a importância de conhecer as diferentes abordagens de aprendizagem de máquina para escolher a melhor técnica para cada situação específica. Enfatizamos que cada tipo de aprendizagem possui um processo de treinamento único, que varia desde o uso de dados rotulados na aprendizagem supervisionada até a interação contínua com um ambiente na aprendizagem por reforço. Compreender essas nuances é essencial para desenvolver soluções eficazes e precisas em ML, otimizando assim os recursos disponíveis e garantindo melhores resultados nos projetos.</p>
											</div>
											
										</section>
											<hr class="m-0">
											<section>
												<div class="image main" id="capa_uni5">
													<img src="images/6. Unidade_5_Introdução a Machine Learning e Redes Neurais.png" alt="">
												</div>
											</section>
											<hr class="m-0">
											<section class="resume-section p-3 p-lg-5 d-flex align-items-center">
												<div class="w-100">
												<h1 class="mb-0" id="uni5">Unidade V - Espaço de características</h1>
											</div></header>
											
											<h2 class="mb-0" id="uni5-1">5.1 Extração de características</h2>
											<p class="lead mb-3 text-justify indent">A extração de características é uma etapa fundamental no processo de aprendizado de máquina, onde informações relevantes são derivadas dos dados brutos. Este processo visa transformar dados complexos e volumosos em um conjunto de características mais manejável e significativo para a modelagem. Por exemplo, em imagens, características como bordas, texturas e formas podem ser extraídas para facilitar a detecção ou o reconhecimento.</p>
											<p class="lead mb-3 text-justify indent">As características extraídas devem capturar a essência dos dados, preservando as informações críticas 
												necessárias para as tarefas de análise subsequentes. Técnicas como Histogramas de Gradientes Orientados (HOG) para imagens, 
												<i>Term Frequency-Inverse Document Frequency</i> (TF-IDF) para textos, e <i>Mel-Frequency Cepstral Coefficients</i> (MFCC) para áudios 
												são exemplos comuns de métodos de extração de características. Cada técnica é escolhida com base na natureza dos dados e 
												nos requisitos específicos da aplicação.</p>
											<p class="lead mb-3 text-justify indent">A extração manual de características é um processo no qual um especialista analisa os dados brutos para identificar e definir características relevantes que serão utilizadas em modelos de ML. Este processo exige um conhecimento profundo do domínio específico e das propriedades dos dados, permitindo ao especialista selecionar atributos significativos que capturam as informações mais importantes. Essas características, uma vez extraídas, são organizadas em um formato estruturado, facilitando a análise e o treinamento de algoritmos de aprendizado. A extração manual de características é essencial em muitos campos, pois garante que os modelos sejam treinados com base em dados bem definidos e altamente relevantes, aumentando assim a eficácia e a precisão das previsões. Falaremos mais sobre conjuntos de dados adiante.</p>
											<p class="lead mb-3 text-justify indent">Além disso, a extração de características pode ser automatizada utilizando DL. 
												Em aplicações de DL, camadas convolucionais de Rede Neural Convolucional (CNN) extraem automaticamente características hierárquicas de 
												imagens, enquanto Rede Neural Recorrente (RNN) ou <i>Transformers</i> (transformadores) podem capturar dependências temporais em dados sequenciais.</p>
											<p class="lead mb-3 text-justify indent">Não existe receita pronta: cada contexto deve ser criteriosamente estudado para se definir quais características serão extraídas manualmente pelo especialista ou qual métodos será empregado para a seleção automática, pois essas escolhas são cruciais para o desempenho do modelo de ML.</p>
											<h2 class="mb-0" id="uni5-2">5.2 Seleção de características</h2>
											<p class="lead mb-3 text-justify indent">A seleção de características é o processo realizado após a extração das características e tem como objetivo identificar e escolher um subconjunto das características mais relevantes para a construção de um modelo de ML (Guyon & Elisseeff, 2003). Esse processo é essencial para melhorar a eficiência do modelo, reduzir a complexidade computacional e prevenir o (sobreajuste) (falaremos sobre isso adiante). De forma direta, podemos entender que técnicas de seleção de características ajudam a eliminar dados redundantes ou irrelevantes que não contribuem para a precisão do modelo.</p>
											<p class="lead mb-3 text-justify indent">Existem vários métodos de seleção de características, incluindo métodos de filtro, <i>wrapper</i><sup>1</sup> e baseados em modelos. 
												Métodos de filtro utilizam estatísticas para avaliar a relevância de cada característica de forma independente do modelo. Exemplos incluem correlação, 
												qui-quadrado e testes de informação mútua. Métodos de <i>wrapper</i>, como <i>Recursive Feature Elimination</i> (RFE), avaliam combinações de características 
												utilizando o desempenho do modelo. Já os métodos baseados em modelos, como <i>Least Absolute Shrinkage and Selection Operator</i> (LASSO)<sup>2</sup>, incorporam a 
												seleção de características diretamente no processo de treinamento do modelo.</p>
											<p class="lead mb-3 text-justify indent">Ao eliminar características irrelevantes ou redundantes, a seleção de características simplifica o modelo, reduzindo o número de parâmetros que precisam ser ajustados durante o treinamento. Isso resulta em algoritmos mais rápidos, pois há menos dados a serem processados. Modelos simplificados necessitam de menos iterações para convergir durante o treinamento, acelerando o processo de aprendizado. Isso é particularmente vantajoso em algoritmos de otimização que dependem de múltiplas iterações, como gradiente descendente. Além disso, com menos características (mantendo, é claro, as mais relevantes), o tempo necessário para a realização dos cálculos durante o treinamento é significativamente reduzido. Isso é crucial em aplicações práticas onde o tempo de processamento é uma limitação.</p>
											<p class="lead mb-3 text-justify indent">Outra vantagem que determina a importância do processo de seleção de características é a redução 
												da demanda de recursos computacionais. Menos características significam que menos dados precisam ser armazenados na memória durante o processamento. 
												Isso é particularmente importante em sistemas com recursos limitados, como dispositivos embarcados ou aplicações móveis.  A quantidade de operações 
												matemáticas necessárias para processar os dados é reduzida, diminuindo a carga computacional e permitindo que modelos sejam treinados e executados 
												em <i>hardwares</i> menos potentes. Por fim, a seleção de características facilita a escalabilidade dos modelos para grandes conjuntos de dados. 
												Ao trabalhar com um subconjunto mais gerenciável de características, torna-se mais fácil lidar com volumes massivos de dados sem sobrecarregar os recursos computacionais.</p>
											<hr class="m-0" size="1" width="30%" Align="left" noshade>
												<p class="lead mb-2 text-justify indent"><small>
													<p class="lead mb-2 text-justify indent"><sup>1</sup> <i>Wrapper</i> é uma abordagem para a seleção de características em <i>machine learning</i> onde a eficácia de diferentes 
														subconjuntos de características é avaliada diretamente pelo desempenho do modelo de aprendizado. Em vez de utilizar medidas 
														estatísticas simples para selecionar características, o método <i>wrapper</i> usa o próprio algoritmo de aprendizado para determinar 
														quais características são mais relevantes. Isso é feito testando iterativamente diferentes combinações de características e 
														observando como a inclusão ou exclusão de cada uma afeta o desempenho do modelo.</p>
													<p class="lead mb-2 text-justify indent"><sup>2</sup> LASSO é uma técnica de regularização e seleção de características que adiciona uma penalidade 
														baseada na soma dos valores absolutos dos coeficientes de regressão. Essa penalidade força a redução de 
														alguns coeficientes a zero, efetivamente selecionando um subconjunto de características durante o treinamento do modelo.</p>
												</small></p>
											<p class="lead mb-3 text-justify indent">A seleção adequada de características pode levar a modelos mais interpretáveis e eficientes, facilitando a compreensão dos dados e a tomada de decisões. Também pode ajudar a reduzir a dimensionalidade dos dados, abordando desafios associados a conjuntos de dados de alta dimensão.</p>
											<h2 class="mb-0" id="uni5-3">5.3 Características vs. dimensionalidade</h2>
											<p class="lead mb-3 text-justify indent">A relação entre características e dimensionalidade é um aspecto crucial em ML. Cada característica adicionada a um conjunto de dados aumenta sua dimensionalidade, o que pode ter implicações significativas no desempenho e na complexidade do modelo. Embora a inclusão de mais características possa fornecer mais informações ao modelo, também pode levar a desafios como a maldição da dimensionalidade (abordaremos essa questão adiante). Vamos utilizar alguns exemplos para entendermos melhor como é a relação característica vs. dimensionalidade.</p>
											<p class="lead mb-3 text-justify indent"><b>a) Uma dimensão (1D ou unidimensional):</b></p>
											<ul style="margin-left: 1cm;" class="lead mb-3 text-justify indent">
												<li>Imagine que temos uma característica, como a altura de uma pessoa.</li>
												<li>Cada pessoa pode ser representada como um ponto em uma linha, onde a posição na linha indica a altura.</li>
											</ul>
											<p class="lead mb-3 text-center" id="link-figura-17"><b>Figura 17</b> - Dados unidimensionais sobre altura (em cm)</p>
												<div align="center">
													<span class="image fit" style="width: 70%;"><img src="images/Figura 17 - Dados unidimensionais sobre altura (em cm).png" alt="" /></span>
													<p class="lead mb-2 text-center"><small>Fonte: Autoria própria</small></p>
												</div>
											<p class="lead mb-3 text-justify indent"><b>b) Duas dimensões (2D ou bidimensional):</b></p>
											<ul style="margin-left: 1cm;" class="lead mb-3 text-justify indent">
												<li>Agora, adicionamos uma segunda característica, como o peso.</li>
												<li>Cada pessoa agora é representada como um ponto em um plano bidimensional, onde a posição é determinada pela altura e pelo peso.</li>
											</ul>
											<p class="lead mb-3 text-center" id="link-figura-18"><b>Figura 18</b> - Dados bidimensionais que relacionam peso (em kg) e altura (em cm) de cinco pessoas</p>
												<div align="center">
													<span class="image fit" style="width: 70%;"><img src="images/Figura 18.png" alt="" /></span>
													<p class="lead mb-2 text-center"><small>Fonte: Autoria própria</small></p>
												</div>
											<p class="lead mb-3 text-justify indent">Cada ponto no gráfico da Figura 18 representa uma pessoa com uma combinação respectiva de altura e peso.</p>
											<p class="lead mb-3 text-justify indent"><b>c) Três dimensões (3D ou tridimensional):</b></p>
											<ul style="margin-left: 1cm;" class="lead mb-3 text-justify indent">
												<li>Adicionando uma terceira característica, como a idade, movemos para um espaço tridimensional.</li>
												<li>Cada pessoa agora é representada como um ponto em um espaço 3D, com altura, peso e idade determinando sua posição. Observe o gráfico da Figura 19 a seguir.</li>
											</ul>
											<p class="lead mb-3 text-center" id="link-figura-19"><b>Figura 19</b> - Dados tridimensionais que relacionam peso (em kg), altura (em cm) e idade (em anos) de cinco pessoas</p>
												<div align="center">
													<span class="image fit" style="width: 70%;"><img src="images/Figura 19.png" alt="" /></span>
													<p class="lead mb-2 text-center"><small>Fonte: Autoria própria</small></p>
												</div>
												<p class="lead mb-3 text-justify indent">Cada nova característica adicionada representa uma nova dimensão no espaço dos dados. Assim:</p>
											<ul style="margin-left: 1cm;" class="lead mb-3 text-justify indent">
												<li>1 característica = 1 dimensão (linha);</li>
												<li>2 características = 2 dimensões (plano);</li>
												<li>3 características = 3 dimensões (espaço 3D);</li>
												<li>N características = N dimensões (hiperespaço).</li>
											</ul>
											<p class="lead mb-3 text-justify indent">Em espaços de alta dimensão (hiperespaços), visualizar os dados se torna impossível, mas a matemática e os algoritmos de ML ainda podem operar nesses espaços. Cada ponto de dado em um espaço N-dimensional representa uma instância com N características, e os algoritmos de ML utilizam essas coordenadas para encontrar padrões, realizar classificações e fazer previsões.</p>
											<p class="lead mb-3 text-justify indent">Por exemplo, se adicionarmos uma nova característica como a "pressão arterial" ao nosso exemplo de pessoas, estaríamos aumentando a dimensionalidade do nosso espaço de dados para quatro Dimensões (4D) (altura, peso, idade, pressão arterial). Embora não possamos visualizar um espaço 4D, a adição dessa característica fornece mais informações que podem ser úteis para melhorar a precisão do modelo de ML.</p>
											<p class="lead mb-3 text-justify indent">Em um espaço de alta dimensão, a densidade dos dados tende a diminuir, tornando mais difícil encontrar padrões significativos. Isso ocorre porque, à medida que a dimensionalidade aumenta, o volume do espaço de características cresce exponencialmente, e os dados se tornam esparsos. Consequentemente, os algoritmos de ML podem ter dificuldades para generalizar a partir dos dados de treinamento, resultando em <i>overfitting</i> (sobreajuste).</p>
											<p class="lead mb-3 text-justify indent">Portanto, equilibrar o número de características é fundamental. A seleção cuidadosa de características relevantes e a redução da dimensionalidade são práticas importantes para manter um conjunto de dados manejável e para garantir que o modelo seja capaz de aprender e generalizar de forma eficaz.</p>

											<h2 class="mb-0" id="uni5-4">5.4 Maldição da dimensionalidade</h2>
											<p class="lead mb-3 text-justify indent">A maldição da dimensionalidade (Bellman, 1961) refere-se aos vários fenômenos que surgem quando se trabalha 
												com dados em espaços de alta dimensão. À medida que a dimensionalidade dos dados aumenta, o volume do espaço aumenta de tal forma que os pontos de dados se tornam esparsos. 
												Em consequência, muitas das intuições e técnicas que funcionam bem em espaços de baixa dimensão deixam de ser aplicáveis. Na Figura 20 mostra 2 gráficos representando um 
												plano bidimensional denso e um plano tridimensional esparso. Veja que, no gráfico da figura 22, os objetos estão distantes entre si de forma generalizada, o que dificulta encontrar similaridades.</p>
											<p class="lead mb-3 text-center" id="link-figura-20"><b>Figura 20</b> - Espaços de características bidimensional denso (à esquerda) e tridimensional esparso (à direita)</p>
												<div align="center">
													<span class="image fit" style="width: 70%;"><img src="images/Figura20.png" alt="" /></span>
													<p class="lead mb-2 text-center"><small>Fonte: Adaptada de <a href="https://www.mssqltips.com/tipimages2/5546_visualize-patterns-high-volume-data-hexbin-scatterplot-power-bi.007.png">Pragmatiq, 2023</a>.</small></p>
												</div>
											<p class="lead mb-3 text-justify indent">Uma das principais dificuldades associadas à maldição da dimensionalidade é que a distância entre os pontos de dados tende a se tornar uniforme, dificultando a distinção entre eles. Isso pode prejudicar a eficácia de algoritmos de aprendizado de máquina baseados em distância, como kNN (<i>k-Nearest Neighbors</i>) e de <i>clustering</i> (agrupamento).</p>
											<p class="lead mb-3 text-justify indent">Para mitigar os efeitos da maldição da dimensionalidade, técnicas de redução de dimensionalidade (aprofundaremos neste assunto adiante), como PCA e <i>t-Distributed Stochastic Neighbor Embedding</i> (t-SNE), são frequentemente utilizadas. Essas técnicas ajudam a projetar os dados em um espaço de menor dimensão, preservando as características mais importantes e facilitando a análise e a modelagem.</p>
											<h2 class="mb-0" id="uni5-5">5.5 Normalização do espaço de características</h2>
											<p class="lead mb-3 text-justify indent">A normalização do espaço de características é uma etapa crucial no pré-processamento de dados em ML. Consiste em ajustar as escalas das características para que todas contribuam igualmente para o modelo, evitando que características com valores maiores dominem o processo de aprendizado. Isso é particularmente importante em algoritmos baseados em distância, como kNN e SVM.</p>
											<p class="lead mb-3 text-justify indent">Existem várias técnicas de normalização, como a padronização (<i>standardization</i>), que transforma as características para terem média zero e desvio padrão um, e a normalização min-max, que reescala os valores para um intervalo específico, geralmente entre 0 e 1. A escolha da técnica de normalização depende da natureza dos dados e do algoritmo utilizado.</p>
											<p class="lead mb-3 text-justify indent">Retomando o exemplo anterior, em que apresentamos um espaço de características bidimensionais com os eixos de altura (em cm) e peso (em kg), se os valores de altura estivessem em metros, a amplitude dessa característica em relação ao peso das pessoas seria bem menor. Isso quer dizer que, sem normalização, as diferenças de escala entre essas características poderiam causar problemas nos algoritmos de aprendizado de máquina. Por exemplo, os valores de peso podem variar entre 50 e 150 kg, enquanto os valores de altura variam entre 1,5 e 2 metros. Esta diferença de escala pode fazer com que a característica de peso domine os cálculos de distância, levando a modelos que não consideram a altura de forma adequada. A normalização transforma os dados para que todas as características tenham a mesma escala, tipicamente ajustando os valores para um intervalo padrão, como 0 a 1, por exemplo. Isso garante que cada característica contribua igualmente para o modelo, melhorando a precisão, a eficiência do treinamento e a capacidade de generalização do modelo para novos dados.</p>
											<p class="lead mb-3 text-justify indent">A Figura 21 apresenta um mesmo espaço de características com os objetos representados por círculos. Na Figura com dados sem normalização percebemos que a escala dos dados do eixo de altura (x1) é bem menor em relação à peso (x2). Enquanto na outra, após a normalização dos valores entre -2 e 2, os objetos aparecem mais distribuídos, com a classe 0 (cor azul) e classe 1 (cor vermelha) mais distantes entre si, ao passo que respectivos elementos mantém a proximidade dentro da mesma classe.</p>
											<p class="lead mb-3 text-center" id="link-figura-21"><b>Figura 21</b> - Espaço de características de peso e altura não normalizado (à esquerda) e normalizado (à direita)</p>
												<div align="center">
													<span class="image fit" style="width: 70%;"><img src="images/Figura 21.png" alt="" /></span>
													<p class="lead mb-2 text-center"><small>Fonte: Adaptada de <a href="https://stats.stackexchange.com/questions/287425/why-do-you-need-to-scale-data-in-knn">Kedarps, 2017</a>.</small></p>
												</div>
											<p class="lead mb-3 text-justify indent">Portanto, a normalização melhora a convergência de algoritmos de otimização e pode levar a um melhor desempenho geral do modelo. Além disso, facilita a comparação de diferentes características e garante que os modelos treinados sejam mais robustos e interpretáveis. Falaremos mais sobre normalização de dados mais adiante.</p>
											<h2 class="mb-0" id="uni5-6">5.6 Transformação do espaço de características</h2>
											<p class="lead mb-3 text-justify indent">A transformação do espaço de características envolve a aplicação de técnicas para alterar a representação das características, de forma a destacar padrões ocultos nos dados ou tornar as características mais apropriadas para o modelo de ML. Apesar das técnicas de transformação do espaço de características alterarem a escala dos valores das características, não confunda com normalização. O processo de normalizar reescala as características para mitigar possíveis desbalanceamentos nos valores que podem priorizar algumas características em detrimento de outras. Já as transformações re-escalam os valores das características para destacar padrões mais significativos e melhorar o desempenho do modelo. Transformações podem incluir a aplicação de funções matemáticas, como logaritmos, exponenciais, ou polinômios, bem como a utilização de técnicas avançadas como PCA.</p>
											<p class="lead mb-3 text-justify indent">PCA é uma técnica amplamente utilizada que transforma um conjunto de características originais em um novo conjunto de características ortogonais (componentes principais), que capturam a maior parte da variação presente nos dados originais. Essa transformação pode reduzir a dimensionalidade dos dados, ao mesmo tempo que preserva as informações essenciais, facilitando a visualização e a modelagem.</p>
											<p class="lead mb-3 text-justify indent">Outra técnica importante é o uso de <i>embeddings</i>, particularmente em PLN. <i>Embeddings</i>, como Word2Vec ou BERT, transformam palavras em vetores de características densos que capturam contextos semânticos, permitindo que os modelos de PLN lidem com a semântica de maneira mais eficaz. A transformação correta do espaço de características pode melhorar significativamente o desempenho dos modelos de ML.</p>
											<p class="lead mb-3 text-justify indent">Na Figura 22, é exemplificado o processo de transformação do espaço de características usando o <i>kernel</i> do SVM. De forma simplificada, o <i>kernel</i> transforma os dados de entrada para um espaço de características de maior dimensão. Esta transformação pode tornar dados que são não linearmente separáveis em seu espaço original (de baixa dimensão) linearmente separáveis no novo espaço (de alta dimensão). Nesse caso, aumentar a dimensionalidade, efeito colateral da transformação, favorece a separação das classes.</p>
											<p class="lead mb-3 text-center" id="link-figura-22"><b>Figura 22</b> - Transformação do espaço de características</p>
												<div align="center">
													<span class="image fit" style="width: 70%;"><img src="images/Figura 22 - Transformação do espaço de características.png" alt="" /></span>
													<p class="lead mb-2 text-center"><small>Fonte: Adaptada de <a href="https://www.researchgate.net/publication/367664188/figure/fig3/AS:11431281117775306@1675533290992/Maximum-hyperplane-and-feature-space-transformation.jpg">Niyogisubizo <i>et al</i>., 2023</a>.</small></p>
												</div>
											<h2 class="mb-0" id="uni5-7">5.7 Redução da dimensionalidade</h2>
											<p class="lead mb-3 text-justify indent">A redução da dimensionalidade é o processo de diminuir o número de características em um conjunto de dados, mantendo a maior quantidade possível de informação relevante. Essa técnica é crucial para lidar com a maldição da dimensionalidade e melhorar a eficiência dos algoritmos de ML. Métodos como PCA e <i>Linear Discriminant Analysis</i> (LDA) são frequentemente utilizados para esse fim.</p>
											<p class="lead mb-3 text-justify indent">PCA reduz a dimensionalidade projetando os dados em um espaço de menor dimensão que captura a maior variância possível. LDA, por outro lado, busca maximizar a separabilidade entre diferentes classes ao projetar os dados em um espaço que preserva as informações discriminantes. Ambas as técnicas ajudam a simplificar o modelo, reduzindo o ruído e a complexidade computacional.</p>
											<p class="lead mb-3 text-justify indent">A redução da dimensionalidade não apenas melhora a eficiência do processamento, mas também pode levar a modelos mais robustos e generalizáveis. Ao focar nas características mais importantes, os modelos são menos propensos a <i>overfitting</i> (sobreajuste) e mais capazes de capturar os padrões subjacentes nos dados.</p>
											<h2 class="mb-0" id="uni5-8">5.8 Seleção de Características vs. Redução da Dimensionalidade</h2>
											<p class="lead mb-3 text-justify indent">A seleção de características e a redução da dimensionalidade são técnicas relacionadas, mas distintas, em ML. A seleção de características envolve a escolha de um subconjunto das características originais que são mais relevantes para a tarefa de aprendizado. Como vimos anteriormente, isso pode ser feito utilizando métodos de filtro, <i>wrapper</i> (empacotagem) ou baseados em modelos, que avaliam a importância de cada característica de forma individual ou em combinação.</p>
											<p class="lead mb-3 text-justify indent">Por outro lado, a redução da dimensionalidade cria novas características a partir das originais, projetando os dados em um espaço de menor dimensão. Técnicas como PCA e LDA transformam as características existentes em novas combinações que capturam a maior parte da variabilidade ou informação discriminante dos dados. Essas novas características não são um simples subconjunto das originais, mas uma reconfiguração que pode melhorar a análise.</p>
											<p class="lead mb-3 text-justify indent">Ambas as abordagens são valiosas para lidar com conjuntos de dados de alta dimensão, mas a seleção de características mantém a interpretabilidade das características originais, enquanto a redução da dimensionalidade pode revelar estruturas e padrões mais profundos. A escolha entre essas técnicas depende do objetivo específico e das características do conjunto de dados.</p>
											
											<p><span class="image right" style="width: 25%;"><img src="Robozinho/roboCuriosoLapisRoxo.png" alt="" /></span></p>
											<div class="box2">
												<h3 class="mb-0" id="5-relembrar">Para relembrar…</h3>
												<p class="lead mb-3 text-justify"><font color="#19032B">&#10132 </font>Nessa unidade, discutimos o processamento e transformação de características em ML, abordando temas como extração e seleção de características, relação entre características e dimensionalidade, maldição da dimensionalidade, normalização e transformação do espaço de características, além da distinção entre seleção de características e redução de dimensionalidade. A extração de características foi apresentada como o processo de derivar informações relevantes dos dados brutos, com exemplos de técnicas como HOG para imagens e TF-IDF para textos. A seleção de características, por sua vez, envolve identificar e escolher o subconjunto mais relevante de características, utilizando métodos como filtros, <i>wrappers</i> e técnicas baseadas em modelos.</p>
												<p class="lead mb-3 text-justify"><font color="#19032B">&#10132 </font>Exploramos a relação entre características e dimensionalidade, destacando como cada nova característica adiciona uma nova dimensão ao espaço dos dados. Isso pode aumentar a complexidade do modelo e levar à maldição da dimensionalidade, onde a alta dimensionalidade faz com que os dados se tornem esparsos e os algoritmos de ML tenham dificuldades para generalizar. A normalização do espaço de características foi enfatizada como uma prática essencial para ajustar as escalas das características, garantindo que todas contribuam igualmente para o modelo, o que é crucial para algoritmos baseados em distância, como kNN e SVM.</p>
												<p class="lead mb-3 text-justify"><font color="#19032B">&#10132 </font>Além disso, discutimos a transformação do espaço de características, que pode incluir técnicas como PCA para redução da dimensionalidade, ajudando a simplificar os dados e melhorar a eficiência computacional. Foi feita uma distinção clara entre seleção de características e redução de dimensionalidade, onde a primeira mantém a interpretabilidade das características originais e a segunda transforma os dados em um novo espaço de menor dimensão. Abordamos também a importância de evitar o <i>overfitting</i> (sobreajuste), onde modelos complexos se ajustam excessivamente aos dados de treinamento, e como técnicas como validação cruzada e regularização podem ajudar a mitigar esse problema.</p>
											</div>
											<p><span class="image left" style="width: 25%;"><img src="Robozinho/roboCuriosoLupaRoxoEsquerda.png" alt="" /></span></p>
											<div class="box3">
												<h3 class="mb-0" id="uni5-saiba-mais">Saiba mais…</h3>
												
													<p class="lead mb-3 text-justify"><font color="#19032B">&#10132 </font><a href="https://www.researchgate.net/publication/287743399_A_survey_of_feature_selection_and_feature_extraction_techniques_in_machine_learning">
														Artigo de revisão abrangente que revisa técnicas de seleção e extração de características</a>.</p>
														<p class="lead mb-3 text-justify"><font color="#19032B">&#10132 </font><a href="https://lvdmaaten.github.io/publications/papers/TR_Dimensionality_Reduction_Review_2009.pdf">
															Revisão comparativa de diversas técnicas de redução de dimensionalidade, como PCA, t-SNE, e LDA</a>.</p>													
												
											</div>
											
											
											</section>
												<hr class="m-0">
												<section>
													<div class="image main" id="capa_uni6">
														<img src="images/6. Unidade_6_Introdução a Machine Learning e Redes Neurais.png" alt="">
													</div>
												</section>
												<hr class="m-0">
												<section class="resume-section p-3 p-lg-5 d-flex align-items-center">
													<div class="w-100">
													<h1 class="mb-0" id="uni6">Unidade VI - Funções discriminantes</h1>
												</div></header>
												
												<h2 class="mb-0" id="uni6-1">6.1 Introdução</h2>
												<p class="lead mb-3 text-justify indent">As funções discriminantes desempenham um papel fundamental no campo da aprendizagem de máquina e reconhecimento de padrões. Estas funções matemáticas são utilizadas para classificar ou categorizar objetos em diferentes classes com base em suas características ou atributos observáveis. O conceito de funções discriminantes tem suas raízes na estatística e na teoria da decisão, remontando ao início do século XX.</p>
												<p class="lead mb-3 text-justify indent">Um dos pioneiros no desenvolvimento de funções discriminantes foi o estatístico britânico Ronald Fisher, que introduziu a LDA em 1936. Fisher aplicou esta técnica para classificar espécies de íris com base em medidas de suas pétalas e sépalas. Seu trabalho estabeleceu as bases para muitas das abordagens modernas de classificação em aprendizagem de máquina.</p>
												<p class="lead mb-3 text-justify indent">Ao longo das décadas, outros pesquisadores contribuíram significativamente para o desenvolvimento das funções discriminantes e suas aplicações em ML. Entre esses estão Vladimir Vapnik, co-criador do SVM e Cedric Smith que introduziu uma variação do LDA com a Análise Discriminante Quadrática (QDA).</p>
												<p class="lead mb-3 text-justify indent">Formalmente, uma função discriminante é uma função matemática que mapeia um vetor de características de entrada para um valor escalar, que é então usado para tomar uma decisão de classificação. Para um problema de classificação com K classes, geralmente são definidas K funções discriminantes, uma para cada classe. A classe predita para um novo exemplo é determinada pela função discriminante que produz o maior valor para esse exemplo.</p>
												<p class="lead mb-3 text-justify indent">Esta abordagem fornece uma base teórica sólida para muitos algoritmos de classificação em aprendizagem de máquina, permitindo a criação de modelos que podem aprender a distinguir entre diferentes classes de objetos ou eventos com base em suas características observáveis.</p>
												<h2 class="mb-0" id="uni6-2">6.2 Aplicações</h2>
												<p class="lead mb-3 text-justify indent">As funções discriminantes são amplamente utilizadas em diversas aplicações de aprendizagem de máquina para solucionar problemas do cotidiano. Alguns exemplos notáveis incluem:</p>
												
												<ul style="margin-left: 1cm;" class="lead mb-3 text-justify indent">
													<li><b>Reconhecimento de Caracteres</b>: em sistemas de OCR, funções discriminantes são empregadas para classificar caracteres individuais em letras ou números. Isso é crucial para a digitalização de documentos, leitura automática de placas de veículos e processamento de formulários escritos à mão.</li>
													<li><b>Diagnóstico Médico</b>: em sistemas de diagnóstico, como a detecção de câncer, as funções discriminantes podem ser utilizadas para classificar se uma célula é cancerosa ou não com base em características extraídas de imagens médicas. O LDA, por exemplo, pode ser aplicado para distinguir entre células benignas e malignas, analisando parâmetros como a textura e a forma das células.</li>
													<li><b>Detecção de Spam</b>: sistemas de filtragem de e-mails frequentemente utilizam funções discriminantes para classificar mensagens como spam ou não-spam. O modelo aprende a distinguir entre as duas classes com base em características do e-mail, como palavras-chave, estrutura do texto e informações do remetente.</li>
													<li><b>Reconhecimento de Fala</b>: em sistemas de reconhecimento de voz, funções discriminantes são aplicadas para classificar segmentos de áudio em fonemas ou palavras específicas. Isso é fundamental para a criação de assistentes virtuais e sistemas de transcrição automática.</li>
													<li><b>Análise de Sentimentos</b>: na análise de mídias sociais e avaliações de produtos, funções discriminantes são usadas para classificar o sentimento expresso em textos como positivo, negativo ou neutro. Isso auxilia empresas a entender a percepção do público sobre seus produtos ou serviços.</li>
													<li><b>Visão Computacional</b>: em sistemas de reconhecimento facial, as funções discriminantes ajudam a identificar indivíduos com base em características faciais. Utilizando técnicas como o SVM, o sistema pode aprender a distinguir entre diferentes rostos, mesmo em condições de iluminação variada e ângulos diferentes.</li>
													<li><b>Previsão de Risco de Crédito</b>: instituições financeiras utilizam funções discriminantes para classificar clientes em diferentes níveis de risco de crédito, baseando-se em seu histórico financeiro, renda e outros fatores relevantes. Modelos como o QDA podem ser aplicados para identificar padrões em dados financeiros que indicam um risco elevado de inadimplência ou atividades fraudulentas.</li>
												</ul>
												<h2 class="mb-0" id="uni6-3">6.3 Conceitos Importantes</h2>
												<p class="lead mb-3 text-justify indent">Para compreender como as funções discriminantes podem ser utilizadas em aplicações é necessário conhecer um pouco mais. As subseções seguintes tratarão de conceitos importantes para esse entendimento.</p>
												<h3 class="mb-0" id="uni6-3-1">6.3.1 Espaço de características</h3>
												<p class="lead mb-3 text-justify indent">O espaço de características é um conceito fundamental em ML. Ele representa um espaço multidimensional onde cada dimensão corresponde a uma característica ou atributo dos dados.  Refere-se ao conjunto de todas as características ou variáveis independentes que são usadas para descrever as amostras de dados. Cada ponto nesse espaço representa uma amostra específica, e suas coordenadas correspondem aos valores das características dessa amostra.</p>
												<p class="lead mb-3 text-justify indent">Para ilustrar, considere um problema de classificação de flores, onde cada flor é descrita por quatro características: comprimento da sépala, largura da sépala, comprimento da pétala e largura da pétala. Aqui, o espaço de características é , e cada flor é um ponto nesse espaço.</p>
												<h3 class="mb-0" id="uni6-3-2">6.3.2 Fronteiras de decisão</h3>
												<p class="lead mb-3 text-justify indent">As fronteiras de decisão referem-se às regiões que separam o espaço de características em áreas associadas a diferentes classes. Na figura abaixo temos alguns exemplos de fronteiras de decisão para classificar X e O. O X e O podem ser, por exemplo, pessoas que foram diagnosticadas com uma doença ou não , respectivamente. Os eixos x, pode ser o valor dos resultados da contagem de leucócitos e o eixo y pode ser a quantidade de dias que a pessoa faz exercícios físicos.</p>
												<p class="lead mb-3 text-justify indent">As fronteiras de decisão podem ser:</p>
												<ul style="margin-left: 1cm;" class="lead mb-3 text-justify indent">
													<li><b>Fronteiras lineares</b>: hiperplanos que separam as classes de forma linear no espaço de características, como ilustrado na figura abaixo e a esquerda.</li>
													<li><b>Fronteiras quadráticas</b>: superfícies quadráticas que permitem separação não linear entre classes, sendo a mais simples fronteira não linear. Ela segue uma equação do segundo grau, como por exemplo y=x^2. Um exemplo dessa curva aplicada à fronteira de decisão é ilustrada na figura abaixo e ao centro.</li>
													<li><b>Fronteiras não lineares</b>: superfícies de decisão complexas que podem assumir formas arbitrárias para melhor separar as classes. A figura abaixo ilustra uma complexa fronteira de decisão que separa perfeitamente X de O, contudo veremos na unidade Conjunto de Dados que nem sempre esse tipo de “perfeição” é vantajosa.</li>
												</ul>
												<p class="lead mb-3 text-center" id="link-figura-23"><b>Figura 23</b> - Exemplo tipo de fronteiras</p>
												<div align="center">
													<span class="image fit" style="width: 70%;"><img src="images/Figura 23 - Exemplo tipo de fronteiras.png" alt="" /></span>
													<p class="lead mb-2 text-center"><small>Fonte: Adaptada de <a href="https://miro.medium.com/v2/resize:fit:828/format:webp/1*dpUnwfXqnU5Kd-gfafgIgQ.png">Towards Data Science, 2018</a>.</small></p>
												</div>
												<h3 class="mb-0" id="uni6-3-3">6.3.3 Classificação binária vs. multiclasse</h3>
												<p class="lead mb-3 text-justify indent">Existem dois grandes grupos de classificação: binária e multiclasse. A classificação binária, como o próprio nome diz, refere-se apenas a duas classes, como por exemplo os casos ilustrados na figura abaixo e a direita. Nesse caso se resumem a uma única função 
													(reta em verde) que separa as duas classes (O de X). Exemplos de métodos de classificação binária incluem Regressão Logística e SVM.</p>
												<p class="lead mb-3 text-justify indent">Em problemas de classificação com mais de duas classes, como classificação de imagens em diferentes categorias, são requeridas múltiplas funções discriminantes , uma para cada par de classes, como o ilustrado abaixo (Figura 24) e a direita. 
													A reta vermelha separa o X dos quadrados e triângulos. A reta em verde separa os triângulos dos X e quadrados, por fim, a reta em azul separa os quadrados dos triângulos e X. Alguns exemplos de métodos multiclasse são a LDA e QDA.</p>
												<p class="lead mb-3 text-center" id="link-figura-24"><b>Figura 24</b> - Na classificação binária utilizou-se uma função discriminante, na multi-classes, múltiplas  funções discriminantes são utilizadas </p>
												<div align="center">
													<span class="image fit" style="width: 70%;"><img src="images/Figura 24.png" alt="" /></span>
													<p class="lead mb-2 text-center"><small>Fonte: Adaptada de <a href="https://miro.medium.com/v2/resize:fit:640/format:webp/1*lp0gdEqNTMsAFAEw_Qwusw.png">Medium, 2021</a>.</small></p>
												</div>
												<h2 class="mb-0" id="uni6-4">6.4 Principais Algoritmos</h2>
												<p class="lead mb-3 text-justify indent">Os algoritmos de aprendizagem de máquina que utilizam funções discriminantes variam em complexidade e capacidade de modelagem, os principais são:</p>
												<ul style="margin-left: 1cm;" class="lead mb-3 text-justify indent">
													<li><b>LDA</b>: é o algoritmo mais simples e amplamente utilizado. Ele assume que os dados seguem uma distribuição normal em cada classe e que as matrizes de covariância são iguais. É ideal para situações com baixo número de variáveis e alta dimensionalidade.</li>
													<li><b>QDA</b>: essa variante da LDA relaxa a suposição de igualdade das matrizes de covariância, permitindo que elas sejam diferentes para cada classe. É mais robusto que a LDA, mas pode ser computacionalmente mais caro.</li>
													<li><b>Análise Discriminante Regularizada (RDA)</b>: essa técnica introduz regularização para lidar com problemas de alta dimensionalidade, onde o número de características é maior do que o número de observações.</li>
												</ul>
												<h3 class="mb-0" id="uni6-4-1">6.4.1 Conceitos Matemáticos Importantes</h3>
												<p class="lead mb-3 text-justify indent">Para entendimento dos algoritmos é bom termos uma noção de alguns conceitos matemáticos que são utilizados.</p>
												<h4 class="mb-0" id="uni6-4-1-1">6.4.1.1 Matriz de covariância ou de dispersão</h4>
												<p class="lead mb-3 text-justify indent">Suponha que você esteja conduzindo um estudo sobre o crescimento de diferentes espécies de plantas em um jardim. Para cada planta, você coleta dados sobre três características: altura, número de folhas e largura das folhas. Essas características podem variar de acordo com fatores como exposição ao sol, quantidade de água e tipo de solo.</p>
												<p class="lead mb-3 text-justify indent">A matriz de dispersão é uma ferramenta matemática que permite compreender como essas características variam em relação umas às outras. Por exemplo:</p>
												<ul style="margin-left: 1cm;" class="lead mb-3 text-justify indent">
													<li><b>Altura x Número de Folhas</b>: Plantas mais altas podem ter um maior número de folhas, ou essa correlação pode ser inexistente.</li>
													<li><b>Altura x Largura das Folhas</b>: Pode haver uma relação entre a altura da planta e a largura das folhas, indicando que plantas mais altas têm folhas mais largas.</li>
													<li><b>Número de Folhas x Largura das Folhas</b>: O número de folhas pode influenciar ou não a largura média das folhas.</li>
												</ul>
												<p class="lead mb-3 text-justify indent">A matriz de dispersão organiza essas relações de forma sistemática, permitindo uma análise clara de como cada par de características está relacionado. Se as características (altura, número de folhas e largura das folhas) tendem a aumentar ou diminuir juntas, isso sugere uma correlação positiva entre elas. Caso contrário, a matriz indicará uma falta de correlação significativa.</p>
												<p class="lead mb-3 text-justify indent">A matriz de dispersão é composta por elementos que representam a variância e a covariância entre as diferentes características:</p>
												<ul style="margin-left: 1cm;" class="lead mb-3 text-justify indent">
													<li><b>Variância</b>: Refere-se à medida de quanto uma única característica (por exemplo, a altura) varia em relação à média.</li>
													<li><b>Covariância</b>: Refere-se à medida de como duas características (por exemplo, altura e número de folhas) variam juntas.</li>
												</ul>
												<p class="lead mb-3 text-justify indent">Por meio da matriz de dispersão, é possível identificar padrões nos dados que podem fornecer tendências valiosas sobre os fatores que mais influenciam o crescimento das plantas.</p>
												<p class="lead mb-3 text-justify indent">Se uma covariância entre duas variáveis for <b>positiva</b>, isso indica que, à medida que uma das variáveis aumenta, a outra também tende a aumentar. Por exemplo, na figura abaixo, o valor positivo na interseção de "<i>Sepal.Length</i>" e "<i>Petal.Length</i>" indica que, conforme o comprimento da sépala aumenta, o comprimento da pétala também tende a aumentar. Isso sugere uma relação linear direta entre essas duas variáveis.</p>
												<p class="lead mb-3 text-justify indent">Por outro lado, se uma covariância entre duas variáveis for <b>negativa</b>, isso indica que, à medida que uma das variáveis aumenta, a outra tende a diminuir. Por exemplo, o valor negativo na interseção de "<i>Sepal.Length</i>" e "<i>Sepal.Width</i>", sugere que à medida que o comprimento da sépala aumenta, a largura da sépala tende a diminuir, indicando uma relação inversa entre essas duas variáveis.</p>
												<p class="lead mb-3 text-justify indent">A matriz de covariância (veja Figura 25 abaixo) permite entender as relações de co-dependência entre as variáveis, e a presença de valores positivos ou negativos ajuda a identificar o tipo de relação linear entre elas.</p>
												<p class="lead mb-3 text-center" id="link-figura-25"><b>Figura 25</b> - Matriz de Covariância e as relações de co-dependência entre as variáveis</p>
												<div align="center">
													<span class="image fit" style="width: 70%;"><img src="images/Figura 25.png" alt="" /></span>
													<p class="lead mb-2 text-center"><small>Fonte: Adaptada de <a href="https://www.hackersrealm.net/post/iris-dataset-analysis-using-python">Hackers Realm, 2022</a>.</small></p>
												</div>
												<h4 class="mb-0" id="uni6-4-1-3">6.4.1.2 Autovetores e Autovalores</h4>
												<p class="lead mb-3 text-justify indent">Os conceitos de autovalores e autovetores são fundamentais em diversas áreas da matemática aplicada, incluindo a análise de dados e o aprendizado de máquina. Apesar de serem conceitos avançados, eles podem ser compreendidos de maneira mais intuitiva por meio de uma analogia visual.</p>
												<p class="lead mb-3 text-justify indent">Imagine que você tem um vetor representado por uma flecha em um plano. Esse vetor aponta em uma determinada direção e possui um certo comprimento. Agora, suponha que aplicamos uma transformação matemática a esse vetor, como uma rotação, esticamento ou compressão. Após essa transformação, o vetor pode mudar de direção, de comprimento, ou ambos. Entretanto, em alguns casos especiais, o vetor mantém sua direção original, embora seu comprimento possa ter sido alterado. Quando isso ocorre, esse vetor é denominado <b>autovetor</b>.</p>
												<p class="lead mb-3 text-justify indent">O fator pelo qual o comprimento do vetor é alterado durante a transformação é chamado de <b>autovalor</b>. Ou seja, o autovalor representa o quanto o autovetor foi esticado ou comprimido, enquanto o autovetor é a direção que permanece inalterada.</p>
												
												<p class="lead mb-3 text-justify indent">Na figura abaixo, imagine que o vetor em azul passa por uma transformação matemática que resulta nos vetores em laranja. A transformação matemática aplicada a ambos os vetores em azul 
													é a mesma (tanto no primeiro quanto no segundo gráfico da figura), porém os resultados são diferentes. No segundo gráfico da figura 26, temos um vetor (1,1) que após a transformação matemática teve rotação e alteração 
													de tamanho, portanto pode-se dizer que o vetor azul <b>não é</b> um autovetor. Já no segundo gráfico, temos o vetor (1,2) que após a transformação matemática <b>não</b> teve rotação porém teve alteração de tamanho, 
													portanto pode-se dizer que o vetor azul <b>é</b> um autovetor e possui um autovalor de 5, que é o fator de escala quando comparados os vetores azul e laranja.</p>
													<p class="lead mb-3 text-center" id="link-figura-26"><b>Figura 26</b> - Aplicação de transformações em vetor, (a) exemplo de autovalor e autovetor, (b) exemplo de um não autovetor e autovalor</p>
													<div align="center">
														<span class="image fit" style="width: 70%;"><img src="images/Figura 26.png" alt="" /></span>
														<p class="lead mb-2 text-center"><small>Fonte: Adaptada de <a href="https://youtu.be/5UjQVJu89_Q?t=64">Solid Mechanics Classroom, 2017</a>.</small></p>
													</div>
												<p class="lead mb-3 text-justify indent">Em termos mais formais:</p>
												<ul style="margin-left: 1cm;" class="lead mb-3 text-justify indent">
													<li><b>Autovetor</b>: Um vetor que, após uma transformação linear, mantém sua direção original.</li>
													<li><b>Autovalor</b>: O escalar pelo qual o autovetor é multiplicado após a transformação.</li>
												</ul>
												<p class="lead mb-3 text-justify indent">Esses conceitos são amplamente utilizados na decomposição de matrizes, uma técnica que permite simplificar problemas complexos.</p>
												<h3 class="mb-0" id="uni6-4-2">6.4.2 Análise Discriminante Linear (LDA)</h3>
												<p class="lead mb-3 text-justify indent">A LDA é um método de classificação que busca encontrar uma combinação linear das características que melhor separa duas ou mais classes. O LDA assume que as classes têm a mesma matriz de covariância, mas médias diferentes.</p>
												<p class="lead mb-3 text-justify indent">Funcionamento do Algoritmo LDA:</p>
												<ol style="margin-left: 1cm;" class="lead mb-3 text-justify indent">
													<li>Calcula-se a média de cada classe;</li>
													<li>Calcula-se a matriz de dispersão entre classes e dentro das classes;</li>
													<li>Calcula-se os autovetores e autovalores da matriz de dispersão;</li>
													<li>Seleciona-se os k melhores autovetores para projeção;</li>
													<li>Projeta-se os dados no novo espaço e realiza a classificação.</li>
												</ol>
												
												<p class="lead mb-3 text-justify indent">Para ilustrar na prática uma aplicação do LDA usando o famoso conjunto de dados Iris, o código abaixo faz todo o processo do algoritmo descrito acima, cujo objetivo é classificar o tipo da flor com base nas suas características (largura e comprimento) de pétalas e sépalas.</p>
												<p class="lead mb-3 text-justify" id="link-codigo-01"><b>Código 1</b> - Processamento do algoritmo de análise discriminante linear (LDA), usando o conjunto de dados Íris</p>
<pre><code># Importação das bibliotecas necessárias
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split

# Carrega o conjunto de dados Iris
iris = load_iris()
X, y = iris.data, iris.target

# Divide os dados em conjuntos de treino e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Cria e treina o modelo LDA
lda = LinearDiscriminantAnalysis()
lda.fit(X_train, y_train)

# Realiza previsões e avalia a acurácia
accuracy = lda.score(X_test, y_test)
print(f"Acurácia do LDA: {accuracy:.2f}")</code></pre>
<br>
												<h4 class="mb-0" id="uni6-4-2-1">6.4.2.1 Detalhamento do código</h4>
												<p class="lead mb-3 text-justify" id="link-codigo-02"><b>Código 2</b> - Importando as bibliotecas necessárias</p>
<pre><code># Importação das bibliotecas necessárias
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split</code></pre>
<br>

												<p class="lead mb-3 text-justify">-<span class="highlight2">from sklearn.discriminant_analysis import LinearDiscriminantAnalysis</span>: Este comando importa a classe <i>Linear Discriminant Analysis</i> (<i>LDA</i>) da biblioteca <i>scikit-learn</i> 
													(comumente abreviada como <span class="highlight2">sklearn</span>).</p>
												<p class="lead mb-3 text-justify">-<span class="highlight2">from sklearn.datasets import load_iris</span>: 
													Aqui, importamos a função <span class="highlight2">load_iris</span>, que carrega o conjunto de dados Iris, um dos datasets mais conhecidos e frequentemente utilizados em exemplos de aprendizado de máquina.</p>
												<p class="lead mb-3 text-justify">-<span class="highlight2">from sklearn.model_selection import train_test_split</span>: Este comando importa a função <span class="highlight2">train_test_split</span>, que facilita a divisão do 
													conjunto de dados em subconjuntos de treinamento e de teste.</p>
													<p class="lead mb-3 text-justify" id="link-codigo-03"><b>Código 3</b> - Carregando o conjunto de dados Íris</p>
<pre><code>iris = load_iris()
X, y = iris.data, iris.target</code></pre>
<br>
												<p class="lead mb-3 text-justify">-<span class="highlight2">iris = load_iris()</span>: Nesta linha, o conjunto de dados Iris é 
													carregado e armazenado na variável <span class="highlight2">iris</span>. Este conjunto de dados contém informações sobre três espécies de flores: setosa, 
													versicolor e virginica; com quatro características mensuradas para cada amostra (comprimento e largura das pétalas e sépalas).</p>
												<p class="lead mb-3 text-justify">-<span class="highlight2">X, y = iris.data, iris.target</span>: Aqui, o conjunto de dados é dividido em duas partes:</p>
												<ul style="margin-left: 1cm;" class="alt4 lead mb-3 text-justify indent">
													<li>-<span class="highlight2">X</span>: Representa as características das amostras: comprimento e largura das pétalas e sépalas (as variáveis independentes).</li>
													<li>-<span class="highlight2">y</span>: Corresponde às classes ou rótulos das amostras (a variável dependente), indicando a qual espécie de flor cada amostra pertence (setosa, versicolor ou virginica).</li>
												</ul>
												<p class="lead mb-3 text-justify" id="link-codigo-04"><b>Código 4</b> - Dividindo o conjunto de dados em dois subconjuntos</p>
<pre><code>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)</code></pre>
												
<br> 											<p class="lead mb-3 text-justify">- <span class="highlight2">train_test_split(X, y, test_size=0.3, random_state=42)</span>: 
	Esta função divide o conjunto de dados em dois subconjuntos, seu objetivo mais claro será abordado na unidade 8:</p>
												<p class="lead mb-3 text-justify indent">-<span class="highlight2">X_train e y_train</span>: Contêm as amostras que serão utilizadas para treinar o modelo.</p>
												<p class="lead mb-3 text-justify indent">-<span class="highlight2">X_test e y_test</span>: Contêm as amostras que serão utilizadas para testar o modelo, avaliando seu desempenho.</p>
												<p class="lead mb-3 text-justify indent">-<span class="highlight2">test_size=0.3</span>: Especifica que 30% das amostras serão reservadas para o teste, enquanto os 70% restantes serão utilizados para o treinamento.</p>
												<p class="lead mb-3 text-justify indent">-<span class="highlight2">random_state=42</span>: Define um valor fixo para o gerador de números aleatórios, garantindo que a divisão dos dados seja reproduzível em diferentes execuções do código.</p>
												<p class="lead mb-3 text-justify" id="link-codigo-05"><b>Código 5</b> -  Criando um modelo de análise discriminante linear (LDA)</p>
<pre><code>lda = LinearDiscriminantAnalysis()
lda.fit(X_train, y_train)</code></pre>
<br>
												<p class="lead mb-3 text-justify">-<span class="highlight2">lda = LinearDiscriminantAnalysis()</span>: 
													Esta linha cria um modelo LDA que será utilizado para a classificação das amostras.</p>
												<p class="lead mb-3 text-justify">-<span class="highlight2">lda.fit(X_train, y_train)</span>: O método fit treina o modelo LDA utilizando os 
													dados de treinamento <span class="highlight2">X_train</span> e <span class="highlight2">y_train</span>. Durante este processo, o modelo aprende as relações entre as características das amostras e 
													suas respectivas classes, ajustando os parâmetros internos para maximizar a separação entre as diferentes classes. 
													É nessa fase que o algoritmo apresentado anteriormente é de fato aplicado.</p>
													<p class="lead mb-3 text-justify" id="link-codigo-06"><b>Código 6</b> -  Realizando previsões e avaliando a acurácia do modelo</p>
<pre><code># Realiza previsões e avalia a acurácia
accuracy = lda.score(X_test, y_test)
print(f"Acurácia do LDA: {accuracy:.2f}")</code></pre>
<br>
												<p class="lead mb-3 text-justify">-<span class="highlight2">accuracy = lda.score(X_test, y_test)</span>: Este método, chamado <span class="highlight2">score</span>, 
													é aplicado ao modelo <span class="highlight2">lda</span> previamente treinado. Ele calcula a acurácia do modelo, ou seja, a proporção de previsões corretas 
													que o modelo fez ao ser testado com o conjunto de dados <span class="highlight2">X_test</span> em comparação com os rótulos verdadeiros <span class="highlight2">y_test</span>. 
													O resultado é guardado na variável <span class="highlight2">accuracy</span>, que representará a porcentagem de amostras corretamente classificadas pelo modelo.</p>
												<p class="lead mb-3 text-justify">-<span class="highlight2">print(f"Acurácia do LDA: {accuracy:.2f}")</span>: Esta função <span class="highlight2">print</span> imprime uma mensagem na tela. 
													<span class="highlight2">f"Acurácia do LDA: {accuracy:.2f}"</span> é uma string formatada que inclui o valor da acurácia calculada. 
													A expressão <span class="highlight2">{accuracy:.2f}</span> formata o valor da acurácia para que seja exibido com duas casas decimais, 
												facilitando a leitura e a interpretação do resultado. Isso só é possível com o uso do <span class="highlight2">f</span> antes da string, que permite 
												inserir o valor da variável <span class="highlight2">accuracy</span> diretamente no texto.</p>
																							
												<h3 class="mb-0" id="uni6-4-3">6.4.3 Análise Discriminante Quadrática (QDA)</h3>
												<p class="lead mb-3 text-justify indent">A QDA é uma extensão do LDA que não assume que as classes têm a mesma matriz de covariância. Isso permite que o QDA capture relações não lineares entre as características.</p>
												<p class="lead mb-3 text-justify indent">Funcionamento do Algoritmo QDA:</p>
												<ol style="margin-left: 1cm;" class="alt4 lead mb-3 text-justify indent">
													<li>Calcula a média e a matriz de covariância para cada classe;</li>
													<li>Calcula a função discriminante quadrática para cada classe;</li>
													<li>Classifica novos pontos de dados com base na função discriminante que produz o maior valor.</li>
												</ol>
												<p class="lead mb-3 text-justify indent">Para ilustrar na prática uma aplicação do QDA abaixo é proposto um código muito similar ao utilizado no LDA, com pequenas diferenças que serão detalhadas a seguir.</p>
												<p class="lead mb-3 text-justify" id="link-codigo-07"><b>Código 7</b> - Processamento do algoritmo de análise discriminante quadrática (QDA)</p>
<pre><code># Importação das bibliotecas necessárias
from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split

# Carrega o conjunto de dados Iris
iris = load_iris()
X, y = iris.data, iris.target

# Divide os dados em conjuntos de treino e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Cria e treina o modelo QDA
qda = QuadraticDiscriminantAnalysis()
qda.fit(X_train, y_train)

# Realiza previsões e avalia a acurácia
accuracy = qda.score(X_test, y_test)
print(f"Acurácia do QDA: {accuracy:.2f}")</code></pre><br>
												<p class="lead mb-3 text-justify indent">Nessa primeira parte do código, somente a primeira linha possui alguma diferença.</p>
												<p class="lead mb-3 text-justify" id="link-codigo-08"><b>Código 8</b> - Importando as bibliotecas necessárias</p>
<pre><code># Importação das bibliotecas necessárias
from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split</code></pre><br>

												<p class="lead mb-3 text-justify">-<span class="highlight2">from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis</span>: 
													Este comando importa a classe referente ao <i>QDA</i> da biblioteca <i>scikit-learn</i>.</p>
												<p class="lead mb-3 text-justify indent">Outra parte que foi necessária adaptação é o emprego dessa classe mais a frente no código.</p>
												<p class="lead mb-3 text-justify" id="link-codigo-09"><b>Código 9</b> - Criando e treinando o modelo de análise discriminante quadrática (QDA)</p>
<pre><code># Cria e treina o modelo QDA
qda = QuadraticDiscriminantAnalysis()
qda.fit(X_train, y_train)</code></pre>
<br>
												<p class="lead mb-3 text-justify indent">De forma similar ao visto no QDA:</p>
												<ul style="margin-left: 1cm;" class="alt4 lead mb-3 text-justify indent">
													<li>-<span class="highlight2">qda = QuadraticDiscriminantAnalysis()</span>: Esta linha cria um modelo QDA que será utilizado para a classificação das amostras.</li>
													<li>-<span class="highlight2">qda.fit(X_train, y_train)</span>: O método fit treina o modelo LDA utilizando os dados de treinamento <span class="highlight2">X_train</span> e <span class="highlight2">y_train</span>.</li>
												</ul>
												<p class="lead mb-3 text-justify indent">Por fim, a apresentação dos resultados de acurácia também precisam ser adaptados.</p>
												<p class="lead mb-3 text-justify" id="link-codigo-10"><b>Código 10</b> - Realiza previsões e avalia a acurácia</p>
<pre><code># Realiza previsões e avalia a acurácia
accuracy = qda.score(X_test, y_test)
print(f"Acurácia do QDA: {accuracy:.2f}")</code></pre>
<br>
												<p class="lead mb-3 text-justify indent">Em comparação com o LDA em accuracy = <span class="highlight2">qda.score(X_test, y_test)</span>, 
													substitui-se <span class="highlight2">lda</span> por <span class="highlight2">qda</span> para que sejam capturados os score do modelo qda. De forma análoga, 
													em <span class="highlight2">print(f"Acurácia do QDA: {accuracy:.2f}")</span> é alterado o texto da impressão de LDA para QDA.</p>
												<h3 class="mb-0" id="uni6-4-4">6.4.4 Análise Discriminante Regularizada (RDA)</h3>
												<p class="lead mb-3 text-justify indent">A RDA é uma técnica que combina LDA e QDA, permitindo um equilíbrio entre os dois métodos através de um parâmetro de regularização.</p>
												<p class="lead mb-3 text-justify indent">O parâmetro de regularização é uma variável crucial que controla a complexidade do modelo e a forma como a regularização é aplicada. 
													A regularização é uma técnica utilizada para evitar o sobreajuste (<i>overfitting</i>), que ocorre quando um modelo se ajusta excessivamente aos dados de treinamento e 
													perde capacidade de generalização para novos dados.</p>
												<p class="lead mb-3 text-justify indent">Ele equilibra entre a matriz de covariância empírica (calculada diretamente a partir dos dados) e uma matriz diagonal  (uma matriz onde apenas as variâncias das variáveis são consideradas, e as covariâncias são ignoradas) com valores variando entre 0 e 1. Com valor 0, não é aplicada nenhuma regularização, portanto a matriz de covariância regularizada é igual à matriz de covariância empírica. Com valor 1, temos o máximo de regularização, ou seja, a matriz de covariância regularizada é igual à matriz de covariância diagonal. Valores intermediário de regularização a matriz de covariância regularizada é uma combinação ponderada entre a matriz de covariância empírica e a matriz de covariância diagonal.</p>
												<p class="lead mb-3 text-justify indent">Funcionamento do algoritmo RDA:</p>
												<ol style="margin-left: 1cm;" class="alt4 lead mb-3 text-justify indent">
													<li>Calcula a média de cada classe;</li>
													<li>Estima as matrizes de covariância de cada classe;</li>
													<li>Aplica regularização para ajustar as matrizes de covariância;</li>
													<li>Calcula a função discriminante regularizada;</li>
													<li>Classifica novos pontos de dados com base na função discriminante que produz o maior valor.</li>
												</ol>
												<p class="lead mb-3 text-justify" id="link-codigo-11"><b>Código 11</b> - Processamento do algoritmo de análise discriminante regularizada (RDA)</p>
<pre><code>from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split

# Carrega o conjunto de dados Iris
iris = load_iris()
X, y = iris.data, iris.target

# Divide os dados em conjuntos de treino e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Cria e treina o modelo RDA (usando LDA com shrinkage)
rda = LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto')
rda.fit(X_train, y_train)

# Realiza previsões e avalia a acurácia
accuracy = rda.score(X_test, y_test)
print(f"Acurácia do RDA: {accuracy:.2f}")</code></pre><br>
												<p class="lead mb-3 text-justify indent">Se compararmos o código proposto ao apresentado no LDA notam-se pequenas diferenças. 
													Não foi necessário a importação de um nova classe, sendo utilizada a mesma <span class="highlight2">LinearDiscriminantAnalysis</span> aplicada no LDA. 
													A principal mudança está no uso de alguns argumentos no momento da criação do modelo <span class="highlight2">rda</span>.</p>
													<p class="lead mb-3 text-justify" id="link-codigo-12"><b>Código 12</b> - Cria e treina o modelo RDA (usando LDA com <i>shrinkage</i>)</p>
<pre><code># Cria e treina o modelo RDA (usando LDA com shrinkage)
rda = LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto')
rda.fit(X_train, y_train)</code></pre><br>
												<ul style="margin-left: 1cm;" class="alt4 lead mb-3 text-justify indent">
													<li>-<span class="highlight2">rda = LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto')</span>: 
														cria o modelo <span>rda</span>, utilizando a regularização automática através do emprego do argumento <span class="highlight2">shrinkage='auto'</span>.</li>
													<li>-<span class="highlight2">shrinkage</span> é o parâmetro de regularização, visto anteriormente. O valor 'auto' encontrará o melhor valor de 
														regularização, porém pode ser alterado manualmente para valores entre 0 e 1.</li>
													<li>-<span class="highlight2">solver</span> é um parâmetro para escolher o algoritmo para encontrar a solução. 
														Para o uso com o RDA é necessário ajustá-lo para <span class="highlight2">‘lsqr’</span>, para utilizar o método dos mínimos quadrados; ou <span class="highlight2">‘eigen’</span>, 
														quando quer utilizar decomposição de autovalores. Somente com o uso desses 2 valores é  calculada a matriz de 
														covariância e o pode-se utilizar em conjunto o parâmetro <span class="highlight2">shrinkage</span>.</li>
												</ul>
												<h2 class="mb-0" id="uni-6-5"><i>Notebook Colab</i></h2>
												<p class="lead mb-3 text-justify indent">No <i>link</i> abaixo é possível ver a implementação dos algoritmos LDA, QDA e RDA explicados anteriormente, bem como alguns exercícios.</p>
												<div class="box">
													<p class="lead mb-3 text-center"><a class="break-all" href="https://colab.research.google.com/drive/1KyyJUAWqp15cqjTF_YQeSdCHZTPA04ic?ouid=109086597327779507567&usp=drive_link">
														https://colab.research.google.com/drive/1KyyJUAWqp15cqjTF_YQeSdCHZTPA04ic?ouid=109086597327779507567&usp=drive_link
													</a></p>
												</div>
												<p><span class="image right" style="width: 25%;"><img src="Robozinho/roboCuriosoLupaRoxoEsquerda.png" alt="" /></span></p>
												<div class="box2">
													<h3 class="mb-0" id="uni-6-saiba-mais">Saiba mais…</h3>
												<ul style="margin-left: 1cm;" class="alt4 lead mb-3 text-justify indent">
													<li>LDA:</li>
													<ul style="margin-left: 1cm;"class="alt4 lead mb-3 text-justify indent">
													<li>- Fisher, R. A. (1936). The use of multiple measurements in taxonomic problems. Annals of Eugenics, 7(2), 179-188.</li>
													<li>- <a class="break-all" href="https://www.geeksforgeeks.org/ml-linear-discriminant-analysis/">
														https://www.geeksforgeeks.org/ml-linear-discriminant-analysis/</a></li>
													<li>- <a href="https://www.youtube.com/watch?v=azXCzI57Yfc">https://www.youtube.com/watch?v=azXCzI57Yfc</a></li>
													<li>- <a href="https://www.youtube.com/watch?v=julEqA2ozcA">https://www.youtube.com/watch?v=julEqA2ozcA</a></li>
												</ul>
													<li>QDA: Smith, C. A. B. (1947). Some examples of discrimination. Annals of Eugenics, 13(1), 272-282.</li>
													<li>RDA: Friedman, J. H. (1989). Regularized discriminant analysis. Journal of the American Statistical Association, 84(405), 165-175.</li>
												</ul>	
												</div>
												<p><span class="image left" style="width: 25%;"><img src="Robozinho/roboCuriosoLapisRoxo.png" alt=" "/></span></p>
												<div class="box3">
													<h3 class="mb-0" id="6-relembrar">Para relembrar…</h3>
													<p class="lead mb-3 text-justify"><font color="#19032B">&#10132 </font>Cada algoritmo possui suas próprias características e é mais adequado para determinados tipos de problemas. A escolha do algoritmo depende das características dos dados, do objetivo da tarefa de classificação e dos requisitos de desempenho e interpretabilidade do modelo.</p>
													<p class="lead mb-3 text-justify" id="link-tabela-03"><b>Tabela 3</b> - Resumo das vantagens e desvantagens dos algoritmos que usam funções discriminantes</p>
													<div align="center">
														<span class="image fit" style="width: 70%;"><img src="images/Tabela 3.png" alt="" /></span>
														<p class="lead mb-2 text-center"><small>Fonte: Autoria própria.</small></p>
													</div>
												</div>
												</section>
													<hr class="m-0">
													<section>
														<div class="image main" id="capa_uni7">
															<img src="images/6. Unidade_7_Introdução a Machine Learning e Redes Neurais.png" alt="">
														</div>
													</section>
													<hr class="m-0">
													<section class="resume-section p-3 p-lg-5 d-flex align-items-center">
														<div class="w-100">
														<h1 class="mb-0" id="uni7">Unidade VII - Conjuntos de dados</h1>
													</div></header>
													
													<h2 class="mb-0" id="uni7-1">7.1 A Importância dos Dados para a Construção de Modelos de ML</h2>
													<p class="lead mb-3 text-justify indent">No ML, a qualidade dos dados é fundamental para o sucesso dos modelos preditivos. Dados robustos e bem preparados são a base para que os algoritmos possam extrair padrões relevantes e generalizar de maneira eficaz para novos casos. Um conjunto de dados rico e diversificado permite que os modelos sejam mais precisos e confiáveis, enquanto dados incompletos ou tendenciosos podem levar a resultados distorcidos e ineficazes. Portanto, a coleta, o processamento e a análise crítica dos dados são etapas cruciais na construção de sistemas inteligentes.
													</p>
													<p class="lead mb-3 text-justify indent">No contexto do ML, os dados são frequentemente referidos como a “matéria prima” que alimenta os modelos. A qualidade e a quantidade dos dados utilizados são fatores determinantes para o desempenho e a eficácia dos algoritmos. Para que um modelo de ML seja capaz de identificar padrões complexos e realizar previsões precisas, é essencial que os dados estejam devidamente coletados, limpos e preparados.
													</p>
													<p class="lead mb-3 text-justify indent">A qualidade dos dados se refere à precisão, completude, consistência e relevância das informações coletadas. Dados de alta qualidade possuem as seguintes características:
													</p>
													<ul style="margin-left: 1cm; list-style-type: disc; padding: 0; margin-bottom: 2%;" class="alt3 lead mb-3 text-justify indent" >
														<li><b>Precisão</b>: Os dados devem refletir a realidade de forma exata, sem erros ou distorções.</li>
														<li><b>Completude</b>: Um conjunto de dados completo sobre todas as variáveis relevantes para o problema que se deseja resolver, sem lacunas significativas.														</li>
														<li><b>Consistência</b>: Dados consistentes mantêm a coerência entre diferentes
															fontes e ao longo do tempo, sem contradições.</li>
														<li><b>Relevância</b>: Apenas os dados que são diretamente aplicáveis ao
															problema em questão devem ser utilizados, evitando o “ruído” de
															informações irrelevantes.</li>
													</ul>
													<p style="padding: 0; margin-top: 0;"    class="lead mb-3 text-justify indent">Quando a qualidade dos dados é alta, os modelos de ML são capazes de
														aprender de forma mais eficiente, resultando em previsões e classificações mais
														precisas.</p>
													<p class="lead mb-3 text-justify indent">Além da qualidade, a diversidade dos dados desempenha um papel crucial na
														robustez dos modelos. Dados diversos são aqueles que capturam uma ampla gama de
														variabilidades possíveis dentro do conjunto de informações. Isso inclui variações em
														termos de demografia, condições operacionais, comportamentos e cenários. Um
														modelo treinado em um conjunto de dados diversificado é mais provável de
														generalizar bem para novos casos que não foram observados durante o treinamento,
														reduzindo o risco de sobreajuste. Modelos treinados em dados que representam
														diversas populações e situações têm maior probabilidade de serem justos e precisos
														para todos os grupos, evitando vieses indesejados.</p>
													<p class="lead mb-3 text-justify indent">Por outro lado, dados incompletos ou tendenciosos podem comprometer
														significativamente a performance dos modelos de ML. Dados incompletos, com
														valores ausentes ou insuficientes para determinadas variáveis, podem levar a falhas
														na aprendizagem do modelo. Da mesma forma, dados tendenciosos, que não
														representam adequadamente a realidade ou que refletem vieses implícitos, podem
														resultar em modelos que perpetuam essas distorções.</p>
													<p class="lead mb-3 text-justify indent">Por exemplo, se um conjunto de dados para um modelo de classificação de
														crédito é composto majoritariamente por exemplos de uma única classe social ou
														região geográfica, o modelo pode aprender a associar características irrelevantes com
														o resultado desejado, prejudicando sua capacidade de generalização.</p>
													<p class="lead mb-3 text-justify indent">Dada a importância dos dados no ML, o processamento e a análise crítica
														desses dados são etapas que demandam atenção e rigor. O processamento envolve
														tarefas como limpeza dos dados, normalização, tratamento de valores ausentes e
														redução de dimensionalidade, todas elas voltadas a melhorar a qualidade dos dados
														antes de serem utilizados para treinar um modelo.</p>
													<p class="lead mb-3 text-justify indent">Além disso, a análise crítica dos dados requer uma compreensão profunda do
														domínio em questão para identificar possíveis vieses, outliers e inconsistências. Esta
														análise permite a correção de problemas antes que os dados sejam usados na
														construção do modelo, garantindo que o modelo seja treinado em dados que
														verdadeiramente representem o problema que se deseja resolver.</p>
														<wbr>

													<h2 class="mb-0" id="uni7-2">7.2 Dados Estruturados vs. Dados Não Estruturados</h2>
													<p style="padding: 0; margin-top: 0;"  class="lead mb-3 text-justify indent">Dados estruturados são aqueles organizados em uma estrutura predefinida,
														como em tabelas com linhas e colunas, facilitando a análise por meio de ferramentas
														de processamento de dados tradicionais. Já os dados não estruturados abrangem
														informações que não seguem um padrão de organização, como textos, imagens e
														vídeos, exigindo técnicas mais avançadas para serem analisados, como PLN e visão
														computacional. A capacidade de trabalhar com ambos os tipos de dados é essencial
														para aproveitar ao máximo o potencial da aprendizagem de máquina.</p>
													<p class="lead mb-3 text-justify indent">Os <b>dados estruturados</b> são organizados em um formato específico, como
														tabelas, facilitando a sua análise e processamento. Exemplos incluem:</p>
														<ul style="margin-left: 1cm; list-style-type: disc; padding: 0; margin-bottom: 2%;" class="alt3 lead mb-3 text-justify indent" >
															<li><b>Bases de Dados Relacionais</b>: Informações armazenadas em tabelas
																com linhas e colunas, como Sistemas de Gestão de Bancos de Dados
																(SGBD).</li>
															<li><b>Planilhas</b>: Dados organizados em colunas e linhas, como arquivos Excel
																ou Google Sheets.</li>
															<li><b>Formulários Online</b>: Respostas capturadas em campos específicos e
																padronizados.</li>											
														</ul>
													<p class="lead mb-3 text-justify indent">Os <b>dados não estruturados</b> não possuem um formato específico e são mais
														difíceis de organizar e analisar. Exemplos incluem:</p>
														<ul style="margin-left: 1cm; list-style-type: disc; padding: 0;" class="alt3 lead mb-3 text-justify indent" >
															<li><b>Texto Livre</b>: Documentos em texto, e-mails, mensagens de texto.</li>
															<li><b>Multimídia</b>: Imagens, vídeos, áudios.</li>
															<li><b>Postagens em Redes Sociais</b>: Conteúdos variados como texto, imagens
																e vídeos, frequentemente misturados.</li>													
														</ul>
														<p class="lead mb-3 text-center indent" id="link-figura-27"><b>Figura 27</b> - Exemplo de dados estruturados e não estruturados </p>
														<div>
															<span class="image fit"><img src="images/Figura 27.png" alt="" /></span>
															<p class="lead mb-2 text-center"><small> Fonte: Adaptada de <a href="https://k21academy.com/microsoft-azure/dp-900/structured-data-vs-unstructured-data-vs-semi-structured-data/"><u>Alam, 2024.</u></a></small></p>
														</div>

													<h2 class="mb-0" id="uni7-3">7.3 Conjuntos de Dados Supervisionados, Não Supervisionados e Semi-supervisionados</h2>
													<p class="lead mb-3 text-justify indent">Nos conjuntos de dados supervisionados, cada exemplo de treinamento inclui
														uma entrada e uma saída desejada, permitindo ao modelo aprender a relação entre
														elas. Em contraste, os conjuntos não supervisionados contêm apenas entradas,
														cabendo ao algoritmo descobrir padrões sem uma resposta direta para guiar o
														aprendizado. Já os conjuntos semi-supervisionados combinam uma pequena
														quantidade de dados rotulados com uma grande quantidade de dados não rotulados,
														aproveitando o melhor de ambas as abordagens para melhorar a precisão dos
														modelos.</p>
													<p class="lead mb-3 text-justify indent">Na figura abaixo (Figura 28) é ilustrado o mesmo conjunto de dados
														apresentado de duas maneiras: rotulados (em triângulos e quadrados) e não rotulados
														(em círculos). Os métodos supervisionados necessitam que todos os dados possuam
														rótulos, como em Modelo Supervisionado da Figura 28. Já os métodos não
														supervisionados não necessitam de rótulo e tentarão identificar apenas pelas
														características, como apresentado da porção Modelo Não Supervisionado. Por último,
														quando há parte dos dados com rótulo e parte sem rótulos, os métodos
														semi-supervisionados podem ser a melhor opção, como ilustrado na porção Modelo
														Semi-supervisionado da figura.</p>
													<p class="lead mb-3 text-center indent" id="link-figura-28"><b>Figura 28</b> - Exemplo de tipos de dados para diferentes modelos</p>
													<div>
														<span class="image fit"><img src="images/Figura 28.png" alt="" /></span>
														<p class="lead mb-2 text-center"><small> Fonte:  Adaptado de <a href="https://www.ncbi.nlm.nih.gov/books/NBK595448/bin/503777_1_En_13_Fig2_HTML.jpg"><u>Trambaiolli, Biazoli, Sato, 2022</u>.</a></small></p>
													</div>
													<p class="lead mb-3 text-justify indent">É possível encontrar publicamente uma série de conjuntos de dados, sejam eles
														supervisionados, semi-supervisionados ou não supervisionados para uso em conjunto
														com modelos de classificação, regressão, clusterização, etc. Alguns conjuntos de dados
														se tornaram icônicos no campo da aprendizagem de máquina pela sua relevância e
														frequente uso em estudos e aplicações. Conjuntos de dados padronizados são
														fundamentais para o desenvolvimento e a avaliação de algoritmos de aprendizado de
														máquina, pois permitem comparar o desempenho de diferentes abordagens em
														condições controladas. Dentre os conjuntos de dados mais amplamente utilizados
														estão o <b>Iris</b>, o <b>MNIST</b> e o <b>CIFAR-10</b>.</p>
													<p class="lead mb-3 text-justify indent">O conjunto <b>Iris</b>, por exemplo, é composto por 150 amostras de flores
														pertencentes à espécie Iris, distribuídas igualmente entre três subespécies. Cada
														amostra é caracterizada por quatro atributos numéricos que descrevem propriedades
														morfológicas das flores, e é utilizado principalmente em tarefas de classificação para
														prever a subespécie com base nessas características.</p>
													<p class="lead mb-3 text-justify indent">O <b>MNIST</b> é um extenso conjunto de 70,000 imagens de dígitos manuscritos,
														cada uma rotulada com um valor correspondente entre 0 e 9. Este conjunto é
														amplamente empregado em tarefas de reconhecimento de caracteres e serve como
														referência para avaliar o desempenho de algoritmos de classificação de imagens.</p>
													<p class="lead mb-3 text-justify indent">Por fim, o <b>CIFAR-10</b> consiste em 60,000 imagens coloridas de 32x32 pixels,
														distribuídas igualmente entre 10 categorias de objetos, como aviões, automóveis e
														animais. Este conjunto de dados é utilizado para testar e comparar algoritmos de
														classificação de imagens, especialmente em tarefas que envolvem reconhecimento de
														objetos em imagens coloridas.</p>
													<p class="lead mb-3 text-justify indent">A Tabela abaixo a seguir resume as principais características dos conjuntos de
														dados mencionados, fornecendo uma visão geral sobre seu tamanho, quantidade de
														dados rotulados e aplicação principal.</p>
													<p class="lead mb-3 text-center indent" id="link-figura-05"><b>Tabela 4</b> - Resumo dos Conjuntos de Dados Iris, MNIST e CIFAR-10</p>
													<div>
														<span class="image fit"><img src="images/Tabela 4.png" alt="" /></span>
														<p class="lead mb-2 text-center"><small> Fonte: Autoria própria</small></p>
													</div>

													<h2 class="mb-0" id="uni7-4">7.4 Limpeza de Dados (Tratamento de Valores Ausentes, <i>Outliers</i>, Erros de Digitação)</h2>
													<p class="lead mb-3 text-justify indent">A limpeza de dados é uma etapa essencial no processamento e análise de
														dados, visando a correção e aprimoramento da qualidade dos dados para garantir a
														eficácia das análises e a confiabilidade dos resultados. Abaixo, são abordados os
														principais aspectos da importância da limpeza de dados, bem como os conceitos
														fundamentais envolvidos nesse processo:</p>
														<ul style="margin-left: 1cm; list-style-type: disc; padding: 0; padding: 0; padding: 0; margin-bottom: 2%;" class="alt3 lead mb-3 text-justify indent" >
															<li><b>Confiabilidade</b>: Dados limpos e bem preparados são cruciais para garantir a
																confiabilidade das análises. Quando os dados estão isentos de erros e
																inconsistências, é possível obter percepções mais precisas e confiáveis, que
																refletem com maior exatidão a realidade que se pretende analisar. A presença
																de valores ausentes, duplicados ou errôneos pode comprometer a validade dos
																resultados e a tomada de decisões.</li>
															<li><b>Qualidade</b>: A qualidade dos dados é um fator determinante para a obtenção
																de percepções precisas. Dados bem limpos e estruturados fornecem uma base
																sólida para a realização de análises avançadas e a construção de modelos
																preditivos. A qualidade dos dados afeta diretamente a capacidade do modelo
																de aprender padrões significativos e generalizar para novos dados.</li>
															<li><b>Eficiência</b>: Dados
																bem
																estruturados
																e
																limpos
																facilitam
																a
																análise,
																economizando tempo e recursos. Ao resolver problemas como valores
																ausentes, duplicações e <i>outliers</i> de forma sistemática, a análise pode ser
																conduzida de maneira mais eficiente, permitindo que os analistas e cientistas
																de dados concentrem seus esforços na interpretação dos resultados em vez de
																corrigir problemas de dados.</li>
															<li><b>Valores Ausentes</b>: Valores ausentes referem-se a dados faltantes ou nulos em
																um conjunto de dados. Esses valores podem surgir por diversos motivos, como
																falhas na coleta de dados ou erros de entrada. A abordagem para tratar valores
																ausentes inclui a imputação, onde valores ausentes são substituídos por
																estimativas baseadas em outros dados, ou a interpolação, que utiliza os dados
																existentes para prever os valores faltantes.</li>
															<li><b>Valores Duplicados</b>: Valores duplicados são registros idênticos dentro do
																conjunto de dados que podem distorcer a análise e levar a resultados
																enviesados. A identificação e remoção de duplicatas são importantes para
																garantir que cada entrada seja considerada apenas uma vez, evitando
																redundâncias que podem afetar a precisão dos resultados analíticos.</li>
															<li><b><i>Outliers</i></b>: São valores que se desviam significativamente da maioria dos dados.
																Esses valores extremos podem influenciar desproporcionalmente os resultados
																das análises e dos modelos estatísticos. A detecção e tratamento de outliers são
																essenciais para evitar que eles distorçam a interpretação dos dados e a
																construção de modelos preditivos.</li>
															<li><b>Formatação</b>: A uniformidade na formatação dos dados refere-se à consistência
																nos formatos e na estrutura dos dados. Dados com formatos inconsistentes,
																como diferentes padrões de data ou variações na representação de números,
																podem causar erros e dificultar a análise. A padronização da formatação
																garante que todos os dados estejam no mesmo formato, facilitando a análise e
																a integração dos dados.</li>
														</ul>
													<p class="lead mb-3 text-justify indent">A limpeza de dados é uma etapa fundamental que assegura a precisão e a
															confiabilidade das análises. Ao tratar valores ausentes, duplicados e <i>outliers</i> eg arantir a uniformidade na formatação, é possível obter dados de alta qualidade que
															são essenciais para a construção de modelos eficazes e a realização de análises
															precisas.</p>

													<h2 class="mb-0" id="uni7-5">7.5 Pré-processamento (Normalização, Codificação de Variáveis Categóricas)</h2>
													<p class="lead mb-3 text-justify indent">O pré-processamento de dados é uma etapa crucial que prepara os dados para
														o treinamento do modelo. A normalização, como visto na unidade 5, ajusta a escala
														dos dados para garantir que todas as características contribuam igualmente para o
														aprendizado. Já a codificação de variáveis categóricas transforma essas variáveis em
														um formato numérico que os algoritmos podem processar, como a codificação <i>one-hot</i>
														ou a utilização de variáveis <i>dummy</i>.</p>
													<p class="lead mb-3 text-justify indent">A normalização ajusta a escala dos dados para garantir que todas as
														características tenham igual importância no processo de aprendizado. As duas
														técnicas comuns de normalização são: <i>Min-Max Scaling</i> e <i>Z-score Standardization</i>.</p>
													<p class="lead mb-3 text-justify indent">O <i>Min-Max Scaling</i>, também conhecido como normalização de intervalo,
														transforma os dados para um intervalo específico, geralmente [0, 1]. A fórmula
														utilizada é:</p>
														<p class="formula text-center"><a href="https://www.codecogs.com/eqnedit.php?latex=X_%7B%5Ctext%7Bnormalizado%7D%7D%20%3D%20%5Cfrac%7BX%20-%20X_%7B%5Ctext%7Bmin%7D%7D%7D%7BX_%7B%5Ctext%7Bmax%7D%7D%20-%20X_%7B%5Ctext%7Bmin%7D%7D%7D#0">
															<strong>X<small>normalizado</small></strong> = 
															<span class="fraction">
																<span class="numerator">X - X<small>min</small></span>
																<span class="denominator cursive">X<small>max</small> - X<small>min</small></span>
															</span></p>
																											
													<p class="lead mb-3 text-justify indent">Onde (X) é o valor original da característica,
														(X<small>min</small>)
														é o valor mínimo da característica,
														e (X<small>max</small>) é o valor máximo. Essa técnica é particularmente útil quando
														é necessário que os dados estejam em um intervalo fixo. No entanto, pode ser sensível
														a outliers, pois os valores extremos podem distorcer o intervalo de normalização.</p>
													<p class="lead mb-3 text-justify indent">A padronização pelo <i>Z-score</i>, também conhecida como normalização padrão,
														transforma os dados para que tenham média zero e desvio padrão um. A fórmula é:</p>
														<p class="formula text-center"><a href="https://www.codecogs.com/eqnedit.php?latex=X_%7B%5Ctext%7Bpadronizado%7D%7D%20%3D%20%5Cfrac%7BX%20-%20%5Cmu%7D%7B%5Csigma%7D#0">
															<strong>X<small>padronizado</small></strong> = 
															<span class="fraction">
																<span class="numerator">X - μ</span>
																<span class="denominator cursive">σ</span>
															</span></p>																												
													<p class="lead mb-3 text-justify indent">Onde (X) é o valor original, (μ) é a média dos valores da característica, e (σ) é o
														desvio padrão. Este método é útil para dados que não possuem uma distribuição
														uniforme ou quando se deseja que as características tenham a mesma escala,
														independentemente das unidades originais. É menos sensível a <i>outliers</i> em
														comparação ao <i>Min-Max Scaling</i>.</p>
													<p class="lead mb-3 text-justify indent">Algoritmos de aprendizado de máquina geralmente exigem que os dados
														estejam em formato numérico. Portanto, variáveis categóricas, que representam
														categorias ou rótulos, precisam ser convertidas em um formato que os algoritmos
														possam processar. As técnicas comuns para codificação de variáveis categóricas
														incluem:</p>
														<ul style="margin-left: 1cm; list-style-type: disc; padding: 0; padding: 0; margin-bottom: 2%;" class="alt3 lead mb-3 text-justify indent" >
															<li><b><i>One-Hot Encoding</i></b> que transforma uma variável categórica em uma série de
																colunas binárias, onde cada coluna representa uma categoria específica. Se
																uma variável categórica tem (k) categorias, será criada uma nova coluna para
																cada categoria, preenchida com 0s e 1s indicando a presença ou ausência
																daquela categoria. Esta técnica é adequada para variáveis categóricas sem
																ordem intrínseca e evita a introdução de uma ordem implícita. No entanto,
																pode
																aumentar
																significativamente
																a
																dimensionalidade
																dos
																dados,
																especialmente se o número de categorias for grande.</li>
															<li><b><i>Label Encoding</i></b> que atribui um valor numérico a cada categoria de uma
																variável categórica. Cada categoria é substituída por um número inteiro único.
																<i>Label Encoding</i> é útil para variáveis categóricas ordinais, onde a ordem das
																categorias é importante. No entanto, pode introduzir uma ordem artificial para
																variáveis categóricas nominais, o que pode ser inadequado para alguns
																algoritmos de aprendizado de máquina.</li>
														</ul>
													<p class="lead mb-3 text-justify indent">Na figura abaixo é possível compreender melhor como funciona cada uma das
														técnicas apresentadas. <i>Label Encoding</i> simplesmente atribui um número único a cada
														categoria, como 1 para "Apple", 2 para "Chicken" e 3 para "Broccoli". <i>One-Hot Encoding</i>, por outro lado, cria uma nova coluna para cada categoria e atribui 1 se a
														observação pertence àquela categoria e 0 caso contrário.</p>
														<p class="lead mb-3 text-center indent" id="link-figura-29"><b>Figura 29</b> - Exemplo de técnicas para criação de variáveis categóricas</p>
														<div>
															<span class="image fit"><img src="images/Figura 29.png" alt="" /></span>
															<p class="lead mb-2 text-center"><small> Fonte: Adaptada de <a href="https://medium.com/@michaeldelsole/what-is-one-hot-encoding-and-how-to-do-it-f0ae272f1179"><i>Medium, 2018.</i></a></small></p>
														</div>
														<p class="lead mb-3 text-justify indent">O pré-processamento de dados é fundamental para garantir que as
															características estejam na mesma escala e em um formato que os algoritmos de
															aprendizado de máquina possam processar efetivamente. A normalização, por meio
															do <i>Min-Max Scaling</i> e da <i>Z-score Standardization</i>, ajusta a escala dos dados para
															melhorar a convergência e o desempenho do modelo. A codificação de variáveis
															categóricas, utilizando técnicas como <i>One-Hot Encoding</i> e <i>Label Encoding</i>, converte
															categorias em formatos numéricos, preparando os dados para análise e modelagem.
															Estas práticas são essenciais para a construção de modelos precisos e robustos em
															aprendizado de máquina.</p>


													<h2 class="mb-0" id="uni7-6">7.6 Seleção e Engenharia de Características (Feature Selection e Feature Engineering)</h2>
													<p class="lead mb-3 text-justify indent">A seleção de características envolve escolher as variáveis mais relevantes para
														o modelo, o que pode aumentar sua eficácia e reduzir a complexidade. Por outro lado,
														a engenharia de características é a arte de criar novas variáveis a partir das
														existentes para capturar relações mais complexas entre os dados, que possam
														influenciar a predição e melhorar a capacidade preditiva do modelo. Ambos os
														processos são essenciais para otimizar o desempenho do modelo.</p>
													<p class="lead mb-3 text-justify indent">A seleção de características visa identificar e escolher o subconjunto mais
														relevante de atributos que melhor explicam a variabilidade da variável alvo. Ao
														reduzir a dimensionalidade dos dados, a seleção de características contribui para:</p>

														
													<ul style="margin-left: 1cm; list-style-type: disc; padding: 0; padding: 0; margin-bottom: 2%;" class="alt3 lead mb-3 text-justify indent" >
														<li><b>Melhora na performance</b>: A remoção de características irrelevantes ou
															redundantes
															pode
															reduzir
															o
															<i>overfitting</i>
															(sobreajuste)
															e
															aumentar
															a
															generalização do modelo.</li>
														<li><b>Redução da complexidade</b>: Modelos com menos características são mais
															simples de treinar, interpretar e manter.</li>
														<li><b>Diminuição do tempo de treinamento</b>: Menos características implicam em
															menor tempo de computação durante o treinamento do modelo.</li>								
													</ul>
													<p class="lead mb-3 text-justify indent">A engenharia de características é uma etapa que exige um profundo
														conhecimento do domínio do problema e criatividade. Abaixo algumas técnicas de
														engenharia de características:</p>
														<ul style="margin-left: 1cm; list-style-type: disc; padding: 0;" class="alt3 lead mb-3 text-justify indent" >
															<li><b>Transformações</b>: Aplicação
																de
																funções
																matemáticas
																como
																logaritmo,
																exponencial ou normalização para ajustar a distribuição dos dados.</li>
															<li><b>Combinações</b>: Criação de novas características a partir da combinação de
																duas ou mais características existentes, como a razão entre duas variáveis.</li>
															<li><b>Interações</b>: Consideração
																de interações entre características, como a multiplicação de duas variáveis.</li>													
															<li><b>Criação de features binárias</b>: Transformação de variáveis categóricas em
																variáveis binárias (<i>one-hot encoding</i>).</li>
															<li><b>Extração de features</b>: Aplicação de técnicas como PCA para reduzir a
																dimensionalidade e extrair as características mais relevantes.</li>
														</ul>

													<h2 class="mb-0" id="uni7-7">7.7 Divisão em Conjuntos de Treino, Validação e Teste</h2>
													<p class="lead mb-3 text-justify indent">A divisão dos dados em conjuntos de treino, validação e teste é fundamental
														para a avaliação objetiva dos modelos de ML. O conjunto de treino é utilizado para
														ajustar
														os
														parâmetros
														do
														modelo,
														o
														de
														validação
														é usado para ajustar
														hiperparâmetros e evitar <i>overfitting</i> (um ajuste excessivo do modelo), e o conjunto de
														teste fornece uma estimativa final da performance do modelo em dados não vistos,
														garantindo a generalização do modelo. Normalmente as proporções dos conjuntos são
														60% para treino, 20% para validação e 20% para teste.</p>
													<p class="lead mb-3 text-justify indent">Para ilustrar, na Figura 32 abaixo temos um conjunto de dados de fotos de
														cachorros e gatos, cujo objetivo é treinar modelos de classificação para diferenciar
														fotos de gatos das de cachorros. Uma parte dos dados originais é alocada para o
														conjunto de treino. O modelo de aprendizado de máquina "aprende" a partir desses
														dados, ajustando seus parâmetros internos para realizar a tarefa desejada (por
														exemplo, classificar imagens como gatos ou cachorros). Outra parte dos dados é
														reservada para o conjunto de validação. Esse conjunto é utilizado para ajustar os
														hiperparâmetros do modelo, como a taxa de aprendizado ou a complexidade do
														modelo. A ideia é encontrar a configuração que leva ao melhor desempenho do
														modelo no conjunto de validação, sem que ele "veja" esses dados durante o
														treinamento.</p>
													<p class="lead mb-3 text-justify indent">Os modelos treinados são avaliados no conjunto de validação. A avaliação
														permite comparar o desempenho de cada modelo e escolher o que apresenta os
														melhores resultados. O modelo que obtém o melhor desempenho no conjunto de
														validação é selecionado como o melhor modelo. Esse melhor modelo é finalmente
														avaliado em um conjunto de dados totalmente independente, chamado conjunto de
														teste. Esse conjunto nunca foi utilizado durante o treinamento ou a validação. A
														avaliação no conjunto de teste fornece uma estimativa mais realista do desempenho
														do modelo em dados nunca vistos antes. A acurácia é uma métrica que mede o
														desempenho do modelo no conjunto de teste e indica a porcentagem de exemplos que
														o modelo classificou corretamente.</p>
													<p class="lead mb-3 text-center indent" id="link-figura-30"><b>Figura 30</b> - Exemplo divisão do conjunto de dados</p>
													<div>
														<span class="image fit"><img src="images/Figura 30.png" alt="" /></span>
														<p class="lead mb-2 text-center"><small> Fonte: Adaptada de <a href="https://analisemacro.com.br/wp-content/uploads/2023/07/esquema2.png"><i> Silva, 2023.</i></a></small></p>
													</div>
													<p class="lead mb-3 text-justify indent"><b><i>Cross Validation</i></b></p>
													<p class="lead mb-3 text-justify indent">Frequentemente utilizado na fase de divisão dos conjuntos de dados, o
														<i>Cross-validation</i> (validação cruzada <i>k-fold</i>) é uma técnica estatística que permite
														avaliar a robustez do modelo ao dividir o conjunto de treino em várias partições e
														realizar treinamentos e validações múltiplas. Isso ajuda a garantir que o modelo não
														esteja sobreajustado (sofra <i>overfitting</i>) a um conjunto de dados específico favorecendo
														melhor desempenho do modelo para dados desconhecidos. Ao contrário da divisão
														tradicional em conjuntos de treino, validação e teste, a validação cruzada  <i>k-fold</i> 
														permite que todos os dados sejam utilizados tanto para treinamento quanto para
														teste, mitigando o impacto da aleatoriedade na divisão inicial dos dados.</p>
													<p class="lead mb-3 text-justify indent">Com base na Figura 31 abaixo, inicialmente o conjunto de dados é dividido em
														K partes (normalmente 5 ou 10), chamadas de <i>folds</i>, de tamanho aproximadamente
														igual. O processo é repetido K vezes (nesse caso 5), K-1 folds são combinados para
														formar o conjunto de treinamento (Folds em verde) e o <i>fold</i> restante é utilizado como
														conjunto de teste (fold em azul). O modelo é treinado em cada iteração (split) e
														avaliado no conjunto de teste correspondente (<i>fold</i> azul). As métricas de desempenho
														(acurácia, precisão, recall, etc.) obtidas em cada iteração são calculadas e uma média é
														tomada. Essa média representa a estimativa do desempenho do modelo.</p>
													<p class="lead mb-3 text-center indent" id="link-figura-31"><b>Figura 31</b> - Exemplo <i>k-fold</i></p>
													<div>
														<span class="image fit"><img src="images/Figura 31.png" alt="" /></span>
														<p class="lead mb-2 text-center"><small> Fonte: Adaptada de <a href="https://scikit-learn.org/stable/modules/cross_validation.html"><i>Scikit-learn, 2024.</i></a></small></p>
													</div>
													<p class="lead mb-3 text-justify indent">Ao utilizar todos os dados tanto para treinamento quanto para teste, o <i>k-fold</i>
														reduz o viés na estimativa do desempenho do modelo, que poderia ocorrer devido a
														uma divisão inicial aleatória não representativa. A média das métricas obtidas em
														todas as iterações fornece uma estimativa mais robusta e confiável do desempenho do
														modelo. O <i>k-fold</i> pode ajudar a identificar modelos que estão sofrendo de <i>overfitting</i>,
														ou seja, modelos que se ajustam muito bem aos dados de treinamento, mas
														apresentam um desempenho pobre em dados não vistos.</p>
													<p class="lead mb-3 text-justify indent">A validação cruzada <i>k-fold</i> é uma técnica poderosa e versátil para avaliar o
														desempenho de modelos de aprendizado de máquina. Ao garantir uma utilização
														mais eficiente dos dados e fornecer uma estimativa mais robusta do desempenho, o
														k-fold é uma ferramenta essencial no processo de desenvolvimento de modelos.</p>

													<h2 class="mb-0" id="uni7-8">7.8 Dados Desbalanceados e Técnicas para Balanceamento</h2>
													<p class="lead mb-3 text-justify indent">Conjuntos de dados desbalanceados ocorrem quando algumas classes têm
														muito mais exemplos do que outras, o que pode prejudicar o aprendizado do modelo.
														Técnicas como <i>oversampling</i> (aumentar a representatividade das classes minoritárias)
														e <i>undersampling</i> (reduzir a representatividade das classes majoritárias) são usadas
														para balancear o conjunto de dados e melhorar o desempenho do modelo.</p>
													<p class="lead mb-3 text-justify indent">Na figura abaixo há um exemplo de dados desbalanceados, nota-se a evidente
														diferença na quantidade de dados da classe 0 e 1, em azul e laranja respectivamente.</p>
													<p class="lead mb-3 text-center indent" id="link-figura-32"><b>Figura 32</b> - Exemplo dados desbalanceados</p>
													<div>
														<span class="image fit"><img src="images/Figura 32.png" alt="" /></span>
														<p class="lead mb-2 text-center"><small> Fonte: Adaptado de <a href="https://medicalfuturist.com/healthcare-trends-hype-cycle/"><i>Medium, 2022</i></a>.</small></p>
													</div>
													<p class="lead mb-3 text-justify indent">Modelos treinados com dados desbalanceados tendem a ser mais precisos na
														classificação da classe majoritária, ignorando ou classificando incorretamente os
														exemplos da classe minoritária. Isso ocorre porque o algoritmo busca minimizar o
														erro global, e a classe majoritária, por ter mais exemplos, exerce maior influência na
														função de custo.</p>
													<p class="lead mb-3 text-justify indent">A acurácia, uma métrica comumente utilizada para avaliar o desempenho de
														modelos de classificação, pode ser enganosa em casos de desbalanceamento. Um
														modelo que simplesmente classifica todos os exemplos como pertencentes à classe
														majoritária pode obter uma alta acurácia, mesmo que tenha um desempenho muito
														ruim na classificação da classe minoritária. Métricas como precisão, <i>recall</i> e <i>F1-score</i> são mais indicadas para avaliar o desempenho em problemas de classificação com
														dados desbalanceados. Essas métricas serão detalhadas na unidade de Classificação.</p>
													<p class="lead mb-3 text-justify indent">Existem diversas técnicas para lidar com o desbalanceamento de dados,
														buscando equilibrar a distribuição das classes e melhorar o desempenho dos
														modelos. As duas principais abordagens são: <i>Oversampling</i> e <i>Undersampling</i>. A
														primeira consiste em aumentar a representatividade da classe minoritária, gerando
														novos exemplos sintéticos. Na segunda busca-se reduzir a representatividade da
														classe majoritária, removendo aleatoriamente exemplos dessa classe.</p>
													<h3 class="mb-0" id="uni7-8-1">7.8.1 - Técnica de <i>oversampling</i></h3>
													<p class="lead mb-3 text-justify indent">O <b>SMOTE (<i>Synthetic Minority Over-sampling Technique</i>)</b> é uma das técnicas
														mais populares de oversampling. Ele cria novos exemplos sintéticos para a classe
														minoritária, interpolando os dados existentes em um espaço multidimensional. Essa
														técnica é eficaz em lidar com desbalanceamentos significativos e pode melhorar
														significativamente o desempenho do modelo na classificação da classe minoritária.
														Nela, dados artificiais são criados com base nos K vizinhos mais próximos. Observe a
														figura abaixo na qual são apresentadas duas classes, quadrados verdes e bolas azuis.
														O SMOTE segue os seguintes passos:</p>
														<ol style="margin-left: 1cm; padding: 0; margin-bottom: 2%;" class="alt3 lead mb-3 text-justify indent" >
															<li>Seleciona a classe minoritária (bolas em azul).</li>
															<li>Utiliza o KNN na classe minoritária com algum valor de K. Em outras palavras,
																seleciona os K vizinhos mais próximos de bola azul x1. Nesse caso o K é 3, por
																isso, os vizinhos mais próximos são x2, x3 e x4.</li>
															<li>Desenha-se linhas entre uma amostra da classe minoritária e seus K vizinhos.</li>
															<li>Escolhe um valor aleatório sobre essa linha. Nesse caso as bolas em vermelho
																s1, s2 e s3 são os valores aleatórios sobre essas linhas. Elas são os dados criados
																artificialmente para o balanceamento da classe de bolas azuis.</li>
														</ol>
													<p class="lead mb-3 text-justify indent">O processo se repete até que a quantidade de bolas (vermelhas + azuis) seja
														igual a quantidade de quadrados verdes.</p>
													<p class="lead mb-3 text-center indent" id="link-figura-33"><b>Figura 33</b> - Exemplo do funcionamento do SMOTE</p>
														<div>
															<span class="image fit"><img src="images/Figura 33.png" alt="" /></span>
															<p class="lead mb-2 text-center"><small> Fonte: Adaptada de <a href="https://i0.wp.com/varshasaini.in/wp-content/uploads/2022/07/smote.jpeg?w=1400&ssl=1"><i>Yang, 2022</i></a>.</small></p>
														</div>	
													<h3 class="mb-0" id="uni7-8-2">7.8.2 - Técnica de <i>undersampling</i></i></h3>
													<p class="lead mb-3 text-justify indent">O <i>RandomUnderSampler</i> é uma técnica simples de <i>undersampling</i> que
														remove aleatoriamente exemplos da classe majoritária até que as classes estejam
														balanceadas. Embora seja fácil de implementar, pode levar à perda de informações
														importantes, especialmente se a classe majoritária contiver padrões relevantes.</p>
													<p class="lead mb-3 text-justify indent">A escolha da técnica de balanceamento depende de diversos fatores, como:</p>
													<ul style="margin-left: 1cm; list-style-type: disc; padding: 0; margin-bottom: 2%;" class="alt3 lead mb-3 text-justify indent" >
														<li><b>Grau
															de
															desbalanceamento</b>: Para
															desbalanceamentos
															extremos,
															o
															oversampling pode ser mais eficaz.</li>
														<li><b>Tamanho do conjunto de dados</b>: Em conjuntos de dados pequenos, o
															<i>oversampling</i> pode levar ao <i>overfitting</i> (sobreajuste).</li>
														<li><b>Natureza dos dados</b>: A complexidade dos dados e a relação entre as features</li>
													</ul>
													<p class="lead mb-3 text-justify indent">O uso prático se estende a diversas aplicações, porém um exemplo didático é a
														detecção de fraudes em cartões de crédito, onde a classe "fraude" é significativamente
														menor do que a classe "não fraude". Ao aplicar o SMOTE, novos exemplos de fraudes
														sintéticas seriam gerados, tornando a distribuição das classes mais equilibrada. Isso
														permitiria que o modelo aprendesse a identificar padrões associados a fraudes com
														maior precisão.</p>
													<p class="lead mb-3 text-justify indent">O tratamento de dados desbalanceados é um desafio comum em aprendizado
														de máquina. A escolha da técnica de balanceamento adequada depende das
														características do conjunto de dados e dos objetivos da análise. Ao utilizar técnicas
														como <i>oversampling</i> e <i>undersampling</i>, é possível melhorar significativamente o
														desempenho dos modelos de classificação em problemas com classes desbalanceadas.</p>

													<h2 class="mb-0" id="uni7-9">7.9 Subajuste (<i>Underfitting</i>) e Sobreajuste (<i>Overfitting</i>)</h2>
													<p class="lead mb-3 text-justify indent">Subajuste, ou mais comumente conhecido como <i>Underfitting</i>, ocorre quando
														um modelo é muito simples e não consegue capturar as tendências dos dados de
														treino, resultando em baixo desempenho tanto no treino quanto no teste. Sobreajuste,
														ou melhor conhecido como <i>Overfitting</i>, por outro lado, acontece quando um modelo
														se ajusta excessivamente aos dados de treino, memorizando ruídos e peculiaridades,
														e falha em generalizar para novos dados. Técnicas como validação cruzada,
														regularização e seleção de modelos são usadas para encontrar um equilíbrio ideal e
														evitar esses problemas. Ambos representam situações em que o modelo não consegue
														capturar adequadamente as relações entre as variáveis, resultando em um
														desempenho insatisfatório.</p>
													<p class="lead mb-3 text-justify indent">O <i>underfitting</i> ocorre quando um modelo é muito simples para capturar a
														complexidade dos dados. Ele não consegue aprender as relações subjacentes entre as
														<i>features</i> (características) e o <i>target</i> (variável alvo), resultando em um alto erro tanto
														no conjunto de treinamento quanto no conjunto de teste. Um exemplo é o ajuste de
														uma linha reta a dados que seguem um padrão não linear, como o ilustrado na figura
														abaixo e a esquerda. As principais causas são:</p>

													<ul style="margin-left: 1cm; list-style-type: disc; padding: 0; margin-bottom: 2%;" class="alt3 lead mb-3 text-justify indent" >
														<li><b>Modelo subespecificado</b>: O modelo escolhido não possui a complexidade
															necessária para representar os dados. Por exemplo, utilizar uma regressão
															linear para modelar dados não lineares.</li>
														<li><b>Poucos dados de treinamento</b>: A quantidade de dados disponíveis é
															insuficiente para o modelo aprender as relações complexas entre as <i>features</i>.</li>
														<li><b>Características irrelevantes</b>: A inclusão de características que não possuem
															relação com a variável alvo pode dificultar o aprendizado do modelo.</li>														
													</ul>
													<p class="lead mb-3 text-justify indent">Existem algumas maneiras de mitigação desses problemas, algumas técnicas
														são:</p>
													<ul style="margin-left: 1cm; list-style-type: disc; padding: 0;" class="alt3 lead mb-3 text-justify indent" >
														<li><b>Aumentar
															a complexidade do modelo</b>: Utilizar modelos com mais
															parâmetros, como redes neurais com mais camadas ou polinômios de maior
															grau.</li>
														<li><b>Adicionar mais <i>features</i></b>: Incluir características relevantes que possam ajudar
															o modelo a capturar as relações subjacentes.</li>														
													</ul>
													<p class="lead mb-3 text-justify indent">O <i>overfitting</i> ocorre quando um modelo se ajusta excessivamente aos dados de
														treinamento, memorizando o ruído presente nos dados e perdendo a capacidade de
														generalizar para novos dados. É como ajustar uma curva muito complexa a um conjunto de pontos, capturando até mesmo as pequenas variações aleatórias, como o
														ilustrado na figura abaixo e a direta. As principais causas são:</p>
													<ul style="margin-left: 1cm; list-style-type: disc; padding: 0;" class="alt3 lead mb-3 text-justify indent" >
														<li><b>Modelo superparametrizado</b>: O modelo possui muitos parâmetros, o que
															permite que ele memorize os dados de treinamento em vez de aprender as
															relações gerais.</li>
														<li><b>Poucos dados de treinamento em relação à complexidade do modelo</b>: Quando o modelo é muito complexo em relação à quantidade de dados, ele
															tende a sobreajustar.</li>
														<li><b>Ruído nos dados</b>: A presença de ruído nos dados pode levar o modelo a
															ajustar-se a padrões aleatórios, em vez das relações subjacentes.</li>														
													</ul>
													<p class="lead mb-3 text-justify indent">Existem algumas maneiras de mitigação desses problemas, algumas técnicas
														são:</p>
													<ul style="margin-left: 1cm; list-style-type: disc; padding: 0;" class="alt3 lead mb-3 text-justify indent" >
														<li><b>Reduzir
															a
															complexidade
															do
															modelo</b>: Utilizar modelos com menos
															parâmetros, como redes neurais com menos camadas ou polinômios de menor
															grau.</li>
														<li><b>Aumentar a regularização</b>: A regularização penaliza modelos complexos,
															evitando que eles se ajustem demais aos dados de treinamento.</li>
														<li><b>Coleta de mais dados</b>: Aumentar a quantidade de dados de treinamento pode
															ajudar a reduzir o <i>overfitting</i> (sobreajuste), pois o modelo terá mais exemplos
															para aprender.</li>
														<li><b>Validação cruzada</b>: A validação cruzada permite avaliar o desempenho do
															modelo em diferentes subconjuntos dos dados, ajudando a identificar o
															<i>overfitting</i> (sobreajuste).</li>
														<li><b><i>Dropout</i></b>: Uma técnica utilizada em redes neurais que desativa aleatoriamente
															neurônios durante o treinamento, forçando o modelo a não depender
															excessivamente de nenhum neurônio em particular.</li>
													</ul>
													<p class="lead mb-3 text-justify indent">O objetivo do aprendizado de máquina é encontrar um modelo que seja capaz
														de generalizar bem para novos dados, evitando tanto o underfitting quanto o
														<i>overfitting</i> (sobreajuste), como o ilustrado na figura abaixo e ao centro. A escolha da
														técnica adequada para mitigar esses problemas depende das características dos dados
														e do modelo utilizado.</p>
													<p class="lead mb-3 text-center indent" id="link-figura-34"><b>Figura 34</b> - Exemplo ajustes de curvas</p>
													<div>
														<span class="image fit"><img src="images/Figura 34.png" alt="" /></span>
														<p class="lead mb-2 text-center"><small> Fonte: <a href="https://miro.medium.com/v2/resize:fit:828/format:webp/1*dpUnwfXqnU5Kd-gfafgIgQ.png"><i>Medium, 2022</i></a>.</small></p>
													</div>

													<h2 class="mb-0" id="uni7-10">7.10 <i>Notebook Colab</i>:</h2>
													<p class="lead mb-3 text-justify indent">No link do colab serão abordados exemplos práticos e exercícios de dados
														estruturados e não estruturados, tipos conjunto de dados; limpeza dos dados; pré
														processamento; divisão do conjuntos de dados em treino, validação e teste; dados
														balanceados e desbalanceados; <i>underfitting</i> e <i>overfitting</i> (sobreajuste).</p>
													<div class="box">
														<div class="lead mb-3 text-center"><a href="https://colab.research.google.com/drive/1s0wK-XDQOdUubutjqhJVQL-6q6jKAfy9">https://colab.research.google.com/drive/1s0wK-XDQOdUubutjqhJVQL-6q6jKAfy9</a></div>																								
													</div>
													<p><span class="image right" style="width: 25%;"><img src="Robozinho/roboCuriosoLapisRoxo.png" alt="" /></span></p>
													<div class="box2">
														<h3 class="mb-0" id="1-saiba-mais">Para relembrar…</h3>
														<p class="lead mb-3 text-justify">Lembre-se da importância dos dados no ML, um dado de entrada ruim
															resultará em modelos ruins, por isso é muito importante estar atento aos dados e os
															efeitos de treinar o modelo sem entender corretamente o que está ocorrendo.
															Tenha sempre em mente:</p>
															<ul style="margin-left: 1cm; list-style-type: disc; padding: 0;" class="alt3 lead mb-3 text-justify indent" >
																<li>Qualidade dos dados como base para modelos eficazes</li>
																<li>Diferenças entre dados estruturados e não estruturados</li>
																<li>Tipos de conjuntos de dados: supervisionados, não supervisionados e
																	semi-supervisionados</li>
																<li>Processos de limpeza e pré-processamento de dados</li>
																<li>Seleção e engenharia de características</li>
																<li>Divisão dos dados em conjuntos de treino, validação e teste</li>
																<li>Técnica de <i>cross-validation</i></li>
																<li>Tratamento de dados desbalanceados</li>
																<li>Problemas de subajuste (<i>underfitting</i>) e sobreajuste (<i>overfitting</i>)</li>
															</ul>
														</div>
														<p><span class="image left" style="width: 25%;"><img src="Robozinho/roboCuriosoLupaRoxoEsquerda.png" alt="" /></span></p>
													<div class="box3">
														<h3 class="mb-0" id="1-saiba-mais">Saiba mais…</h3>
														<ul style="margin-left: 1cm; list-style-type: disc; padding: 0;" class="alt3 lead mb-3 text-justify indent">
															<li><a href="https://www.youtube.com/watch?v=KWtrhdSWuSQ&t=1072s">Conjunto de Dados</a></li>
															<li><a href="https://www.youtube.com/watch?v=jQIOCMlDAs0%20https://www.youtube.com/watch?v=EuBBz3bI-aA&t=1s">Subajuste e sobreajuste</a> </li>
															<li><a href="https://www.youtube.com/watch?v=Gzn6srbzU30">Dados desbalanceados</a></li>
															<li><a href="https://youtu.be/fSytzGwwBVw?si=d4cEPTUCvxsc1U2s">Validação cruzada</a></li>															
														</ul>														
													</div>


													
													</section>
														<hr class="m-0">
														<section>
															<div class="image main" id="capa_uni8">
																<img src="images/6. Unidade_8_Introdução a Machine Learning e Redes Neurais.png" alt="">
															</div>
														</section>
														<hr class="m-0">
														<section class="resume-section p-3 p-lg-5 d-flex align-items-center">
															<div class="w-100">
															<h1 class="mb-0" id="uni8">Unidade VIII - Regressão</h1>
														</div></header>
														
														<p class="lead mb-3 text-justify indent">A regressão, no contexto do ML, constitui uma técnica estatística fundamental
															para modelar a relação entre uma variável dependente contínua e uma ou mais
															variáveis independentes. Variável dependente contínua é aquela que estamos
															tentando prever ou explicar e que pode assumir qualquer valor numérico dentro de
															um intervalo. Ela é "dependente" porque seu valor é influenciado pelos valores de
															outras variáveis. Variáveis independentes são aquelas que utilizamos para prever o
															valor da variável dependente. Elas são chamadas de "independentes" porque,
															teoricamente, seus valores não são influenciados por outras variáveis no modelo. Um
															exemplo prático seria na previsão de consumo de energia em que a variável
															dependente contínua seria o consumo de energia em kWh (um valor numérico). As
															variáveis independentes poderiam ser: temperatura externa, número de pessoas na
															residência, hora do dia, etc. A variável dependente é o "efeito" que queremos explicar.
															As variáveis independentes são as "causas" que influenciam o efeito.</p>
														<p class="lead mb-3 text-justify indent">Essa metodologia, amplamente utilizada em diversas áreas do conhecimento,
															permite realizar previsões quantitativas com base em padrões identificados nos
															dados. Ao ajustar um modelo de regressão a um conjunto de dados, os cientistas de
															dados podem estimar o valor da variável dependente para novos conjuntos de dados,
															o que é de grande valor para tomada de decisões em diversos setores, como
															economia, finanças, indústria e <i>marketing</i>.</p>
														<p class="lead mb-3 text-justify indent">A escolha do modelo de regressão mais adequado depende das características
															dos dados e do problema a ser resolvido. Existem diversos tipos de regressão, cada
															um com suas particularidades e aplicações. A regressão linear, por exemplo, é a mais
															simples e amplamente utilizada, modelando a relação entre as variáveis através de
															uma equação linear. Já a regressão polinomial permite modelar relações não lineares,
															enquanto a regressão logística é utilizada para problemas de classificação, onde a
															variável dependente é binária.</p>
														<p class="lead mb-3 text-justify indent">A importância da regressão no ML reside na sua capacidade de extrair
															informações valiosas a partir de dados complexos. Ao identificar as relações entre as
															variáveis, os modelos de regressão podem ser utilizados para entender os fatores que
															influenciam um determinado fenômeno, otimizar processos, tomar decisões mais precisas e gerar novas hipóteses para pesquisa. Além disso, a regressão é uma técnica
															fundamental para outras técnicas de ML, como a árvore de decisão e a floresta
															aleatória.</p>
														<p class="lead mb-3 text-justify indent">Enquanto a regressão foca na predição de variáveis contínuas, como preços,
															temperaturas ou índices, a classificação é empregada para atribuir instâncias a
															categorias discretas. Por exemplo, determinar se um e-mail é <i>spam</i> ou não é um
															problema de classificação binária. Já prever a temperatura máxima para o próximo
															dia é um problema típico de regressão. A distinção entre esses dois tipos de
															problemas é crucial, pois os métodos e métricas de avaliação são distintos e a escolha
															do modelo adequado depende dessa compreensão.</p>
														<p class="lead mb-3 text-justify indent"><p class="lead mb-3 text-justify indent"> </p></p>
														
														<h2 class="mb-0" id="uni8-1">8.1 Métricas de Avaliação</h2>
														<h3 class="mb-0" id="uni8-1-1">8.1.1 Coeficiente de Determinação R<sup>2</sup></h3>
														<p class="lead mb-3 text-justify indent">O coeficiente de determinação mede a proporção da variabilidade da variável
															dependente que é explicada pelas variáveis independentes no modelo. Os valores
															obtidos dessa métrica variam entre 0 e 1. Um valor de 1 indica que o modelo explica
															toda a variância dos dados, enquanto um valor de 0 indica que o modelo não explica
															nenhuma variância. O Coeficiente de Determinação, R<sup>2</sup>, é calculado como:</p>
															<p class="text-center">
																<span style="font-size: 1.5em;">\( R^2 = 1 - \frac{\sum_{i=1}^{n} (y_i - \hat{y_i})^2}{\sum_{i=1}^{n} (y_i - \bar{y})^2} \)</span>
															</p>
															
																														
															<p class="lead mb-3 text-justify indent">onde:</p>	
															<ul style="margin-left: 1cm; list-style-type: disc; padding: 0;" class="alt3 lead mb-3 text-justify indent" >
																<li>\( y_i \) são os valores reais,</li>
																<li>\( \hat{y}_i \) são os valores preditos pelo modelo,</li>
																<li>\( \bar{y} \) é a média dos valores reais,</li>
														
																<li><span>\( \sum\limits_{i=1}^{n} (y_i - \hat{y_i})^2 \)</span> é a Soma dos Quadrados dos Resíduos (SSR),
																</li>
																<li> <span>\( \sum\limits_{i=1}^{n} (y_i - \bar{y})^2 \)</span>
																	 é a Soma Total dos Quadrados (SST).</li>
															</ul>
															<p class="lead mb-3 text-justify indent">O valor de R<sup>2</sup> varia entre 0 e 1:</p>
															<ul style="margin-left: 1cm; list-style-type: disc; padding: 0;" class="alt3 lead mb-3 text-justify indent" >
																<li>R<sup>2</sup> = 0  indica que o modelo não explica nenhuma variação nos dados.</li>
																<li>R<sup>2</sup> = 1  indica que o modelo explica toda a variação nos dados.</li>																
															</ul>
															<p class="lead mb-3 text-justify indent">De forma facilitar a compreensão, a figura abaixo ilustra a aplicação das
																parcelas SSR e SST.</p>
															<p class="lead mb-3 text-justify indent"><b>Variabilidade
																Não
																Explicada
																(SSR):</b>
																As
																linhas
																pontilhadas
																laranja
																representam os erros do modelo, ou seja, a diferença entre o valor real (ponto em
																azul) e sua projeção ao modelo (linha vermelha). Quanto menores forem essas linhas,
																melhor o modelo se ajusta aos dados.</p>
															<p class="lead mb-3 text-justify indent"><b>Variabilidade Total (SST):</b> A linha horizontal verde representa a média dos
																dados. A distância entre os pontos e a linha representa a variabilidade total dos
																dados. O primeiro gráfico mostra a variabilidade que o modelo não consegue
																explicar.</p>
															<p class="lead mb-3 text-justify indent">Quanto menor a distância entre os pontos e a linha de regressão, melhor o
																modelo se ajusta aos dados. O segundo gráfico mostra a variabilidade total dos dados.
																Comparando os dois gráficos, pode-se ter uma ideia de quanto da variabilidade total
																está sendo explicada pelo modelo.</p>
															<p class="lead mb-3 text-center indent" id="link-figura-35"><b>Figura 35</b> - Exemplo R<sup>2</sup></p>
															<div>
																<span class="image fit"><img src="images/Figura 35.png" alt="" /></span>
																<p class="lead mb-2 text-center"><small> Fonte: Elaborado pelo autor e disponível no <i>Google colab</i>.</small></p>
															</div>
														<h3 class="mb-0" id="uni8-1-2">8.1.2 Erro Quadrático Médio (MSE)</h3>
														<p class="lead mb-3 text-justify indent">O Erro Quadrático Médio, <i>Mean Squared Error</i> (MSE) é uma métrica utilizada para avaliar a performance de um modelo de regressão. Ele calcula a média dos
															quadrados das diferenças entre os valores observados (reais) e os valores preditos
															pelo modelo. O MSE é definido como:</p>
															<p class="formula text-center" >
																<strong>MSE</strong> = 
																<span class="fraction">
																	<span class="numerator">1</span>
																	<span class="denominator cursive">n</span>
																</span>
																<span class="summation">
																	<sup class="cursive">n</sup>
																	&sum;
																	<sub class="cursive">i=1</sub>
																</span>
																(<span class="cursive">y<small>i</small></span> - <span class="cursive">&#x0177<small>i</small></span>)²
															</p>															
															<p class="lead mb-3 text-justify indent">onde:</p>	
															<ul style="margin-left: 1cm; list-style-type: disc; padding: 0;" class="alt3 lead mb-3 text-justify indent" >
																<li>y<sub>i</sub> são os valores reais,</li>
																<li>ŷ<sub>i</sub> são os valores preditos pelo modelo,</li>
																<li>n é o número de observações.</li>															
															</ul>
														<p class="lead mb-3 text-justify indent">O MSE penaliza erros grandes mais severamente do que erros pequenos
															devido ao uso do quadrado das diferenças. Um MSE menor indica um modelo com
															melhor performance, enquanto um MSE maior indica um modelo com pior
															performance. De forma facilitar a compreensão, a figura abaixo ilustra o MSE. 1. No
															primeiro gráfico (Resíduos ao Quadrado), tem-se:</p>
															<ul style="margin-left: 1cm; list-style-type: disc; padding: 0;" class="alt3 lead mb-3 text-justify indent" >
																<li>Os pontos azuis representam os dados reais.</li>
																<li>A linha vermelha representa a linha de regressão ajustada pelo modelo.</li>
																<li>As linhas tracejadas laranja e os pontos laranja representam <b>os erros
																	individuais ao quadrado</b>, mostrando as diferenças entre os valores
																	observados e preditos.</li>																
															</ul>
															<p class="lead mb-3 text-justify indent">No segundo gráfico da figura abaixo (MSE), tem-se:</p>
															<ul style="margin-left: 1cm; list-style-type: disc; padding: 0;" class="alt3 lead mb-3 text-justify indent" >
																<li>Os pontos azuis representam os dados reais.</li>
																<li>A linha vermelha representa a linha de regressão ajustada pelo modelo.</li>
																<li>A linha tracejada roxa horizontal representa o MSE, que é a média dos
																	resíduos ao quadrado.</li>																
															</ul>
															<p class="lead mb-3 text-center indent" id="link-figura-36"><b>Figura 36</b> - Exemplo MSE</p>
															<div>
																<span class="image fit"><img src="images/Figura 36.png" alt="" /></span>
																<p class="lead mb-2 text-center"><small> Fonte: Elaborado pelo autor e disponível no <i>Google colab</i>.</small></p>
															</div>
														<h3 class="mb-0" id="uni8-1-3"><h3 class="mb-0" id="uni8-1-3">8.1.3 Erro Absoluto Médio (MAE)</h3>
														<p class="lead mb-3 text-justify indent">O MAE mede a magnitude média dos erros em um conjunto de previsões, sem
															considerar sua direção. É uma métrica linear, o que significa que todos os erros são
															ponderados igualmente. Quanto menor o MAE, melhor o modelo. Penaliza de forma
															linear todos os erros.</p>
														<p class="lead mb-3 text-justify indent">O <i>Mean Absolute Error</i> (MAE) é definido como:</p>
														<p class="formula text-center"><span style="font-size: 1.5em;">\( MAE = \frac{1}{n} \sum_{i=1}^{n} |y_i - \hat{y_i}|\)</span>
															</p>													
														
														<p class="lead mb-3 text-justify indent">onde:</p>	
															<ul style="margin-left: 1cm; list-style-type: disc; padding: 0;" class="alt3 lead mb-3 text-justify indent" >
																<li>\( y_i \) são os valores reais,</li>
																<li>\( \hat{y}_i \) são os valores preditos pelo modelo,</li>
																<li>\( n \) é o número de observações.</li>														
															</ul>
														<p class="lead mb-3 text-justify indent">De forma facilitar a compreensão, a figura abaixo ilustra o MAE. No primeiro
															gráfico (Erros Absolutos Individuais) tem-se:</p>
															<ul style="margin-left: 1cm; list-style-type: disc; padding: 0;" class="alt3 lead mb-3 text-justify indent" >
																<li>Os pontos azuis representam os dados reais.</li>
																<li>A linha vermelha representa a linha de regressão ajustada pelo modelo.</li>
																<li>As linhas tracejadas laranja e os pontos laranja representam os <b>erros
																	absolutos individuais</b>, ou seja, as diferenças absolutas entre os valores
																	observados e os valores preditos.</li>																
															</ul>
														<p class="lead mb-3 text-justify indent">No segundo gráfico (MAE) tem-se:</p>
														<ul style="margin-left: 1cm; list-style-type: disc; padding: 0;" class="alt3 lead mb-3 text-justify indent" >
															<li>Os pontos azuis representam os dados reais.</li>
															<li>A linha vermelha representa a linha de regressão ajustada pelo modelo.</li>
															<li>A linha tracejada roxa horizontal representa o valor do MAE, que é a média
																dos erros absolutos.</li>															
														</ul>
														<p class="lead mb-3 text-center indent" id="link-figura-37"><b>Figura 37</b> - Exemplo MAE</p>
														<div>
															<span class="image fit"><img src="images/Figura 37.png" alt="" /></span>
															<p class="lead mb-2 text-center"><small> Fonte: Elaborado pelo autor e disponível no <i>Google colab</i>.</small></p>
														</div>
														<h3 class="mb-0" id="uni8-1-4"><h3 class="mb-0" id="uni8-1-4">8.1.4 Raiz do Erro Quadrático Médio (RMSE)<sup>2</sup></h3>
														<p class="lead mb-3 text-justify indent">A raiz quadrada do MSE, traz a medida de erro para a mesma escala da
															variável dependente. Quanto menor o RMSE, melhor o modelo. Ela possui a mesma
															unidade dos dados originais e penaliza mais os erros grandes.</p>
														<p class="lead mb-3 text-justify indent">O <i>Root Mean Squared Error</i> (RMSE) é definido como:</p>
														<p class="formula text-center" >
															<strong>RMSE</strong> = 
															<span>&#8730;</span>															
															<span class="fraction">
																<span class="numerator"> 1</span>
																<span class="denominator cursive">n</span>
															</span>
															<span class="summation">
																<sup class="cursive">n</sup>
																&sum;
																<sub class="cursive">i=1</sub>
															</span>
															(<span class="cursive">y<small>i</small></span> - <span class="cursive">&#x0177<small>i</small></span>)²
														
														</p>														
														<p class="lead mb-3 text-justify indent">onde:</p>
														<ul style="margin-left: 1cm; list-style-type: disc; padding: 0;" class="alt3 lead mb-3 text-justify indent" >
															<li>y<sub>i</sub> são os valores reais,</li>
															<li>ŷ<sub>i</sub> são os valores preditos pelo modelo,</li>
															<li>n é o número de observações.</li>															
														</ul>
														<p class="lead mb-3 text-justify indent">O RMSE penaliza mais severamente grandes erros devido ao uso do quadrado
															das diferenças, similar ao MSE, mas retorna os erros na mesma unidade dos valores
															observados.</p>
														<p class="lead mb-3 text-justify indent">De forma facilitar a compreensão, a figura abaixo ilustra o MAE. No primeiro
															gráfico (Quadrados dos Resíduos Individuais) tem-se:</p>
														<ul style="margin-left: 1cm; list-style-type: disc; padding: 0;" class="alt3 lead mb-3 text-justify indent" >
															<li>Os pontos azuis representam os dados reais.</li>
															<li>A linha vermelha representa a linha de regressão ajustada pelo modelo.</li>
															<li>As linhas tracejadas laranja e os pontos laranja representam os quadrados dos
																resíduos individuais, ou seja, as diferenças ao quadrado entre os valores
																observados e os valores preditos.</li>															
														</ul>
														<p class="lead mb-3 text-justify indent">No segundo gráfico (RMSE), tem-se:</p>
														<ul style="margin-left: 1cm; list-style-type: disc; padding: 0;" class="alt3 lead mb-3 text-justify indent" >
															<li>Os pontos azuis representam os dados reais.</li>
															<li>A linha vermelha representa a linha de regressão ajustada pelo modelo.</li>
															<li>A linha tracejada roxa horizontal representa o valor do RMSE, que é a raiz
																quadrada da média dos resíduos ao quadrado.</li>															
														</ul>
														<p class="lead mb-3 text-center indent" id="link-figura-38"><b>Figura 38</b> - Exemplo RMSE</p>
														<div>
															<span class="image fit"><img src="images/Figura 38.png" alt="" /></span>
															<p class="lead mb-2 text-center"><small> Fonte: Gerado pelo autor e disponível no <i>Google colab</i>.</small></p>
														</div>
														<p class="lead mb-3 text-justify indent">No Quadro 2 abaixo é apresentado um resumo das vantagens e desvantagens
															das métricas acima explicadas. Há também a fórmula para cada uma na qual:</p>
														<ul style="margin-left: 1cm; list-style-type: disc; padding: 0;" class="alt3 lead mb-3 text-justify indent" >
															<li>y<sub>i</sub> são os valores reais,</li>
															<li>ŷ<sub>i</sub> são os valores preditos pelo modelo,</li>
															<li>n é o número de observações.</li>															
														</ul>
														<p class="lead mb-3 text-center indent" id="link-quadro-2"><b>Quadro 2</b> - Comparativo entre as métricas abordadas resume essa seção</p>
														<div>
															<span class="image fit"><img src="images/Quadro 2.png" alt="" /></span>
															<p class="lead mb-2 text-center"><small> Fonte: autoria própria.</small></p>
														</div>
														<h2 class="mb-0" id="uni8-2">8.2 Tipos de Regressão</h2>
														<p class="lead mb-3 text-justify indent">A análise de regressão é uma técnica estatística fundamental utilizada para
															modelar a relação entre uma variável dependente e uma ou mais variáveis
															independentes. Existem vários tipos de modelos de regressão, cada um com suas
															características e aplicações específicas, algumas serão apresentadas nas próximas
															subseções.</p>
														<h3 class="mb-0" id="uni8-2-1"><h3 class="mb-0" id="uni8-2-1">8.2.1 Regressão Linear</h3>
														<p class="lead mb-3 text-justify indent">Simples e múltipla, modela a relação linear entre variáveis. É o ponto de
															partida para muitos estudos de regressão. A regressão linear é um método estatístico
															para modelar a relação entre uma variável dependente e uma ou mais variáveis
															independentes assumindo uma relação linear. A regressão linear simples assume a
															seguinte fórmula:</p>
														<p class="lead mb-3 text-justify indent">y = &beta;<sub>0</sub> + &beta;<sub>1</sub>X + &epsilon;</p>
														<p class="lead mb-3 text-justify indent">onde:</p>
														<ul style="margin-left: 1cm; list-style-type: disc; padding: 0;" class="alt3 lead mb-3 text-justify indent" >
															<li>y é a variável dependente.</li>
															<li>X é a variável independente.</li>
															<li>&beta;<sub>0</sub> é o intercepto (valor de y quando X = 0).</li>
															<li>&beta;<sub>1</sub>é o coeficiente de inclinação (quanto y
																mudança em
																
																quando
																muda com uma unidade de mudança em X
																).</li>
															<li>&epsilon; é o termo de erro (a diferença entre os valores observados e os valores
																preditos).</li>
														</ul>
														<h3 class="mb-0" id="uni8-2-2"><h3 class="mb-0" id="uni8-2-2">8.2.2 Regressão Ridge, Lasso e Elastic Net</h3>
														<p class="lead mb-3 text-justify indent">A regressão linear é uma ferramenta poderosa para modelar relações entre
															variáveis. No entanto, quando lidamos com um grande número de preditores ou
															quando estes estão altamente correlacionados (multicolinearidade), o modelo pode se
															tornar instável e sobreajustar aos dados de treinamento, generalizando mal para
															novos dados. Para mitigar esses problemas, foram desenvolvidas técnicas de
															regularização, como Ridge, Lasso e Elastic Net.</p>
														<p class="lead mb-3 text-justify indent">Regressão Ridge (L2):</p>
														<p class="lead mb-3 text-justify indent">A Regressão Ridge utiliza a regularização L2. Ela adiciona um termo de
															penalidade baseado na norma L2 dos coeficientes à função de custo da regressão
															linear. Essa penalização faz com que o novo modelo não obtenha os melhores
															resultados no conjunto de treino, porém visa-se melhor desempenho no conjunto de
															teste. Sua fórmula:</p>
														<p class="lead mb-3 text-justify indent">min(‖y - Xβ‖² + λ‖β‖²)</p>
														<p class="lead mb-3 text-justify indent">Onde:</p>														
														<ul style="margin-left: 1cm; list-style-type: disc;" class="alt3 lead mb-3 text-justify indent">
															<li>y é o vetor de variáveis dependentes</li>
															<li>X é a matriz de variáveis independentes</li>
															<li>β é o vetor de coeficientes</li>
															<li>λ é o parâmetro de regularização</li>															
														</ul>
														<p class="lead mb-3 text-justify indent">ou ainda:</p>
														<p class="lead mb-3 text-justify indent">‖y - Xβ‖²: Esta parte é também conhecida como SSR que foi apresentada junto
															com a métrica R<sup>2</sup>, na qual:</p>
														<ul style="margin-left: 1cm; list-style-type: disc; padding: 0;" class="alt3 lead mb-3 text-justify indent" >
															<li>y representa os valores observados;</li>
															<li>Xβ representa os valores previstos pelo modelo;</li>
															<li>A diferença (y - Xβ) representa os resíduos;</li>
															<li>Ao elevar ao quadrado (‖...‖²), obtemos a soma dos quadrados desses resíduos.</li>															
														</ul>
														<p class="lead mb-3 text-justify indent">λ‖β‖²: Esta é a parte da regularização L2 (Ridge), onde:</p>
														<ul style="margin-left: 1cm; list-style-type: disc; padding: 0;" class="alt3 lead mb-3 text-justify indent" >
															<li>‖β‖² é a norma L2 ao quadrado dos coeficientes β;</li>
															<li>λ (lambda) é o parâmetro de regularização que controla a força da penalidade.</li>
														</ul>
														<p class="lead mb-3 text-justify indent">Algumas observações adicionais:</p>
														<ul style="margin-left: 1cm; list-style-type: disc; padding: 0;" class="alt3 lead mb-3 text-justify indent" >															
															<li>O termo RSS (‖y - Xβ‖²) garante que o modelo se ajuste bem aos dados de
																treinamento</li>
															<li>O termo de regularização L2 (λ‖β‖²) penaliza coeficientes grandes, incentivando
																o modelo a usar coeficientes menores e mais estáveis.</li>
															<li>O parâmetro λ controla o equilíbrio entre estes dois objetivos. Um λ maior dá
																mais peso à regularização, enquanto um λ menor prioriza o ajuste aos dados.</li>
														</ul>
														<p class="lead mb-3 text-justify indent">Como principais características da regressão Ridge estão: a redução do
															overfitting (sobreajuste) ao diminuir a magnitude dos coeficientes, a tendência de
															distribuir o peso entre todas as variáveis e sua eficácia quando há multicolinearidade
															entre as variáveis independentes.</p>
														<p class="lead mb-3 text-justify indent">Regressão Lasso (L1):</p>
														<p class="lead mb-3 text-justify indent">LASSO utiliza a regularização L1. Adiciona um termo de penalidade baseado
															na norma L1 dos coeficientes.</p>
														<p class="lead mb-3 text-justify indent">Fórmula:</p>
														<p class="lead mb-3 text-justify indent">min(‖y - Xβ‖² + λ‖β‖₁)</p>
														<p class="lead mb-3 text-justify indent">Onde:</p>
														<ul style="margin-left: 1cm; list-style-type: disc; padding: 0;" class="alt3 lead mb-3 text-justify indent" >
															<li>y é o vetor de variáveis dependentes</li>
															<li>X é a matriz de variáveis independentes</li>
															<li>β é o vetor de coeficientes</li>
															<li>λ é o parâmetro de regularização</li>															
														</ul>
														<p class="lead mb-3 text-justify indent">Como visto anteriormente, ‖y - Xβ‖² refere-se ao SSR e λ‖β‖₁ é a norma L1. A
															principal diferença entre a L1 e L2 é que a segunda utiliza a norma ao quadrado.
															Pode-se entender β como uma inclinação que será adicionado à inclinação já existente
															do resultado do modelo linear.</p>
														<p class="lead mb-3 text-justify indent">No L1 o β está sob módulo, e no L2 ele é elevado o quadrado. Em ambos casos,
															o objetivo é evitar os valores negativos. A diferença é que para o L2, por menor que
															seja β, ele nunca poderá ser nulo, uma vez que sempre será elevado ao quadrado. Já
															para o L1, o módulo de 0 é 0, permitindo assim a seleção de variáveis.</p>
														<p class="lead mb-3 text-justify indent">Elastic Net:</p>
														<p class="lead mb-3 text-justify indent">O Elastic Net combina as regularizações L1 e L2, aproveitando as vantagens de
															ambas as técnicas.</p>
														<p class="lead mb-3 text-justify indent">Fórmula:</p>
														<p class="lead mb-3 text-justify indent">min(‖y - Xβ‖² + λ₁‖β‖₁ + λ₂‖β‖²)</p>
														<p class="lead mb-3 text-justify indent">Onde:</p>
														<ul style="margin-left: 1cm; list-style-type: disc; padding: 0;" class="alt3 lead mb-3 text-justify indent" >
															<li>‖y - Xβ‖²: Esta parte é também conhecida como SSR</li>
															<li>λ₁‖β‖₁: componente da regularização Lasso (L1)</li>
															<li>λ₂‖β‖²: componente da regularização Ridge (L2)</li>															
														</ul>
														<p class="lead mb-3 text-justify indent">Combina as propriedades do Ridge e do Lasso, pode selecionar variáveis (como
															o Lasso) e lidar com multicolinearidade (como o Ridge).</p>
														<h3 class="mb-0" id="uni8-2-3"><h3 class="mb-0" id="uni8-2-3">8.2.3 Árvores de Regressão</h3>
														<p class="lead mb-3 text-justify indent">As árvores de regressão constituem uma técnica robusta e versátil no campo
															do aprendizado de máquina, especialmente adequada para problemas de regressão
															onde o objetivo é prever uma variável de saída contínua. Esta metodologia se
															distingue por sua capacidade de capturar relações não-lineares complexas entre
															variáveis preditoras e a variável alvo, oferecendo uma alternativa valiosa aos
															modelos lineares tradicionais.</p>
														<p class="lead mb-3 text-justify indent">A estrutura fundamental de uma árvore de regressão assemelha-se a um
															fluxograma invertido, onde cada nó interno representa uma decisão baseada em uma
															característica específica, e cada nó folha contém uma previsão numérica. O processo
															de construção da árvore envolve a divisão recursiva do conjunto de dados em
															subconjuntos cada vez menores, com base em regras de decisão que maximizam a
															homogeneidade dentro de cada subgrupo resultante. Um exemplo de árvore de
															regressão é ilustrado abaixo. Uma árvore de regressão é composta por:</p>
														<ul style="margin-left: 1cm; list-style-type: disc; padding: 0;" class="alt3 lead mb-3 text-justify indent" >
															<li><b>Nós de decisão</b>: Pontos onde o algoritmo faz uma escolha baseada em uma
																característica.</li>
															<li><b>Ramos</b>: Caminhos que conectam os nós, representando os resultados das
																decisões.</li>
															<li><b>Nós folha</b>: Pontos finais que contêm as previsões numéricas.</li>															
														</ul>
														<p class="lead mb-3 text-justify indent">O algoritmo constrói a árvore de cima para baixo, seguindo estas etapas:</p>
														<ul style="margin-left: 1cm; list-style-type: disc; padding: 0;" class="alt3 lead mb-3 text-justify indent" >
															<li><b>Seleção
																da
																Melhor
																Característica</b>: O
																algoritmo
																examina
																todas
																as
																características disponíveis. Para cada característica, ele calcula uma métrica de
																"impureza" (geralmente a variância) para todas as possíveis divisões. A
																característica que resulta na maior redução da impureza é selecionada.</li>
															<li><b>Determinação do Ponto de Divisão</b>: Para a característica selecionada, o
																algoritmo determina o valor ótimo para dividir os dados. Este ponto de divisão
																minimiza a variância dentro dos subgrupos resultantes.</li>
															<li><b>Divisão do Nó</b>: O conjunto de dados no nó atual é dividido em dois
																subconjuntos com base na regra de decisão estabelecida.</li>
															<li><b>Recursão</b>: o processo é repetido para cada nó filho até que um critério de
																parada seja atingido.</li>															
														</ul>
														<p class="lead mb-3 text-justify indent">A construção da árvore para quando:</p>
														<ul style="margin-left: 1cm; list-style-type: disc; padding: 0;" class="alt3 lead mb-3 text-justify indent" >
															<li>Um nó contém um número mínimo pré definido de amostras;</li>
															<li>A profundidade máxima da árvore é alcançada;</li>
															<li>A redução na impureza cai abaixo de um limiar especificado.</li>															
														</ul>
														<p class="lead mb-3 text-justify indent">Para fazer uma previsão, um novo dado é passado pela árvore, seguindo as
															regras de decisão em cada nó. Quando atinge um nó folha, o valor associado a esse nó
															é a previsão.</p>
														<p class="lead mb-3 text-justify indent">As figuras abaixo apresentam um exemplo da aplicação de uma árvore de
															regressão. Na Figura 39 tem-se:</p>														
														<ul style="margin-left: 1cm;" class="custom-list alt3 lead mb-3 text-justify indent" >
															<li><b>Eixos X1 e X2</b>: Representam as duas variáveis preditoras utilizadas para
																construir a árvore.</li>
															<li><b>Pontos Vermelhos</b>: Cada ponto representa uma observação (exemplo) no
																conjunto de dados. A posição do ponto no gráfico indica os valores das
																variáveis preditoras para aquela observação.</li>
															<li><b>Linhas Verticais e Horizontais</b>: Representam os <i>splits</i> (divisões) realizados
																pela árvore de regressão. Cada <i>split</i> divide o espaço de características em duas
																regiões, criando nós filhos.</li>
															<li><b>Caixas Verdes</b>: Cada caixa representa uma região do espaço de características
																e contém um valor numérico. Esse valor é a previsão média da variável alvo
																(Y) para todas as observações que caem nessa região.</li>															
														</ul>
														<p class="lead mb-3 text-justify indent">Com base nisso, a Figura 40 pode ser interpretada da seguinte maneira. Se X1 é
															menor que 20, verifica-se se o valor de X2 é menor que 200. Se sim, então será
															retornado 300.5, que é o valor predito para o grupo de dados contidos à esquerda do
															split 1 e abaixo do split 3. Se o X2 for maior que 200, então será retornado 65.7, que é o
															valor predito para o grupo de dados contidos à esquerda do <i>split</i> 1 e acima do <i>split</i> 3.</p>
														<p class="lead mb-3 text-center indent" id="link-figura-39"><b>Figura 39</b> - Exemplo de Árvore de Regressão - Dados</p>
														<div>
															<span class="image fit"><img src="images/Figura 39.png" alt="" /></span>
															<p class="lead mb-2 text-center"><small> Fonte: <a href="https://medium.com/pursuitnotes/decision-tree-regression-in-6-steps-with-python-1a1c5aa2ee16"><i>Medium, 2019</i></a>.</small></p>
														</div>
														<p class="lead mb-3 text-center indent" id="link-figura-40"><b>Figura 40</b> - Exemplo de Árvore de Regressão - Árvore</p>
														<div>
															<span class="image fit"><img src="images/Figura 40.png" alt="" /></span>
															<p class="lead mb-2 text-center"><small> Fonte: Adaptada de <a href="https://medium.com/pursuitnotes/decision-tree-regression-in-6-steps-with-python-1a1c5aa2ee16"><i>Medium, 2019</i></a>.</small></p>
														</div>
														<p class="lead mb-3 text-justify indent">As árvores de regressão oferecem diversas vantagens:</p>
														<ul style="margin-left: 1cm; list-style-type: disc; padding: 0;" class="alt3 lead mb-3 text-justify indent" >
															<li><b>Interpretabilidade</b>: A
																estrutura
																hierárquica
																permite
																uma fácil
																visualização e compreensão das decisões do modelo.</li>
															<li><b>Capacidade de lidar com não-linearidades</b>: Capturam eficientemente
																relações complexas e interações entre variáveis.</li>
															<li><b>Robustez a <i>outliers</i></b>: São menos sensíveis a valores atípicos em
																comparação com métodos baseados em mínimos quadrados.</li>
															<li><b>Tratamento automático de variáveis categóricas </b>: Não requerem
																codificação prévia de variáveis categóricas.</li>															
														</ul>
														<p class="lead mb-3 text-justify indent">Contudo, também apresentam algumas limitações:</p>
														<ul style="margin-left: 1cm; list-style-type: disc; padding: 0;" class="alt3 lead mb-3 text-justify indent" >
															<li><b>Tendência ao <i>overfitting</i></b>: Árvores muito profundas podem se ajustar
																excessivamente aos dados de treinamento.</li>
															<li><b>Instabilidade</b>: Pequenas variações nos dados podem resultar em
																árvores significativamente diferentes.</li>
															<li><b>Dificuldade em capturar relações aditivas</b>:  Podem ser menos
																eficientes que modelos lineares para relações puramente aditivas.</li>															
														</ul>
														<p class="lead mb-3 text-justify indent">As árvores de regressão encontram aplicações em diversos domínios,
															incluindo: previsão de preços imobiliários, estimativa de demanda de produtos,
															avaliação de risco de crédito, previsão de consumo de energia.</p>
														<h3 class="mb-0" id="uni8-2-4"><h3 class="mb-0" id="uni8-2-4">8.2.4 <i>Recurrent Neural Network</i> (RNN) ou Rede Neural Recorrente</h3>
														<p class="lead mb-3 text-justify indent">As RNNs representam uma classe sofisticada de arquiteturas de RNAs,
															especificamente concebidas para lidar com dados sequenciais. Esta estrutura
															inovadora revolucionou diversas áreas da IA, particularmente aquelas que envolvem
															o processamento de informações temporais ou ordenadas.</p>
														<p class="lead mb-3 text-justify indent">A característica distintiva das RNNs reside em sua estrutura cíclica.
															Diferentemente das redes neurais <i>feedforward</i> tradicionais que serão detalhadas na
															unidade específica, as RNNs incorporam conexões de realimentação, permitindo que
															a informação persista ao longo do tempo. Esta propriedade confere à rede uma forma
															de "memória", capacitando-a a considerar contextos anteriores na geração de saídas
															atuais.</p>
														<p class="lead mb-3 text-justify indent">Na figura abaixo é ilustrado à direita uma rede neural <i>feedforward</i>, sem
															recorrência. À esquerda é ilustrada a RNN, destacando-se pela seta adicional que
															retorna para a mesma camada de origem.</p>
														<p class="lead mb-3 text-center indent" id="link-figura-41"><b>Figura 41</b> - Comparação entre redes neurais, RNN e Feed-Forward</p>
														<div>
															<span class="image fit"><img src="images/Figura 41.png" alt="" /></span>
															<p class="lead mb-2 text-center"><small> Fonte: Adaptada de <a href="https://www.geeksforgeeks.org/introduction-to-recurrent-neural-network/"><i>GeekesForgeeks, 2024</i></a>.</small></p>
														</div>
														<p class="lead mb-3 text-justify indent">Na rede neural <i>feedforward</i> a informação flui em uma única direção, das
															camadas de entrada para as camadas de saída. Cada neurônio em uma camada só
															recebe informações da camada anterior e não possui conexões com neurônios em
															camadas anteriores. Isso limita a capacidade da rede de processar sequências de
															dados, onde o contexto anterior é importante.</p>
														<p class="lead mb-3 text-justify indent">Na RNN os neurônios em uma camada recebem informações não apenas da
															camada anterior, mas também de si mesmos em um tempo anterior. Isso cria um
															"loop" que permite à rede "lembrar" informações passadas. A presença de conexões
															recorrentes permite que a RNN capture dependências temporais nos dados,
															tornando-as ideais para processar sequências como texto, séries temporais e fala.</p>
														<p class="lead mb-3 text-justify indent">O
															treinamento
															de
															RNNs
															emprega
															uma
															variante
															do
															algoritmo
															de
															retropropagação, denominada <i>Backpropagation Through Time</i> (BPTT). Este método
															"desdobra" a RNN em uma rede <i>feedforward</i> profunda equivalente, permitindo a
															aplicação de técnicas de otimização baseadas em gradiente.</p>
														<p class="lead mb-3 text-justify indent">As RNNs encontram aplicações em uma vasta gama de domínios incluindo
															PLN, com tradução automática, geração de texto e análise de sentimentos. No
															reconhecimento de fala, na conversão de fala para texto e em sistemas de comando
															por voz. Na análise de Séries Temporais, com a previsão de demanda e análise de
															mercado financeiro. Na bioinformática com a análise de sequências de DNA ou
															previsão de estruturas proteicas.</p>
														<p class="lead mb-3 text-justify indent">Apesar de sua potência, as RNNs apresentam desafios significativos como:
															desvanecimento e explosão do gradiente. O gradiente é como um sinal que diz à rede
															neural como ela deve ajustar seus "pesos" (parâmetros internos) para melhorar suas
															previsões. Este sinal viaja de trás para frente na rede durante o treinamento. Quando
															trabalha-se com sequências longas em RNNs, esse gradiente precisa percorrer um
															caminho muito longo, causando o desvanecimento ou explosão do gradiente. Como
															consequência disso, a rede tem dificuldade em aprender de eventos que ocorreram
															muito tempo atrás na sequência, ou os ajustes na rede se tornam muito grandes,
															fazendo com que o treinamento se torne instável. Além disso, o processamento
															sequencial pode ser computacionalmente intensivo, especialmente para sequências
															muito longas.</p>
														<h2 class="mb-0" id="uni8-3">8.3 <i>Notebook Colab</i>:</h2>
														<p class="lead mb-3 text-justify indent">No link do colab serão abordados exemplos didáticos apresentando o cálculo
															manual e utilizando as bibliotecas disponíveis, bem serão criadas diversas ilustrações
															para fixar a aprendizagem. Dentre os conteúdos abordados nesse notebook
															incluem-se as métricas R<sup>2</sup>, MSE, MAE, RMSE, um exemplo detalhado de uso do modelo regressão linear e a aplicação direta dos modelos de regressão ridge, árvores
															de regressão e RNN.</p>
														<div class="box">
															<p class="lead mb-3 text-justify indent">Link:</p>
															<p class="lead mb-3 text-justify"><a href="https://colab.research.google.com/drive/13J8VuT8tDkdazsZa4w36h_tj3Z5QuVuI">
																https://colab.research.google.com/drive/13J8VuT8tDkdazsZa4w36h_tj3Z5QuVuI</a></p>																	
														</div>
														<p><span class="image left" style="width: 25%;"><img src="Robozinho/roboCuriosoLupaRoxoEsquerda.png" alt="" /></span></p>
														<div class="box2">
															<h3 class="mb-0" id="1-saiba-mais">Saiba mais…</h3>
															<p class="lead mb-3 text-justify">Regressão Linear - <a href="https://youtu.be/7ArmBVF2dCs?si=XV-Ax7DZz0sN2Wx1">https://youtu.be/7ArmBVF2dCs?si=XV-Ax7DZz0sN2Wx1</a></p>
															<p class="lead mb-3 text-justify">Regressão Linear - <a href="https://www.youtube.com/watch?v=PaFPbb66DxQ">https://www.youtube.com/watch?v=PaFPbb66DxQ</a></p>
															<p class="lead mb-3 text-justify">Regressão Ridge - <a href="https://youtu.be/Q81RR3yKn30?si=K-TkT-W69SAM60uK">https://youtu.be/Q81RR3yKn30?si=K-TkT-W69SAM60uK</a></p>	
															<p class="lead mb-3 text-justify">Regressão Lasso - <a href="https://youtu.be/NGf0voTMlcs?si=T8z8AlNTh8zl6iZF">https://youtu.be/NGf0voTMlcs?si=T8z8AlNTh8zl6iZF</a></p>
															<p class="lead mb-3 text-justify">Comparação entre Ridge e Lasso - <a href="https://youtu.be/Xm2C_gTAl8c?si=Ti2D0PTfnJAl1e4B">https://youtu.be/Xm2C_gTAl8c?si=Ti2D0PTfnJAl1e4B</a></p>
															<p class="lead mb-3 text-justify">Árvores de regressão - <a href="https://youtu.be/g9c66TUylZ4?si=-fP85nMbFRgT2nw7">https://youtu.be/g9c66TUylZ4?si=-fP85nMbFRgT2nw7</a></p>
															<p class="lead mb-3 text-justify">R<sup>2</sup> - <a href="https://youtu.be/bMccdk8EdGo?si=zRO2xrswQPq6xSZS">https://youtu.be/bMccdk8EdGo?si=zRO2xrswQPq6xSZS</a></p>
															<p class="lead mb-3 text-justify">R<sup>2</sup> - <a href="https://youtu.be/aP8YP1aX2zc?si=WDFJh6kkSNPjdtgO">https://youtu.be/aP8YP1aX2zc?si=WDFJh6kkSNPjdtgO</a></p>
															<p class="lead mb-3 text-justify">Regressão Linear - <a href="https://youtu.be/bMccdk8EdGo?si=zRO2xrswQPq6xSZS">https://youtu.be/bMccdk8EdGo?si=zRO2xrswQPq6xSZS</a></p>
															<p class="lead mb-3 text-justify">Regressão Linear - <a href="https://youtu.be/Wo9Vt7Sc_E0?si=hd7X7u5QX-2m57AI">https://youtu.be/Wo9Vt7Sc_E0?si=hd7X7u5QX-2m57AI</a></p>
														</div>
														<p><span class="image right" style="width: 25%;"><img src="Robozinho/roboCuriosoLapisRoxo.png" alt="" /></span></p>
														<div class="box2">
															<h3 class="mb-0" id="1-saiba-mais">Para relembrar…</h3>
															<p class="lead mb-3 text-justify">Regressão: Técnica estatística para modelar relações entre variáveis
																dependentes contínuas e variáveis independentes.</p>
																<p class="lead mb-3 text-justify indent">Importância: Fundamental para previsões quantitativas em diversos campos como economia, finanças e indústria.</p>
																
																<p class="alt4 lead mb-3 text-justify"><font color="#19032B">&#10132 </font>Regressão vs. Classificação:</p>
																<ul style="margin-left: 1cm; list-style-type: disc; padding: 0;" class="alt3 lead mb-3 text-justify indent" >
																	<li>Regressão: Predição de variáveis contínuas (ex.: preços, temperaturas)</li>
																	<li>Classificação: Atribuição de instâncias a categorias discretas (ex.:
																		spam ou não spam)</li>																	
																</ul>															
															<p class="alt4 lead mb-3 text-justify"><font color="#19032B">&#10132 </font>Métricas de Avaliação:</p>
															<ul style="margin-left: 1cm; list-style-type: disc; padding: 0;" class="alt3 lead mb-3 text-justify indent" >
																<li>R<sup>2</sup>: Coeficiente de Determinação</li>
																<li>MSE: Erro Quadrático Médio</li>
																<li>MAE: Erro Absoluto Médio</li>
																<li>RMSE: Raiz do Erro Quadrático Médio</li>																
															</ul>															
															<p class="alt4 lead mb-3 text-justify"><font color="#19032B">&#10132 </font>Tipos de Regressão:</p>
															<ul style="margin-left: 1cm; list-style-type: disc; padding: 0;" class="alt3 lead mb-3 text-justify indent" >
																<li>Linear: Simples e múltipla</li>
																<li>Ridge, Lasso e Elastic Net: Incluem penalizações</li>
																<li>Árvores de Regressão: Estrutura em forma de árvore</li>
																<li>RNN: Para processar sequências de dados</li>																
															</ul>
														</div>
														
														
														</section>
															<hr class="m-0">
															<section>
																<div class="image main" id="capa_uni9">
																	<img src="images/6. Unidade_9_Introdução a Machine Learning e Redes Neurais.png" alt="">
																</div>
															</section>
															<hr class="m-0">
															<section class="resume-section p-3 p-lg-5 d-flex align-items-center">
																<div class="w-100">
																<h1 class="mb-0" id="uni9">Unidade IX - Classificação</h1>
															</div></header>
															
															<p class="lead mb-3 text-justify indent">Como já foi comentado nas unidades anteriores deste eBook, um dos
																problemas comuns no Aprendizado de Máquina é a tarefa de identificar as classes
																associadas a um determinado objeto. A partir de suas características, também
																chamadas de variáveis, utilizamos métodos computacionais inteligentes para tentar
																determinar a qual classe esse objeto pertence. Podemos usar como exemplo a simples
																tarefa de identificar se um determinado e-mail é spam ou não. Um e-mail pode conter
																texto, imagens e arquivos diversos, que são suas variáveis, e pode ser interpretado
																como spam ou não spam. O que determina se um e-mail é spam ou não é uma
																interpretação dessas variáveis de acordo com o interesse do dono da caixa de e-mail.
																Para uma pessoa, um e-mail de propaganda de um pet shop, por exemplo, pode ser
																irrelevante, logo, seria classificado como spam; mas para outra pessoa, pode ser de
																interesse, logo, não seria considerado spam. Dessa forma, classificar diferentes
																mensagens de e-mail entre as duas classes (spam e não spam) é uma tarefa que exige
																a interpretação das variáveis a cada nova mensagem, compondo assim uma tarefa de
																classificação de mensagens.</p>
															<p class="lead mb-3 text-justify indent">As tarefas de classificação são comuns por serem amplamente utilizadas na
																automação de processos que envolvem a interpretação de dados de diversos tipos. Se
																dividirmos por tipo de dado de entrada, podemos listar alguns exemplos de
																aplicações.</p>
																<p class="lead mb-3 text-center indent" id="link-figura-42"><b>Figura 42</b> - Exemplos de Aplicações de Classificação</p>
																<div>
																	<span class="image fit"><img src="images/Figura 42.1.png" alt="" /></span>
																	<span class="image fit"><img src="images/Figura 42.2.png" alt="" /></span>
																	<span class="image fit"><img src="images/Figura 42.3.png" alt="" /></span>
																	<span class="image fit"><img src="images/Figura 42.4.png" alt="" /></span>
																	<span class="image fit"><img src="images/Figura 42.5.png" alt="" /></span>
																	<span class="image fit"><img src="images/Figura 42.6.png" alt="" /></span>
																	<span class="image fit"><img src="images/Figura 42.7.png" alt="" /></span>
																	<span class="image fit"><img src="images/Figura 42.8.png" alt="" /></span>
																	<span class="image fit"><img src="images/Figura 42.9.png" alt="" /></span>
																	<span class="image fit"><img src="images/Figura 42.10.png" alt="" /></span>
																	<p class="lead mb-2 text-center"><small> Fonte: autoria própria.</small></p>
																</div>
																<h2 class="mb-0" id="uni9-1">9.1 Classificadores</h2>
																<p class="lead mb-3 text-justify indent">O elemento principal ao tratar um problema de classificação é o classificador.
																	Classificadores são métodos de Aprendizado de Máquina que, a partir das variáveis
																	extraídas de um objeto, tentam determinar a qual classe ele pertence. Esses métodos
																	são desenvolvidos com o objetivo de compreender as possíveis variações dentro de
																	uma classe. Por exemplo, em uma tarefa de reconhecimento de gatos a partir de uma
																	imagem, podemos ter diversas variações, como posição, raça, cor, tamanho e formato,
																	conforme ilustrado na Figura 45. Todas essas variações geram variáveis com algumas
																	diferenças, mas que ainda assim representam exemplos da mesma classe. O objetivo
																	dos classificadores é identificar os padrões comuns a cada classe (dois olhos, bigodes,
																	orelhas, quatro patas, etc.) enquanto tentam generalizar esses padrões, considerando
																	as possíveis variações. Assim, um bom classificador de gatos deve ser capaz de
																	generalizar a definição de gato e reconhecer todos os diferentes bichanos.</p>
																<p class="lead mb-3 text-center indent" id="link-figura-43"><b>Figura 43</b> - Exemplo de diferentes amostras de uma classe “gato”</p>
																<div>
																	<span class="image fit"><img src="images/Figura 43.png" alt="" /></span>
																	<p class="lead mb-2 text-center"><small> Fonte: autoria própria.</small></p>
																</div>
																<p class="lead mb-3 text-justify indent">Na literatura de Aprendizado de Máquina temos diversos classificadores.
																	Podemos categorizar estes métodos a partir do princípio de funcionamento de cada
																	um como mostra o mapa mental a seguir.</p>
																	<p class="lead mb-3 text-center indent" id="link-figura-44"><b>Figura 44</b> - Mapa mental classificadores na literatura de aprendizado de máquina</p>
																	<div>
																		<span class="image fit"><img src="images/Figura 44.png" alt="" /></span>
																		<p class="lead mb-2 text-center"><small> Fonte: autoria própria.</small></p>
																	</div>
															
																	<p class="lead mb-3 text-justify indent">Para entendermos melhor vamos estudar alguns destes métodos de forma mais
																		detalhada começando pelo KNN, ou k-Vizinhos Mais Próximos em português, que
																		realiza a classificação com base na vizinhança de cada amostra de dados.</p>	
															
															<h3 class="mb-0" id="uni9-1-1">9.1.1 KNN: k-<i>Nearest Neighbors</i></h3>
															<p class="lead mb-3 text-justify indent">O KNN é um classificador clássico do Aprendizado de Máquina e apesar de
																possuir funcionamento simples e intuitivo é muito utilizado. O conceito principal do
																KNN é que os dados utilizados no treinamento do classificador delimitam a região do
																espaço de variáveis que compõem as classes com base na proximidade. Para melhor
																visualizar esta propriedade vamos usar como exemplo o dataset Íris .</p>
															<p class="lead mb-3 text-justify indent">O dataset Íris é composto por 50 amostras de três diferentes espécies de flores
																de plantas Íris, onde cada flor teve sua sépala e pétala medida. As partes das flores e
																diferentes espécies estão na imagem abaixo. O objetivo aqui é diferenciar as espécies
																de acordo com as características das suas flores.</p>
															<p class="lead mb-3 text-center indent" id="link-figura-45"><b>Figura 45</b> - Exemplos das três espécies de flores Iris</p>
																<div>
																	<span class="image fit"><img src="images/Figura 45.png" alt="" /></span>
																	<p class="lead mb-2 text-center"><small> Fonte: Adaptada de <a href="https://www.researchgate.net/profile/Shohal-Hossain-2/publication/367220930/figure/fig1/AS:11431281113694842@1674035105600/Three-species-of-IRIS-flower.jpg"><i>Leitura de um dataset, 2020</i></a>.</small></p>
															</div>
															<p class="lead mb-3 text-justify indent">Se visualizarmos a distribuição dos dados em torno de duas das variáveis
																	(comprimento e largura da pétala) podemos observar que as diferentes espécies
																	formam regiões no espaço das variáveis. A espécie setosa apresenta uma
																	sobreposição quando olhamos apenas o comprimento (eixo x) ou largura (eixo y), mas
																	usando ambas as variáveis fica claro o surgimento de uma região própria da classe. O
																	KNN atua justamente nesse conceito de vizinhança classificando um novo dado a
																	partir dos k vizinhos mais próximos. Vizinhos são os dados já existentes na base de
																	treinamento e que estão rotulados (já sabemos a sua resposta), a partir destes são
																	encontrados os k mais próximos e feito uma votação para decidir qual classe atribuir
																	a um novo dado. O valor de k é atribuído no processo de parametrização do algoritmo
																	e deve ser otimizado para obter o melhor resultado.</p>
															<p class="lead mb-3 text-center indent" id="link-figura-46"><b>Figura 46</b> - Distribuição das amostras de flores com base no comprimento e largura
																da Sépala</p>
															<div>
																		<span class="image fit"><img src="images/Figura 46.png" alt="" /></span>
																		<p class="lead mb-2 text-center"><small> Fonte: autoria própria.</small></p>
															</div>
															<p class="lead mb-3 text-justify indent">Dessa forma, se imaginarmos uma nova flor cuja pétala foi medida em termos
																de largura e comprimento, ao utilizarmos o KNN com valor de k igual a 5, iremos
																buscar os 5 exemplos de pétalas já conhecidos mais próximos para definir qual classe
																deve ser atribuída a esse novo exemplo. Na figura a seguir podemos ver um exemplo
																deste caso, onde o novo ponto será atribuído a versicolor por possuir 4 vizinhos mais
																próximos que faz parte desta classe.</p>
																<p class="lead mb-3 text-center indent" id="link-figura-47"><b>Figura 47</b> - Exemplo de aplicação do KNN em um novo dado</p>
															<div>
																<span class="image fit"><img src="images/Figura 47.png" alt="" /></span>
																<p class="lead mb-2 text-center"><small> Fonte: autoria própria.</small></p>
															</div>
															<p class="lead mb-3 text-justify indent">A partir deste processo podemos definir as regiões do espaço das variáveis
																conforme a proximidade dos 5 vizinhos mais próximos, criando assim uma fronteira
																de discriminação baseada na vizinhança dos dados. Na figura a seguir podemos
																visualizar a região de cada classe. Neste exemplo podemos ver que a classe setosa está
																quase perfeitamente discriminada das outras duas classes, porém as classes
																versicolor e virginica estão sobrepostas de uma forma que não é possível separá-las
																perfeitamente com o KNN. Dessa forma podemos afirmar que o KNN com apenas
																estas duas variáveis não é capaz de obter uma boa generalização. Uma alternativa
																para se obter um melhor resultado pode ser com uso das técnicas discutidas nas
																unidades anteriores, como: adicionar outras variáveis, normalizar ou transformar as
																variáveis utilizadas ou talvez remover <i>outliers</i> do conjunto de treino. De qualquer
																maneira, para mensurarmos a qualidade desta modelagem em classificar flores e sua
																capacidade de generalização é necessária uma metodologia de avaliação e métricas
																objetivas.</p>
																<p class="lead mb-3 text-center indent" id="link-figura-48"><b>Figura 48</b> - Fronteira de discriminação de um KNN</p>
																<div>
																	<span class="image fit"><img src="images/Figura 48.png" alt="" /></span>
																	<p class="lead mb-2 text-center"><small> Fonte: autoria própria.</small></p>
																</div>
															
															<h2 class="mb-0" id="uni9-2">9.2 Avaliação de Classificadores</h2>
															<p class="lead mb-3 text-justify indent">A avaliação de modelos de Aprendizado de Máquina varia conforme o
																problema a ser tratado. No caso de um problema de classificação, há alguns critérios
																específicos que precisam ser observados.</p>
															<p class="lead mb-3 text-justify indent">O primeiro ponto a ser tratado é a divisão dos dados em conjuntos de treino e
																teste, ou em treino, validação e teste. A divisão dos dados deve ser coerente com o
																problema, de forma que cada amostra de treino seja independente das amostras de
																teste. Por exemplo, em um problema de imagens médicas, caso existam várias
																imagens de um mesmo paciente, elas devem ser alocadas ou no conjunto de treino ou
																no de teste, mas sempre juntas. Dessa forma, garantimos que os conjuntos são
																Independentes e Identicamente Distribuídos (IID). Esse conceito vem da estatística e
																define que as amostras devem ser:</p>
																<ul style="margin-left: 1cm; list-style-type: disc; padding: 0; margin-bottom: 2%;" class="alt3 lead mb-3 text-justify indent" >
																	<li><b>Independentes</b>: Se os conjuntos de treino e teste não forem
																		independentes, pode haver uma correlação entre os dados nos dois
																		conjuntos. Isso pode levar o modelo a "lembrar" informações específicas
																		do conjunto de treino e usar essas informações para obter um
																		desempenho artificialmente alto no conjunto de teste, em vez de
																		aprender padrões generalizáveis. Isso resulta em uma avaliação
																		otimista e irrealista do modelo.</li>
																	<li><b>Identicamente Distribuídos</b>: Se os conjuntos de treino e teste não
																		forem identicamente distribuídos, o modelo treinado em um conjunto
																		de dados pode não se comportar bem no conjunto de teste, pois os
																		padrões que ele aprendeu podem não ser aplicáveis ao conjunto de
																		teste. Isso levaria a uma avaliação incorreta do modelo, onde o
																		desempenho no conjunto de teste não reflete o desempenho esperado
																		em novos dados do mundo real.</li>																	
																</ul>
																<p class="lead mb-3 text-justify indent">Esse cuidado deve ser considerado para que a avaliação reflita de forma mais
																	fidedigna como o modelo se comportará no futuro ao lidar com novos dados,
																	conseguindo assim, mensurar a capacidade de generalização e identificando ao
																	mesmo tempo um possível <i>overfitting</i> (sobreajuste), que no caso seria equivalente a
																	“decorar” o conjunto de treino, que leva o classificador a um alto erro nos dados de
																	teste.</p>
																<p class="lead mb-3 text-justify indent">Por fim, após treinar o modelo e executar o conjunto de teste, mensuramos a
																	qualidade das predições a partir dos rótulos já conhecidos. Para isso temos métricas
																	específicas para problemas de classificação.</p>
															<h3 class="mb-0" id="uni9-2-1">9.2.1 Métricas para Classificação</h3>
															<p class="lead mb-3 text-justify indent">Dentre as métricas a serem usadas, alguns pontos de atenção são importantes a
																serem considerados. Primeiro, o objetivo da aplicação. Cada métrica tem como função
																avaliar alguma qualidade ou defeito específico dos modelos, não existem métricas
																universais. Assim, é necessário avaliar com base no objetivo da aplicação que está
																sendo desenvolvida qual é o resultado esperado. Como por exemplo em um sistema
																médico voltado a classificação de risco de pacientes que chegam ao pronto
																atendimento em risco baixo e alto. Se o objetivo for fazer uma triagem automatizada
																espera-se que o modelo acerte as classificações em geral, e também é preciso verificar
																o desempenho por classe, para garantir que os pacientes de alto risco estão sendo
																classificados corretamente, pois são os casos mais críticos. Caso o objetivo seja algo
																parcialmente automatizado, de forma que um profissional de saúde irá receber uma
																probabilidade de risco entre 0 e 1 e interpretar tal informação, já é preciso avaliar
																não só se a classificação é correta, mas o quão precisa ela é, pois se em dois casos de
																altíssimo risco um tiver probabilidade de 0,6 e o outro de 0,9, isso pode gerar
																interpretações diferentes.</p>
															<p class="lead mb-3 text-justify indent">Para interpretarmos as métricas, é necessário entender o contexto de
																classificação
																como
																a
																tentativa
																de
																classificar
																corretamente
																cada
																classe
																individualmente. Nesse contexto, usamos os termos "positivos" e "negativos" para se
																referir a pertencente ou não pertencente à classe. Ao realizar a classificação, temos os
																casos positivos classificados corretamente, chamados de Verdadeiros Positivos, e os
																classificados erroneamente como negativos, chamados de Falsos Negativos. Da
																mesma forma, temos os negativos classificados corretamente, chamados de
																Verdadeiros Negativos, e os erroneamente classificados como positivos, chamados de
																Falsos Positivos. Esses quatro valores formam a chamada matriz de confusão, a partir
																da qual extraímos as métricas.</p>
															<p class="lead mb-3 text-center indent" id="link-figura-49"><b>Figura 49</b> - Matriz de confusão e seus componentes</p>
															<div>
																<span class="image fit"><img src="images/Figura 49.png" alt="" /></span>
																<p class="lead mb-2 text-center"><small> Fonte: autoria própria.</small></p>
															</div>
															<p class="lead mb-3 text-justify indent">A partir das combinações dos quatro valores temos as principais métricas:</p>
															<h4 class="mb-0" id="uni9-2-1-1">9.2.1.1 Acurácia</h4>
															
															<ul style="margin-left: 1cm; list-style-type: disc; padding: 0;" class="alt3 lead mb-3 text-justify indent" >
																<li><b>Equação</b>: <p class="formula text-center" >
																	<strong>ACURÁCIA</strong> = 
																	<span class="fraction">
																		<span class="numerator">    TP + TN </span>
																		<span class="denominator cursive">𝑇𝑃 + 𝑇𝑁 + 𝐹𝑃 + 𝐹𝑁</span>
																	</span>
																</p></li>
																<li><b>Definição</b>: Acurácia é a proporção de acertos com relação ao número de
																	respostas, sendo assim a métrica mais intuitiva pois nos entrega uma
																	medida do quanto o modelo acerta/erra.</li>
																<li><b>Pontos positivos</b>:  
																	<ul style="margin-left: 1cm; list-style-type: disc; padding: 0; margin-bottom: 0;" class="alt3 lead mb-3 text-justify indent" >
																		<li>Fácil compreensão</li>																		
																	</ul></li>
																<li><b>Pontos negativos</b>:  
																	<ul style="margin-left: 1cm; list-style-type: disc; padding: 0;" class="alt3 lead mb-3 text-justify indent" >
																		<li>Pode ser enganosa em conjuntos de dados desbalanceados, pois
																			um modelo que prevê a classe majoritária para todos os
																			exemplos ainda pode ter alta acurácia.</li>																		
																	</ul></li>													
															</ul>
															<h4 class="mb-0" id="uni9-2-1-2">9.2.1.2 Precisão</h4>
															<ul style="margin-left: 1cm; list-style-type: disc; padding: 0;" class="alt3 lead mb-3 text-justify indent" >
																<li><b>Equação</b>: <p class="formula text-center" >
																	<strong>PRECISÃO</strong> = 
																	<span class="fraction">
																		<span class="numerator">    TP </span>
																		<span class="denominator cursive">𝑇𝑃 + 𝐹𝑃 </span>
																	</span>
																</p></li>
																<li><b>Definição</b>: A precisão mede a proporção de instâncias corretamente
																	identificadas como positivas em relação ao total de instâncias previstas
																	como positivas. Ela indica o quanto as previsões positivas do modelo são
																	confiáveis.</li>
																<li><b>Pontos positivos</b>:  
																	<ul style="margin-left: 1cm; list-style-type: disc; padding: 0; margin-bottom: 0;" class="alt3 lead mb-3 text-justify indent" >
																		<li>Útil quando o custo de um falso positivo é alto.</li>	
																		<li>Boa métrica quando se deseja minimizar alarmes falsos.</li>																		
																	</ul></li>																	
																<li><b>Pontos negativos</b>:  
																	<ul style="margin-left: 1cm; list-style-type: disc; padding: 0;" class="alt3 lead mb-3 text-justify indent" >
																		<li>Não considera os falsos negativos, o que pode ser problemático
																			em casos onde a identificação de todos os positivos é crucial.</li>																		
																</ul></li>																
															</ul>
															<h4 class="mb-0" id="uni9-2-1-3">9.2.1.3 <i>Recall</i></h4>
															<ul style="margin-left: 1cm; list-style-type: disc; padding: 0;" class="alt3 lead mb-3 text-justify indent" >
																<li><b>Equação</b>: <p class="formula text-center" >
																	<strong><i>Recall</i></strong> = 
																	<span class="fraction">
																		<span class="numerator">    TP  </span>
																		<span class="denominator cursive">𝑇𝑃 + 𝐹𝑁</span>
																	</span>
																</p></li>
																<li><b>Definição</b>: O <i>recall</i> (ou sensibilidade) mede a proporção de instâncias
																	positivas corretamente identificadas pelo modelo em relação ao total de
																	instâncias positivas reais. Ele indica a capacidade do modelo de detectar
																	todos os positivos.</li>
																	<li><b>Pontos positivos</b>:  
																		<ul style="margin-left: 1cm; list-style-type: disc; padding: 0; margin-bottom: 0;" class="alt3 lead mb-3 text-justify indent" >
																			<li>Útil quando o custo de um falso negativo é alto.</li>	
																			<li>Boa métrica quando se deseja capturar o máximo de positivos
																				possível.</li>																		
																		</ul></li>	
																		<li><b>Pontos negativos</b>:  
																			<ul style="margin-left: 1cm; list-style-type: disc; padding: 0; margin-bottom: 0;" class="alt3 lead mb-3 text-justify indent" >
																				<li>Pode levar a muitos falsos positivos se não for balanceado com
																					precisão.</li>																		
																		</ul></li>
															</ul>
															<h4 class="mb-0" id="uni9-2-1-4">9.2.1.4 <i>F1-score</i></h4>
															<ul style="margin-left: 1cm; list-style-type: disc; padding: 0;" class="alt3 lead mb-3 text-justify indent" >
																<li><b>Equação</b>: <p class="formula text-center" >
																	<strong>F1</strong> = 
																	2 ×
																	<span class="fraction">
																		<span class="numerator"> Precisão × <i>Recall</i></span>
																		<span class="denominator">Precisão + <i>Recall</i></span>
																	</span>
																</p> </li>
																<li><b>Definição</b>: O F1-Score é a média harmônica da precisão e do recall,
																	oferecendo um equilíbrio entre as duas métricas. Ele é
																	especialmente útil em situações onde é necessário um equilíbrio
																	entre precisão e <i>recall</i>.</li>
																	<li><b>Pontos positivos</b>:  
																		<ul style="margin-left: 1cm; list-style-type: disc; padding: 0; margin-bottom: 0;" class="alt3 lead mb-3 text-justify indent" >
																			<li>Útil em cenários de classes desbalanceadas.</li>	
																			<li>Balanceia os erros de falsos positivos e falsos negativos.</li>																		
																		</ul></li>	
																		<li><b>Pontos negativos</b>:  
																			<ul style="margin-left: 1cm; list-style-type: disc; padding: 0;" class="alt3 lead mb-3 text-justify indent" >
																				<li>Pode ser difícil de interpretar isoladamente.</li>	
																				<li>Não diferencia a importância relativa de precisão e <i>recall</i>.</li>																		
																		</ul></li>
															</ul>														
															<h4 class="mb-0" id="uni9-2-1-5">9.2.1.5 Matriz de confusão</h4>
															<ul style="margin-left: 1cm; list-style-type: disc; padding: 0; margin-bottom: 0;" class="alt3 lead mb-3 text-justify indent" >																
																<li><b>Definição</b>: A própria matriz de confusão pode ser usada como métrica, pois
																	mostra o desempenho do modelo de classificação ao exibir o
																	número de instâncias verdadeiras e falsas para cada classe. Ela
																	ajuda a entender onde o modelo está cometendo erros.</li>
																	<li><b>Pontos positivos</b>:  
																		<ul style="margin-left: 1cm; list-style-type: disc; padding: 0; margin-bottom: 0;" class="alt3 lead mb-3 text-justify indent" >
																			<li>Proporciona uma visão detalhada do desempenho do modelo.</li>																																				
																		</ul></li>	
																		<li><b>Pontos negativos</b>:  
																			<ul style="margin-left: 1cm; list-style-type: disc; padding: 0; margin-bottom: 0;" class="alt3 lead mb-3 text-justify indent" >
																				<li>Pode ser difícil de interpretar quando o número de classes é
																					muito grande.</li>	
																				<li>Não oferece uma métrica única de desempenho, exigindo cálculo
																					de outras métricas para análise quantitativa.</li>																		
																		</ul></li>
															</ul>
															<p style="padding-bottom: 3%;" class="lead mb-3 text-justify indent">Como podemos ver, nenhuma métrica é perfeita. As diferentes formas de
																interpretar acertos e erros nos permitem avaliar a performance de um classificador
																sob diferentes ângulos. Agora, vamos refletir sobre como essas métricas podem ser
																aplicadas em diferentes problemas.</p>
															<h4 class="mb-0" id="uni9-2-1-6">9.2.1.6 Acurácia em Detecção de Fraude</h4>
															<ul style="margin-left: 1cm; list-style-type: disc; padding: 0;" class="alt3 lead mb-3 text-justify indent" >
																<li><b>Problema</b>: Um banco quer identificar transações fraudulentas em tempo real.</li>
																<li><b>Uso da Acurácia</b>: A acurácia pode ser usada como uma métrica geral para
																	avaliar o modelo se as classes de transações fraudulentas e não fraudulentas
																	estiverem balanceadas.</li>																
																<li><b>Dificuldade</b>: Se 99% das transações são legítimas, um modelo com 99% de
																	acurácia pode parecer bom, mas pode estar ignorando completamente as
																	fraudes (1% dos casos). Nesse cenário, a acurácia sozinha pode ser enganosa.</li>
																<li><b>Alternativas</b>:  
																	<ul style="margin-left: 1cm; list-style-type: disc; padding: 0;" class="alt3 lead mb-3 text-justify indent" >
																		<li><b>Recall</b>: Para garantir que o modelo detecte a maioria das fraudes.</li>
																		<li><b><i>F1-Score</i></b>: Para equilibrar a precisão (evitar falsos positivos) e <i>recall</i>
																			(detectar fraudes).</li>																		
																	</ul></li>
															</ul>
															<h4 class="mb-0" id="uni9-2-1-7">9.2.1.7 Precisão em Diagnóstico Médico (Detecção de Câncer)</h4>
															<ul style="margin-left: 1cm; list-style-type: disc; padding: 0;" class="alt3 lead mb-3 text-justify indent" >
																<li><b>Problema</b>: Um sistema de apoio à decisão médica é usado para detectar câncer
																	em imagens de exames.</li>
																<li><b>Uso da Precisão</b>: A precisão mede a proporção de diagnósticos corretos entre
																	os casos identificados como positivos. Alta precisão significa menos falsos
																	positivos.</li>
																<li><b>Dificuldade</b>: A precisão sozinha não garante que todos os casos de câncer
																	sejam detectados.</li>
																	<li><b>Alternativas</b>:  
																		<ul style="margin-left: 1cm; list-style-type: disc; padding: 0;" class="alt3 lead mb-3 text-justify indent" >
																			<li><b>Recall</b>: Para garantir que a maioria dos casos de câncer seja
																				identificada.</li>
																			<li><b><i>F1-Score</i></b>: Para equilibrar precisão e recall, maximizando a detecção de
																				cânceres enquanto minimiza falsos positivos.</li>																		
																		</ul></li>																
															</ul>
															<h4 class="mb-0" id="uni9-2-1-8">9.2.1.8 <i>F1-Score</i> em Detecção de Spam</h4>
															<ul style="margin-left: 1cm; list-style-type: disc; padding: 0; margin-bottom: 0;" class="alt3 lead mb-3 text-justify indent" >
																<li><b>Problema</b>: Um sistema de e-mail precisa classificar mensagens como spam ou
																	não-spam.</li>
																<li><b>Uso do <i>F1-Score</i></b>: O F1-score equilibra precisão e recall, sendo útil para lidar
																	com o trade-off entre capturar a maioria dos spams e evitar falsos positivos
																	(e-mails legítimos marcados como spam).</li>
																<li><b>Dificuldade</b>: <i>F1-Score</i> pode ser difícil de interpretar isoladamente e não
																	considera a distribuição das classes.</li>
																	<li><b>Alternativas</b>:  
																		<ul style="margin-left: 1cm; list-style-type: disc; padding: 0; margin-bottom: 0;" class="alt3 lead mb-3 text-justify indent" >
																			<li><b>Matriz de Confusão</b>: Para entender a distribuição dos erros (falsos
																				positivos e falsos negativos) e ajustar o modelo de acordo.</li>																																			
																		</ul></li>																
															</ul>
															<p class="lead mb-3 text-justify indent">Alguns problemas exigem interpretações mais complexas para a avaliação de
																classificadores, indo além de apenas interpretar acertos e erros, mas também avaliando a qualidade da classificação. Uma das alternativas mais comuns para isso é
																o uso da Curva Receiver Operating Characteristic (ROC).</p>
															<h4 class="mb-0" id="uni9-2-1-9">9.2.1.9 Curva ROC</h4>
															<p class="lead mb-3 text-justify indent">A maioria dos classificadores realiza as classificações utilizando valores reais,
																de forma que um novo objeto pode ser classificado, por exemplo, como sendo 0,7
																"gato". Essas respostas são posteriormente convertidas para classes a fim de calcular
																métricas clássicas como Acurácia e Precisão, resultando em acertos e erros. No
																entanto, ao analisarmos mais a fundo a qualidade da classificação, podemos
																considerar que, se o objeto é um gato, ele deveria ser classificado como 0,9999... "gato"
																e não apenas 0,7 "gato". Esse tipo de interpretação é comum em problemas chamados
																binários, onde há apenas duas classes, normalmente encaradas como positivo e
																negativo, ou presença e ausência. Alguns problemas já discutidos na unidade são
																binários, como diagnóstico médico, identificação de spam e detecção de fraude. Por
																outro lado, o problema das flores Íris é um problema multiclasse, onde temos três
																classes diferentes, e uma métrica como a acurácia, por exemplo, precisa ser calculada
																por classe para, então, termos uma média geral entre todas as classes.</p>
															<p class="lead mb-3 text-justify indent">Voltando aos problemas binários, podemos interpretar a saída numérica dos
																classificadores e medir a qualidade a partir da Curva ROC. A Curva ROC mensura a
																taxa de Verdadeiros Positivos (Recall) junto da taxa de Falsos Positivos (1 -
																Especificidade, outra métrica calculada a partir da matriz de confusão) a partir de
																diferentes limiares de interpretação das classes. É como se considerássemos que,
																acima de 0,1, é "gato", depois acima de 0,2, é "gato", acima de 0,3, é "gato", e assim por
																diante. Calculando as taxas em diferentes limiares, obtemos diferentes interpretações
																do classificador e, por fim, desenhamos uma curva com esses valores. Ao observar a
																curva, podemos visualizar a qualidade geral do classificador, tendo como referência
																um classificador aleatório (que acerta 50% das vezes) e um classificador perfeito, que
																formaria uma curva cobrindo toda a área do gráfico. Na figura a seguir, podemos
																visualizar três exemplos de classificadores e suas Curvas ROC. Quanto mais alta a
																curva, maior a área e, portanto, melhor o classificador.</p>
																<p class="lead mb-3 text-center indent" id="link-figura-50"><b>Figura 50</b> - Exemplos de Curva ROC de diferentes classificadores</p>
																<div>
																	<span class="image fit"><img src="images/Figura 50.png" alt="" /></span>
																	<p class="lead mb-2 text-center"><small> Fonte: Wikipedi, 2023.</small></p>
																</div>
																<p class="lead mb-3 text-justify indent">Como a Curva ROC pode ser complexa de interpretar, uma alternativa é
																	calcular a Área Sob a Curva (AUC - <i>Area Under the Curve</i>). Dessa forma, podemos
																	resumir toda a curva em um único valor entre 0 e 1 que sintetiza a qualidade do
																	classificador.</p>
															<h2 class="mb-0" id="uni9-3">9.3 Classificadores Modernos</h2>
															<p class="lead mb-3 text-justify indent">Com o tempo muitos classificadores, como os listados no início da unidade,
																foram propostos a fim de maximizar as métricas que discutimos anteriormente.
																Dentre estes os que mais obtiveram sucesso em problemas complexos foram os
																classificadores baseados em <i>Ensembles</i> que usam de Árvores de Decisão. O conceito
																de Ensemble refere-se à combinação de vários classificadores individuais para formar
																um modelo mais robusto e preciso. A ideia principal por trás dos <i>ensembles</i> é que a
																combinação de vários modelos "fracos" pode resultar em um modelo "forte". Os
																métodos de ensemble, como <i>Bagging</i> e <i>Boosting</i>, têm sido amplamente utilizados para
																melhorar o desempenho em tarefas de classificação. Enquanto isso, uma Árvore de
																Decisão realiza a classificação por meio de uma estrutura hierárquica, onde cada "nó"
																da árvore representa uma condição sobre as <i>features</i> (características) dos dados, e cada "ramo" representa o resultado de um teste sobre essa condição, conduzindo a
																decisões finais ou previsões nos "nós folha". Como na figura a seguir onde podemos
																ver um exemplo de Árvore de Decisão para decidir entre ir em um compromisso ou
																não.</p>
																<p class="lead mb-3 text-center indent" id="link-figura-51"><b>Figura 51</b> - Exemplo de uma árvore de decisão sobre o problema de decidir sair de
																	casa ou não</p>
																<div>
																	<span class="image fit"><img src="images/Figura 51.png" alt="" /></span>
																	<p class="lead mb-2 text-center"><small> Fonte: autoria própria.</small></p>
																</div>
																<p class="lead mb-3 text-justify indent">Dentre os classificadores que combinam Ensemble e Árvores de Decisão
																	podemos destacar o <i>Extreme Gradient Boosting</i> (XGBoost) e <i>Light Gradient Boosting
																		Machine</i> (LightGBM):</p>
															<h3 class="mb-0" id="uni9-3-1">9.3.1 XGBoost</h3>
															<ul style="margin-left: 1cm; list-style-type: disc; padding: 0;" class="alt3 lead mb-3 text-justify indent" >
																<li><b>Arquitetura</b>: XGBoost é um algoritmo baseado em <i>Gradient Boosting</i> que
																	implementa técnicas como regularização para evitar <i>overfitting</i> (sobreajuste),
																	além de outras otimizações como paralelização e uso de histogramas para
																	acelerar sua execução.</li>
																<li><b>Desempenho</b>: XGBoost é conhecido por seu alto desempenho em termos de
																	precisão e velocidade, sendo capaz de lidar com grandes conjuntos de dados e
																	modelos complexos.</li>
																<li><b>Aplicações</b>: É amplamente utilizado em diversas áreas, desde previsão de risco
																	de crédito até diagnóstico médico, onde a maximização de métricas como
																	<i>F1-score</i> e AUC-ROC é crucial.</li>																
															</ul>
															<h3 class="mb-0" id="uni9-3-2">9.3.2 LightGBM</h3>
															<ul style="margin-left: 1cm; list-style-type: disc; padding: 0;" class="alt3 lead mb-3 text-justify indent" >
																<li><b>Arquitetura</b>: LightGBM é outro algoritmo de <i>Gradient Boosting</i>, mas com foco
																	em maior eficiência. Ele utiliza técnicas como o algoritmo de aprendizado
																	baseado em folhas (<i>leaf-wise</i>), que cresce as árvores de decisão de maneira
																	mais eficiente em termos de memória e tempo de computação.</li>
																<li><b>Desempenho</b>: LightGBM é particularmente rápido em treinar modelos em
																	grandes volumes de dados e pode lidar melhor com características de alta
																	dimensão e dados esparsos.</li>
																<li><b>Aplicações</b>: LightGBM é usado em muitos problemas industriais, incluindo
																	classificação de texto, recomendação de produtos e detecção de fraudes, onde a
																	precisão e a velocidade são críticas.</li>																
															</ul>
															<p class="lead mb-3 text-justify indent">XGBoost e LightGBM são algoritmos altamente eficazes em evitar o overfitting
																(sobreajuste), graças ao uso de técnicas de regularização e otimização que melhoram
																a capacidade de generalização dos modelos. Eles são otimizados para alta
																performance, utilizando paralelização e métodos de processamento eficientes, o que
																permite o treinamento em grandes conjuntos de dados de maneira relativamente
																rápida. Além disso, esses algoritmos são extremamente flexíveis e escaláveis,
																suportando diferentes tipos de dados e permitindo ajustes finos nos parâmetros do
																modelo para alcançar o melhor desempenho possível em métricas como acurácia,
																F1-score e AUC-ROC. Outra vantagem significativa é a capacidade de lidar com dados
																desbalanceados, graças a opções internas para ajustar pesos de classe e métricas
																específicas, permitindo que XGBoost e LightGBM encontrem o equilíbrio ideal entre
																precisão e <i>recall</i>.</p>
															<p class="lead mb-3 text-justify indent">Outro ponto relevante de ambos os classificadores é a capacidade de equilibrar
																viés e variância, abordando de forma eficiente esse dilema clássico do Aprendizado
																de Máquina. O desafio de encontrar o equilíbrio ideal entre viés e variância é
																fundamental para o desenvolvimento de modelos eficazes e robustos. Esses dois
																conceitos estão diretamente ligados ao desempenho de um modelo em termos de sua capacidade de generalização para dados novos e não vistos. Na figura a seguir temos
																uma ilustração do efeito de ambos os conceitos.</p>
																<p class="lead mb-3 text-center indent" id="link-figura-52"><b>Figura 52</b> - Ilustração do efeito do Viés e Variância</p>
																<div>
																	<span class="image fit"><img src="images/Figura 52.png" alt="" /></span>
																	<p class="lead mb-2 text-center"><small> Fonte: autoria própria.</small></p>
																</div>
																<p class="lead mb-3 text-justify indent">Viés: Refere-se à diferença entre as previsões médias de um modelo e os
																	valores reais que ele está tentando prever. Um modelo com alto viés tende a fazer
																	suposições fortes e simplistas sobre os dados, o que pode levar a subajuste
																	(<i>underfitting</i>), onde o modelo é incapaz de capturar a complexidade dos dados de
																	treinamento, resultando em baixa performance tanto nos dados de treinamento
																	quanto nos dados de teste.</p>
																<p class="lead mb-3 text-justify indent">Variância: Refere-se à sensibilidade do modelo às variações nos dados de
																	treinamento. Um modelo com alta variância tende a se ajustar muito de perto aos
																	dados de treinamento, capturando até mesmo o ruído presente, o que leva a um
																	superajuste (<i>overfitting</i>). Embora o modelo apresente alta performance nos dados de
																	treinamento, ele falha ao generalizar para novos dados, resultando em desempenho
																	inconsistente nos dados de teste.</p>
															<h2 class="mb-0" id="uni9-4">9.4 <i>Notebook Colab</i></h2>
															<p class="lead mb-3 text-justify indent">No notebook a seguir iremos praticar os conceitos estudados na unidade ao
																estudar e solucionar um problema de classificação de vinhos através das suas
																características químicas.</p>
																<div class="box">
																	<div class="lead mb-3 text-center"><a href="https://colab.research.google.com/drive/13kaBaoI_3tjaB3DsrlON6_K_rG_AkIwK">https://colab.research.google.com/drive/13kaBaoI_3tjaB3DsrlON6_K_rG_AkIwK</a></div>
																</div>
																<p><span class="image left" style="width: 25%;"><img src="Robozinho/roboCuriosoLupaRoxoEsquerda.png" alt="" /></span></p>
																<div class="box2">
																	<h3 class="mb-0" id="1-saiba-mais">Saiba mais…</h3>
																	<p class="lead mb-3 text-justify">k-nn - <a href="https://youtu.be/HVXime0nQeI?si=zRbX-4XwNUouNy9h">https://youtu.be/HVXime0nQeI?si=zRbX-4XwNUouNy9h</a></p>
																	<p class="lead mb-3 text-justify">Árvores de decisão - <a href="https://www.youtube.com/watch?v=_L39rN6gz7Y">https://www.youtube.com/watch?v=_L39rN6gz7Y</a></p>
																	<p class="lead mb-3 text-justify">Florestas aleatórias - <a href="https://www.youtube.com/watch?v=J4Wdy0Wc_xQ">https://www.youtube.com/watch?v=J4Wdy0Wc_xQ</a></p>	
																	<p class="lead mb-3 text-justify">Regressão Logística - <a href="https://www.youtube.com/watch?v=yIYKR4sgzI8">https://www.youtube.com/watch?v=yIYKR4sgzI8</a></p>
																	<p class="lead mb-3 text-justify">SVM - <a href="https://www.youtube.com/watch?v=efR1C6CvhmE&feature=youtu.be">https://www.youtube.com/watch?v=efR1C6CvhmE&feature=youtu.be</a></p>
																	<p class="lead mb-3 text-justify">ROC e AUC - <a href="https://youtu.be/4jRBRDbJemM?si=HFvY9Ish7trA8Ww1">https://youtu.be/4jRBRDbJemM?si=HFvY9Ish7trA8Ww1</a></p>
																	<p class="lead mb-3 text-justify">Matriz de Confusão - <a href="https://www.youtube.com/watch?v=Kdsp6soqA7o">https://www.youtube.com/watch?v=Kdsp6soqA7o</a></p>
																	<p class="lead mb-3 text-justify">Métricas - <a href="https://towardsdatascience.com/understanding-confusion-matrix-a9ad42dcfd62">https://towardsdatascience.com/understanding-confusion-matrix-a9ad42dcfd62</a></p>
																</div>
																<p><span class="image right" style="width: 25%;"><img src="Robozinho/roboCuriosoLapisRoxo.png" alt="" /></span></p>
																<div class="box2">
																		<h3 class="mb-0" id="1-saiba-mais">Para relembrar…</h3>
																		<p class="lead mb-3 text-justify">Classificação:</p>
																			<ul style="margin-left: 1cm; list-style-type: disc; padding: 0;" class="alt3 lead mb-3 text-justify indent" >
																				<li>Tarefa fundamental em aprendizagem de máquina</li>
																				<li>Atribui categorias ou rótulos a dados de entrada</li>
																				<li>Ampla aplicabilidade em medicina, finanças, marketing e segurança</li>
																			</ul>																		
																		<p class="lead mb-3 text-justify">Aplicações:</p>
																			<ul style="margin-left: 1cm; list-style-type: disc; padding: 0;" class="alt3 lead mb-3 text-justify indent" >
																				<li>Diagnóstico de doenças</li>
																				<li>Detecção de fraudes bancárias</li>
																				<li>Análise de sentimentos</li>
																				<li>Reconhecimento de imagens</li>
																			</ul>
																		<p class="lead mb-3 text-justify indent">Métricas de avaliação:</p>
																		<ul style="margin-left: 1cm; list-style-type: disc; padding: 0;" class="alt3 lead mb-3 text-justify indent" >
																			<li>Precisão: proporção de previsões positivas corretas</li>
																			<li><i>Recall</i> (sensibilidade): proporção de instâncias positivas identificadas
																				corretamente</li>
																			<li><i>F1-score</i>: média harmônica entre precisão e <i>recall</i></li>
																			<li>Matriz de confusão: visão detalhada do desempenho do modelo</li>																			
																		</ul>
																		<p class="lead mb-3 text-justify indent">Algoritmos básicos:</p>
																		<ul style="margin-left: 1cm; list-style-type: disc; padding: 0;" class="alt3 lead mb-3 text-justify indent" >
																			<li>k-NN (Vizinhos mais próximos)</li>
																			<li>Árvores de Decisão</li>
																			<li>Florestas Aleatórias</li>
																			<li>Regressão Logística</li>
																			<li>SVM</li>
																		</ul>
																		<p class="lead mb-3 text-justify indent">Curva ROC e AUC:</p>
																		<ul style="margin-left: 1cm; list-style-type: disc; padding: 0;" class="alt3 lead mb-3 text-justify indent" >
																			<li>ROC: representa o desempenho do modelo em diferentes limiares</li>
																			<li>AUC: área sob a curva ROC, medida agregada de desempenho</li>
																			<li>AUC de 1,0 indica classificador perfeito, 0,5 indica classificador
																				aleatório</li>
																			<li>Úteis para comparar modelos e selecionar limiares ótimos,
																				especialmente com classes desbalanceadas</li>																			
																		</ul>
																</div>
															
															

															
															</section>
																<hr class="m-0">

																<section>
																	<div class="image main" id="capa_uni6">
																		<img src="images/6. Unidade_10_Introdução a Machine Learning e Redes Neurais.png" alt="">
																	</div>
																</section>
																<hr class="m-0">
																<section class="resume-section p-3 p-lg-5 d-flex align-items-center">
																	<div class="w-100">
																	<h1 class="mb-0" id="uni10">Unidade X - Agrupamento</h1>
																</div></header>
																<p class="lead mb-3 text-justify indent">Dentre as técnicas de aprendizado não supervisionado, a mais comum é o agrupamento, também conhecido 
																	como clusterização (do inglês <i>clustering</i>). O objetivo do agrupamento é encontrar padrões em dados não rotulados. Diferente da classificação, 
																	que identifica o padrão nas variáveis que representam uma classe, no agrupamento buscamos padrões apenas observando as variáveis em busca de grupos, 
																	ou <i>clusters</i>, que são subconjuntos dos dados com comportamentos em comum, mas que apresentam diferenças entre si.</p>
																<p class="lead mb-3 text-justify indent">Um exemplo de agrupamento é a interpretação de padrões de consumo de clientes. Imaginando uma loja <i>online</i> que 
																	vende calçados, podemos ter diversos tipos de clientes. Alguns podem comprar mais calçados esportivos, outros preferem calçados casuais, e alguns 
																	apenas opções mais formais. Os clientes não possuem rótulos explícitos para determinarmos classes, mas, ao analisarmos o padrão de consumo, podemos 
																	identificar perfis comuns. Ao observar o histórico de compras combinado com dados como idade, gênero e profissão, é possível agrupar os clientes em 
																	agrupamentos que reúnem perfis de compra semelhantes, ao mesmo tempo que separam grupos com perfis diferentes.</p>
																<p class="lead mb-3 text-justify indent">Os diferentes algoritmos de agrupamento buscam identificar similaridades entre os dados enquanto tentam compreender a dissimilaridade entre os grupos. Baseado nas diferentes abordagens para tratar o problema, podemos listar alguns desses métodos no mapa mental a seguir.</p>
																<p class="lead mb-3 text-center" id="link-figura-53"><b>Figura 53</b> - Mapa mental com os algoritmos de agrupamento</p>
																	<div align="center">
																		<span class="image fit" style="width: 70%;"><img src="images/Figura 53 - Mapa mental com os algoritmos de agrupamento.png" alt="" /></span>
																		<p class="lead mb-2 text-center"><small>Fonte: autoria própria.</small></p>
																	</div>
																
																<h2 class="mb-0" id="uni10-1">10.1 K-Means</h2>
																<p class="lead mb-3 text-justify indent">O algoritmo de agrupamento mais comum é o <i>K-Means</i>. Ele pertence à categoria dos algoritmos de clusterização baseados em 
																	partição, cujo objetivo é dividir um conjunto de dados em K agrupamentos distintos, onde cada ponto de dados pertence ao agrupamento mais próximo do seu centróide. 
																	Um centróide é o ponto central do agrupamento e é usado para representar o "centro" do mesmo. Ele é calculado como a média aritmética das coordenadas de todos os pontos 
																	de dados que pertencem a esse agrupamento. O número de agrupamentos, K, é definido pelo usuário e ao fim da execução o esperado é ter K diferentes agrupamentos como demonstrado 
																	na Figura a seguir.</p>
																	<p class="lead mb-3 text-center" id="link-figura-54"><b>Figura 54</b> - Ilustração de um <i>K-Means</i> aplicado com três agrupamentos</p>
																	<div align="center">
																		<span class="image fit" style="width: 70%;"><img src="images/Figura 54 - Ilustração de um K-Means aplicado com três agrupamentos.png" alt="" /></span>
																		<p class="lead mb-2 text-center"><small>Fonte: Adaptada de <a href="https://www.tabnews.com.br/Ga0512/seu-primeiro-projeto-de-machine-learning-usando-python">Murilo, 2023</a>.</small></p>
																	</div>																
																<p class="lead mb-3 text-justify indent">O algoritmo <i>K-Means</i> segue um processo iterativo que pode ser resumido nos seguintes passos:</p>
																<ol style="margin-left: 1cm;"class="alead mb-3 text-justify indent">
																	<li><b>Inicialização:</b></li>
																	<ul class="hollow-circle lead mb-3 text-justify indent">
																		<li>O usuário define o número de agrupamentos K que deseja encontrar.</li>
																		<li>Inicialmente, os centróides são escolhidos aleatoriamente. Esses centróides podem ser selecionados diretamente dos pontos de dados ou gerados aleatoriamente dentro do espaço de variáveis.</li>
																	</ul>
																	<li><b>Atribuição de Agrupamentos:</b></li>
																	<ul class="hollow-circle lead mb-3 text-justify indent">
																		<li>Cada ponto de dados é atribuído ao agrupamento cujo centróide é o mais próximo. A proximidade é geralmente medida pela distância euclidiana.</li>
																	</ul>
																	<li><b>Atualização dos Centróides:</b></li>
																	<ul class="hollow-circle lead mb-3 text-justify indent">
																		<li>Depois que todos os pontos foram atribuídos a seus respectivos agrupamentos, os centróides de cada agrupamento são recalculados. O novo centróide é a média aritmética de todos os pontos dentro do agrupamento.</li>
																	</ul>
																	<li><b>Convergência:</b></li>
																	<ul class="hollow-circle lead mb-3 text-justify indent">
																		<li>Os passos de atribuição de agrupamentos e atualização dos centróides são repetidos iterativamente até que os centróides não mudem mais significativamente ou até que um número máximo de iterações seja atingido. A convergência é geralmente alcançada quando a atribuição dos pontos aos agrupamentos não muda mais, ou seja, os centróides permanecem estáveis. Para calcular a estabilidade dos centróides é usado o cálculo da inércia que refere-se à soma das distâncias quadradas entre cada ponto de dados e o centróide.</li>
																	</ul>
																</ol>
																<p class="lead mb-3 text-justify indent">O algoritmo <i>K-Means</i> é eficiente para uso em grandes bases de dados e possui uma convergência relativamente rápida. 
																	Por outro lado, o parâmetro K pode ser um desafio em sua aplicação, pois é necessário definir previamente a quantidade de agrupamentos a serem encontrados. 
																	Outro problema comum é a sensibilidade a <i>outliers</i>, que podem alterar significativamente a posição dos centróides. Algumas variações do <i>K-Means</i> propõem o uso 
																	de outras formas de calcular os centróides, como o <i>K-Medoids</i>, que utiliza um dado real do agrupamento como referência central, ou o <i>K-Medians</i>, que usa a mediana do agrupamento.</p>

																<h2 class="mb-0" id="uni10-2">10.2 DBSCAN</h2>
																<p class="lead mb-3 text-justify indent">Uma alternativa mais moderna ao <i>K-means</i> é o DBSCAN. O algoritmo possui duas principais vantagens,  a capacidade de detectar outliers e 
																	excluir tais dados dos agrupamentos os identificando como ruído, e a definição automática do número de agrupamentos. Para alcançar tais vantagens o método funciona baseado em 
																	densidade considerando regiões de alta densidade como possíveis agrupamentos. Após definir agrupamentos iniciais ele considera as regiões próximas a partir do raio entre os pontos 
																	já pertencentes ao agrupamento, isso faz com que o método encontre agrupamentos de quaisquer formatos, o que é diferente do <i>K-means</i>, que por considerar apenas a distância para a 
																	condróide ele assuma que os agrupamentos sejam esféricos. Após encontrar as regiões de alta densidade únicas estas são consideradas agrupamentos únicos, possibilitando assim identificar 
																	quando agrupamentos existiram no conjunto de dados.</p>
																	<p class="lead mb-3 text-center" id="link-figura-55"><b>Figura 55</b> - Exemplos de aplicação do <i>K-means</i> e DBSCAN</p>
																	<div align="center">
																		<span class="image fit" style="width: 70%;"><img src="images/Figura 55 - Exemplos de aplicação do K-means e DBSCAN.png" alt="" /></span>
																		<p class="lead mb-2 text-center"><small>Fonte: <a href="https://towardsdatascience.com/understanding-dbscan-algorithm-and-implementation-from-scratch-c256289479c5">Medium, 2020</a>.</small></p>
																	</div>																	
																<h2 class="mb-0" id="uni10-3">10.3 Avaliação de Agrupamentos</h2>
																<p class="lead mb-3 text-justify indent">A avaliação de agrupamentos é um aspecto crucial na análise de dados, pois ajuda a determinar a qualidade e a utilidade dos clusters identificados por algoritmos de agrupamento. 
																	Diferente de tarefas de aprendizado supervisionado, onde as métricas de avaliação como acurácia, precisão e <i>recall</i> podem ser facilmente calculadas com base em rótulos conhecidos, o agrupamento geralmente é um 
																	problema de aprendizado não supervisionado, onde não se tem rótulos. Isso torna a avaliação dos agrupamentos mais desafiadora e subjetiva. Existem duas principais abordagens para avaliação de agrupamentos: avaliação 
																	interna e avaliação externa.</p>
																<p class="lead mb-3 text-justify indent">As métricas de avaliação interna avaliam a qualidade dos agrupamentos com base nas propriedades intrínsecas dos dados e dos agrupamentos formados, sem usar informações externas ou rótulos verdadeiros.</p>
																<p class="lead mb-3 text-justify indent">A métrica de avaliação interna mais comum é o Índice de Silhueta (<i>Silhouette Score</i>) que mede a coesão e a separação dos agrupamentos. Para cada ponto, a silhueta é calculada como a diferença entre a 
																	distância média ao próprio agrupamentos (coesão) e a distância média ao agrupamentos mais próximo (separação), normalizada pela maior dessas distâncias. O índice de silhueta varia de -1 a 1, onde valores próximos de 1 indicam que os pontos 
																	estão bem agrupados em seus próprios <i>clusters</i>, valores próximos de 0 indicam sobreposição de <i>clusters</i>, e valores negativos sugerem que os pontos podem estar mal agrupados.</p>
																<p class="lead mb-3 text-justify indent">Na figura a seguir podemos ver a avaliação do Índice de Silhueta do agrupamento do <i>dataset Wine</i> usando duas variáveis obtidas com PCA e o método <i>K-Means</i> com K igual a 2 e 3. Neste exemplo o resultado com 
																	dois agrupamentos possui maior índice e isso pode ser visualizado pela separação dos agrupamentos. Com três, o agrupamento vermelho e verde estão muito próximos, o que pode indicar que sejam apenas um e não dois agrupamentos separados.</p>
																<p class="lead mb-3 text-center" id="link-figura-56"><b>Figura 56</b> - Exemplos de agrupamentos e índice de silhueta com uso do KNN com diferentes valores de <i>k</i></p>
																<div align="center">
																	<span class="image fit" style="width: 70%;"><img src="images/Figura 56.png" alt="" /></span>
																	<p class="lead mb-2 text-center"><small>Fonte: autoria própria.</small></p>
																</div>
																<p class="lead mb-3 text-justify indent">Quando se tem ao menos alguns rótulos ou a possibilidade de rotular dados o agrupamento pode ser validado a partir destes rótulos, realizando assim a avaliação externa. 
																	A técnica mais comum para tal avaliação é o <i>Rand Index</i>, ou Índice de Rand, que calcula a porcentagem de agrupamentos corretos. O índice de Rand varia de -1 a 1, onde 1 indica um agrupamento perfeito em relação aos rótulos verdadeiros, 0 indica agrupamento aleatório e valores negativos indicam desacordo com os rótulos de referência.</p>
																<h2 class="mb-0" id="uni10-4">10.4 </i>Notebook Colab</i></h2>
																<p class="lead mb-3 text-justify indent">No <i>notebook</i> a seguir realizaremos passo a passo o agrupamento do <i>dataset Wine</i> citado anteriormente com uso do algoritmo <i>K-Means</i>.</p>
																<div class="box">
																	<p class="lead mb-3 text-center"><a class="break-all" href="https://colab.research.google.com/drive/1SsSG-x5pZRPaQ_NhL-Gvpcz50QAzpPP-">https://colab.research.google.com/drive/1SsSG-x5pZRPaQ_NhL-Gvpcz50QAzpPP-</a></p>
																</div>
																<p><span class="image right" style="width: 25%;"><img src="Robozinho/roboCuriosoLupaRoxoEsquerda.png" alt="" /></span></p>
																<div class="box2">
																	<h3 class="mb-0" id="uni-11-saiba-mais">Saiba mais…</h3>
																	<ul style="margin-left: 1cm;" class="alt4 lead mb-3 text-justify indent">
																	
																	<li><a href="https://www.youtube.com/watch?v=4b5d3muPQmA">k-means - https://www.youtube.com/watch?v=4b5d3muPQmA</a></li>
																	<li><a href="https://www.youtube.com/watch?v=RDZUdRSDOok">DBSCAN - https://www.youtube.com/watch?v=RDZUdRSDOok</a></li>
																	<li><a href="https://www.youtube.com/watch?v=7xHsRkOdVwo">Agrupamento hierárquico - https://www.youtube.com/watch?v=7xHsRkOdVwo</a></li>
																	<li><a href="https://www.youtube.com/watch?v=a2Kg2_l3L8M">Coeficiente de silhueta - https://www.youtube.com/watch?v=a2Kg2_l3L8M</a></li>
																	<li><a href="https://www.youtube.com/watch?v=4E_DFMt60rc">Método Cotovelo - https://www.youtube.com/watch?v=4E_DFMt60rc</a></li>
																	<li><a href="https://www.youtube.com/watch?v=MHnoWsBJpeM">Como analisar agrupamentos - https://www.youtube.com/watch?v=MHnoWsBJpeM</a></li>
																	
																</ul>	
																</div>
																<p><span class="image left" style="width: 25%;"><img src="Robozinho/roboCuriosoLapisRoxo.png" alt="" /></span></p>
																<div class="box3">
																	<h3 class="mb-0" id="11-relembrar">Para relembrar…</h3>
																	<p class="lead mb-3 text-justify"><font color="#19032B">&#10132 </font>Apesar de semelhantes, classificação e agrupamento são técnicas distintas. 
																		Classificação temos <b>dados rotulados</b>, já sabemos de antemão qual é a resposta correta. 
																		Com métodos de agrupamento, os dados estão <b>sem rótulos</b> e buscamos identificar possíveis formas de agrupamento desses dados criando algumas classes.</p>
																	
																</div>
																</section>
																	<hr class="m-0">
																	<section>
																		<div class="image main" id="capa_uni11">
																			<img src="images/6. Unidade_11_Introdução a Machine Learning e Redes Neurais.png" alt="">
																		</div>
																	</section>
																	<hr class="m-0">
																	<section class="resume-section p-3 p-lg-5 d-flex align-items-center">
																		<div class="w-100">
																		<h1 class="mb-0" id="uni11">Unidade XI - Redes Neurais</h1>
																	</div></header>
																	<p class="lead mb-3 text-justify indent">As RNAs constituem um ramo do Aprendizado de Máquina, o qual, por sua vez, é um subcampo da IA. Inspiradas pela estrutura e função das redes neurais biológicas, as RNAs são sistemas de processamento de informação compostos por múltiplos elementos de processamento interconectados, chamados neurônios artificiais. Esses neurônios são organizados em camadas que transformam entradas em saídas, permitindo que a rede aprenda e faça inferências a partir de dados.</p>
																	<p class="lead mb-3 text-justify indent">Dentro do espectro do ML, as RNAs são particularmente notáveis por sua capacidade de modelar relações complexas e não lineares. Elas são uma ferramenta poderosa para tarefas como classificação, regressão, e até mesmo para geração de conteúdo, como em Redes Generativas Adversárias (GANs). As RNAs se destacam principalmente quando se trata de aprender representações úteis de dados, o que é fundamental em tarefas de visão computacional, PLN e muitas outras áreas.</p>
																	<p class="lead mb-3 text-justify indent">A história das RNAs é marcada por avanços e retrocessos, com períodos de entusiasmo seguidos por períodos de ceticismo. A ideia de simular a atividade cerebral surgiu na década de 1940, com trabalhos pioneiros como o de Warren McCulloch e Walter Pitts, que propuseram um modelo simples de neurônio artificial.</p>
																	<p class="lead mb-3 text-justify indent">O desenvolvimento do Perceptron, na década de 1950 por Frank Rosenblatt, foi um marco importante, mas logo se mostrou limitado devido à sua incapacidade de resolver problemas não lineares. Na década de 1980, o algoritmo de retropropagação (<i>backpropagation</i>) foi popularizado, o que permitiu o treinamento eficiente de redes neurais multicamadas.</p>
																	<p class="lead mb-3 text-justify indent">A virada do século XXI trouxe avanços significativos, impulsionados por melhorias em hardware, algoritmos e disponibilidade de dados. O surgimento das DL revolucionou campos como o reconhecimento de voz e a visão computacional. A partir daí, o interesse pelas RNAs cresceu exponencialmente, levando a aplicações práticas em diversos setores e contribuindo para o desenvolvimento de tecnologias inovadoras.</p>
																	<h2 class="mb-0" id="uni11-1">11.1 Neurônio Artificial</h2>
																	<p class="lead mb-3 text-justify indent">O neurônio biológico é a unidade básica de processamento no cérebro humano, caracterizado por sua capacidade de receber sinais elétricos, processá-los e transmiti-los a outros neurônios. Um neurônio artificial, por sua vez, é uma abstração simplificada desse modelo biológico. Ele recebe entradas (sinais), pondera cada uma delas com um peso específico e as combina, geralmente adicionando um viés. A soma ponderada é então passada por uma função de ativação, que determina se e como o "neurônio" deve responder — ou seja, se deve "disparar".</p>
																	<p class="lead mb-3 text-justify indent">Embora a inspiração seja clara, é importante notar que a analogia não é perfeita. As RNAs são construções simplificadas que capturam apenas aspectos gerais da função neural biológica, sendo projetadas para otimizar a eficiência computacional e a capacidade de aprendizado de padrões, e não para replicar o cérebro humano com precisão.</p>
																	<p class="lead mb-3 text-justify indent">O neurônio artificial, ilustrado na figura abaixo, recebe múltiplas entradas, que podem ser sinais de outros neurônios ou dados de entrada direta (X), cada uma com um peso (W) associado. Esses pesos representam a força das conexões entre os neurônios, similar às sinapses no cérebro humano.</p>
																	<p class="lead mb-3 text-center" id="link-figura-57"><b>Figura 57</b> - Esquema de um neurônio artificial - <i>Perceptron</i></p>
																		<div align="center">
																			<span class="image fit" style="width: 70%;"><img src="images/Figura 57 - Esquema de um neurônio artificial - Perceptron.png" alt="" /></span>
																			<p class="lead mb-2 text-center"><small>Fonte: Adaptada de <a href="https://miro.medium.com/v2/resize:fit:720/format:webp/1*upfpVueoUuKPkyX3PR3KBg.png">Medium, 2024</a>.</small></p>
																		</div>
																	<p class="lead mb-3 text-justify indent">As entradas ponderadas são somadas, e um viés (b) pode ser adicionado a esta soma para ajustar o ponto de ativação do neurônio. O resultado é então passado através de uma função de ativação, que introduz não linearidade ao modelo. A função de ativação (f) determina a saída do neurônio, que pode ser enviada para outros neurônios em camadas subsequentes ou ser parte da saída final da rede.</p>
																	<p class="lead mb-3 text-justify indent">Os pesos (W) em uma rede neural artificial são parâmetros ajustáveis que determinam a influência relativa das entradas na saída do neurônio. Durante o treinamento da rede, os pesos são modificados através do processo de aprendizado, permitindo que a rede ajuste suas respostas para melhor se adequar aos dados.</p>
																	<p class="lead mb-3 text-justify indent">O viés, também conhecido como <i>bias</i>, é um parâmetro adicional que permite ajustar a resposta do neurônio de forma independente das entradas, funcionando como uma tentativa de representar o viés presente no problema.</p>
																	<p class="lead mb-3 text-justify indent">A função de ativação tem a função de transformar o resultado do somatório em uma saída coerente. Inicialmente, foi utilizada uma função <i>step</i>, que respondia com 0 quando o somatório resultava em um valor negativo e com 1 quando o valor era positivo. Posteriormente, começaram a ser usadas funções diferentes, como a sigmóide, que mapeia a saída em valores contínuos entre 0 e 1, como ilustrado na figura a seguir.</p>
																	<p class="lead mb-3 text-center" id="link-figura-58"><b>Figura 58</b> - Funções de ativação <i>step</i> e <i>sigmóide</i></p>
																		<div align="center">
																			<span class="image fit" style="width: 70%;"><img src="images/Figura 58 - Funções de ativação step e sigmóide.png" alt="" /></span>
																			<p class="lead mb-2 text-center"><small>Fonte: autoria própria.</small></p>
																		</div>
																	<p class="lead mb-3 text-justify indent">Este modelo de neurônio foi inicialmente proposto como uma nova abordagem de Aprendizado de Máquina, capaz de resolver múltiplas tarefas. No entanto, devido à sua simplicidade, não conseguiu obter resultados significativos. O avanço das RNAs ocorreu com a introdução do algoritmo de <i>backpropagation</i>, que possibilitou a criação de redes com múltiplas camadas, conhecidas como <i>Multi-Layer Perceptron</i> (MLP).</p>
																	<h2 class="mb-0" id="uni11-2">11.2 <i>Multi-Layer Perceptron</i></h2>
																	<p class="lead mb-3 text-justify indent">O cérebro humano é composto por uma complexa rede de neurônios biológicos interligados. De maneira similar, às pesquisas em RNAs buscaram formas de combinar vários neurônios artificiais para formar uma rede mais complexa. A solução surgiu com o algoritmo de <i>backpropagation</i>, que deu origem às redes chamadas MLPs. Como o nome sugere, essas redes organizam os perceptrons, o neurônio artificial proposto anteriormente, em forma de camadas, como ilustrado na figura a seguir.</p>
																	<p class="lead mb-3 text-center" id="link-figura-59"><b>Figura 59</b> - Esquema básico de um <i>Multi-Layer Perceptron</i></p>
																		<div align="center">
																			<span class="image fit" style="width: 70%;"><img src="images/Figura 59 - Esquema básico de um Multi-Layer Perceptron.png" alt="" /></span>
																			<p class="lead mb-2 text-center"><small>Fonte: Adaptada de <a href="https://www.researchgate.net/publication/379446797_Machine_learning_embedded_EM_algorithms_for_semiparametric_mixture_regression_models">Xiang, 2024</a>.</small></p>
																		</div>
																	<p class="lead mb-3 text-justify indent">Em um MLP temos três principais estruturas:</p>
																	<ul style="margin-left: 1cm;" class="alt4 lead mb-3 text-justify indent">
																		<li><b>Camada de Entrada</b>: A camada de entrada recebe as variáveis do problema a ser tratado. Os neurônios desta camada multiplicam seus pesos pelas variáveis, com cada variável tendo um peso independente. Por conta disso, o número de neurônios é dado pelo número de entradas.</li>
																		<li><b>Camada Escondida</b>: A camada escondida recebe as saídas da camada anterior e gera uma nova saída. O conceito por trás da camada escondida é proporcionar uma interpretação mais complexa dos dados por meio da combinação de camadas. Um MLP básico possui ao menos uma camada escondida, mas o mesmo processo de treinamento pode ser aplicado a várias camadas, o que pode proporcionar uma compreensão mais profunda do problema. O número de neurônios na camada escondida é arbitrário e quanto mais, maior a capacidade da rede.</li>
																		<li><b>Camada de Saída</b>: A camada de saída é responsável por fornecer a resposta ao problema, seja uma classificação ou regressão. Ela transforma a abstração gerada pela camada escondida em saídas específicas para o problema tratado. Em um problema de classificação com duas classes, por exemplo, é comum termos dois neurônios de saída, cada um representando a probabilidade da entrada pertencer a uma das classes.</li>
																	</ul>
																	<p class="lead mb-3 text-justify indent">O <i>backpropagation</i> é o algoritmo responsável por treinar o MLP. Em um treinamento de uma RNA temos dois estágio: o feedfoward e logo após o backpropagation, como na figura a seguir. No <i>feedfoward</i> os diversos exemplos de um dataset são passados pela rede em direção a saída, isso faz com que tenhamos respostas para um dos exemplos e com base nessas respostas é calculado o erro do MLP.</p>
																	<p class="lead mb-3 text-center" id="link-figura-60"><b>Figura 60</b> - Esquema básico de um <i>Multi-Layer Perceptron</i> com indicação de fluxo de dados no <i>feedforward</i> e <i>backpropagation</i></p>
																	<div align="center">
																		<span class="image fit" style="width: 70%;"><img src="images/Figura 60.png" alt="" /></span>
																		<p class="lead mb-2 text-center"><small>Fonte: Adaptada de <a href="https://www.researchgate.net/publication/379446797_Machine_learning_embedded_EM_algorithms_for_semiparametric_mixture_regression_models">Xiang, 2024</a>.</small></p>
																	</div>
																	<p class="lead mb-3 text-justify indent">O erro é mensurado pela chamada função de custo, também chamada de função de perda ou <i>loss function</i> em inglês. A função de custo é responsável por guiar o treinamento para que o MLP reduza o erro a cada tentativa. Uma função de custo comum e que foi usada inicialmente para treinar MLPs é o MSE. A função consiste em calcular a média do erro quadrático de cada amostra como mostra a equação:</p>
																	
																	<p class="formula text-center" >
																		<strong>MSE</strong> = 
																		<span class="fraction">
																			<span class="numerator">1</span>
																			<span class="denominator cursive">n</span>
																		</span>
																		<span class="summation">
																			<sup class="cursive">n</sup>
																			&sum;
																			<sub class="cursive">i=1</sub>
																		</span>
																		(<span class="cursive">y</span> - <span class="cursive">&#x0177</span>)²
																	</p>

																	
																<p class="lead mb-3 text-justify indent">Na equação o <i>n</i> se refere as <i>n</i> amostras do conjunto de treino, o <i>y</i> é o rótulo, resposta esperada, e &#x0177 a resposta calculada pela rede. Existem 
																	outras funções de perda como a Entropia Cruzada, Divergência KL e Erro Absoluto Médio, cada uma possui suas características e são usadas 
																	conforme o tipo de saída da rede neural. A partir do erro é calculado o vetor gradiente em cada neurônio da camada de saída e logo em 
																	seguida ajustados os pesos e o viés. O vetor gradiente é um operador no cálculo vetorial que indica a direção na qual uma função cresce 
																	mais rapidamente. Na figura a seguir, podemos ver um exemplo com a superfície de uma função e o vetor gradiente calculado em um ponto específico.</p>
																	
																	<p class="lead mb-3 text-center" id="link-figura-61"><b>Figura 61</b> - Exemplo de vetor gradiente em uma função com duas variáveis</p>
																	<div align="center">
																		<span class="image fit" style="width: 70%;"><img src="images/Figura 61 - Exemplo de vetor gradiente em uma função com duas variáveis.png" alt="" /></span>
																		<p class="lead mb-2 text-center"><small>Fonte: autoria própria.</small></p>
																	</div>
																	<p class="lead mb-3 text-justify indent">Como a função de perda mensura o erro do modelo, ao movimentarmos os pesos na direção oposta ao gradiente, obteremos novos pesos que reduzirão o erro calculado. Esse processo de otimização é chamado de Gradiente Descendente, e a repetição iterativa deste processo realiza o treinamento do MLP, reduzindo progressivamente o erro em relação às amostras de treinamento.</p>
																	<p class="lead mb-3 text-justify indent">Para corrigir as camadas escondidas e de entrada de um MLP o cálculo do gradiente é realizado novamente a cada camada, gerando assim uma série de cálculos que propagam o erro, daí o nome <i>backpropagation</i>. A retropropagação do erro garante que a rede seja ajustada de forma que as camadas trabalhem em conjunto para minimizar o erro e assim gerar respostas corretas.</p>
																	<p class="lead mb-3 text-justify indent">O MLP oferece uma capacidade muito maior do que um neurônio artificial individual, pois, com várias camadas, é capaz de construir funções discriminantes complexas. No entanto, com a introdução de várias camadas, surge o problema do <i>vanishing gradient</i>, ou "sumiço do gradiente" em português. Ao retropropagar o gradiente para camadas anteriores, temos um produto de múltiplos gradientes, o que se torna problemático devido à função de ativação sigmóide, que gera gradientes pequenos e sempre menores que 1. Como resultado, quanto mais camadas escondidas, menor o gradiente nas primeiras camadas, tornando-as mais difíceis de serem treinadas. Este problema conteve o avanço das redes neurais por algumas décadas e a solução para este problema deu origem às chamadas DL.</p>
																	<h2 class="mb-0" id="uni11-3">11.3 <i>Deep Learning</i></h2>
																	<p class="lead mb-3 text-justify indent">O estudo das redes neurais avançou significativamente após a criação do <i>backpropagation</i>, resultando em diversos 
																		aprimoramentos em relação ao MLP clássico. Um dos primeiros avanços foi a introdução da função <i>Rectified Linear Unit</i> (ReLU), que substituiu a função 
																		sigmoide e ajudou a mitigar o problema do <i>vanishing gradient</i>. Como mostrado na figura a seguir, a ReLU funciona de maneira simples, permitindo a 
																		passagem de sinais positivos e anulando valores negativos, substituindo-os por 0. Esse funcionamento é suficiente para permitir que os neurônios 
																		mapeiem suas saídas, ao mesmo tempo em que gera gradientes melhores, pois a derivada (inclinação) da função ReLU é 1 e constante. Com isso, 
																		multiplicar seus gradientes através de várias camadas não apresenta o mesmo problema que ocorre com a sigmóide. Com uso da ReLU surgiram as 
																		primeiras redes neurais com muitas camadas, caminhando assim para as redes profundas.</p>
																		<p class="lead mb-3 text-center" id="link-figura-62"><b>Figura 62</b> - Funções de ativação sigmóide e ReLU</p>
																		<div align="center">
																			<span class="image fit" style="width: 70%;"><img src="images/Figura 62 - Funções de ativação sigmóide e ReLU.png" alt="" /></span>
																			<p class="lead mb-2 text-center"><small>Fonte: Adaptada de <a href="https://link.springer.com/article/10.1007/s00521-023-09178-5">Locke, 2023</a>.</small></p>
																		</div>
																	<p class="lead mb-3 text-justify indent">Outros pontos avançaram para o surgimento das redes profundas, sendo os principais:</p>

																	<ul style="margin-left: 1cm;" class="alt4 lead mb-3 text-justify indent">
																		<li><b>Otimizadores</b>: Novos algoritmos para a aplicação do gradiente nos pesos, também conhecidos como otimizadores, foram propostos para otimizar as redes de maneira mais rápida e eficiente.</li>
																		<li><b>Inicialização dos pesos</b>: Toda rede neural precisa iniciar com alguns pesos aleatórios para dar início ao processo de <i>feedforward</i>. Estudos descobriram formas melhores de definir esses pesos iniciais, melhorando o desempenho do treinamento.</li>
																		<li><b>Regularização</b>: O sobreajuste dos dados sempre foi um problema nas RNAs, pois com muitas camadas e neurônios, o modelo passa a ter alta capacidade, o que facilita o sobreajuste aos dados de treinamento. Para evitar esse problema, foram propostas técnicas como <i>Dropout</i> e <i>Batch Normalization</i>.</li>
																		<li><b>Infraestrutura computacional</b>: O surgimento de hardware especializado contribuiu enormemente para a evolução das RNAs. Unidades de Processamento Gráfico (GPUs) e Unidades de Processamento de Tensor (TPUs) viabilizaram o treinamento de redes muito maiores do que se tinha anteriormente.</li>
																	</ul>
																	<p class="lead mb-3 text-justify indent">Além dos pontos apontados acima, tivemos também o desenvolvimento de arquiteturas alternativas ao MLP. Sendo a principal a CNN.</p>

																	<h3 class="mb-0" id="uni11-3-1">11.3.1 CNNs: Redes Neurais Convolucionais</h3>
																	<p class="lead mb-3 text-justify indent">As CNNs propostas nos anos 90 substituem o neurônio artificial, como o perceptron, por uma operação de convolução que pode ser treinada. A convolução é uma operação entre sinais que tem como objetivo buscar por um padrão. A ideia de utilizar uma convolução vem da dificuldade do MLP em lidar com imagens. Uma imagem digital é um mapa de pixel e para usar uma imagem como entrada em um MLP seria necessário um peso para cada pixel. Esse arranjo gera uma entrada com altíssima dimensão, com uma imagem de 200x200 seriam 40 mil entradas, e os pesos não possuem compreensão de que pixels podem ser vizinhos.</p>
																	<p class="lead mb-3 text-center" id="link-figura-63"><b>Figura 63</b> - Esquema básico de um <i>Multi-Layer Perceptron</i> ao receber uma imagem</p>
																		<div align="center">
																			<span class="image fit" style="width: 70%;"><img src="images/Figura 63.png" alt="" /></span>
																			<p class="lead mb-2 text-center"><small>Fonte: Adaptada de <a href="https://www.dropbox.com/scl/fi/vbw3iv4k8xunelxfbebh5/mpl_imagem.png?rlkey=ba6x96e6t7q237ttkm29j8lm3&dl=0">Anderson, 2024</a>.</small></p>
																		</div>
																	
																	<p class="lead mb-3 text-justify indent">A convolução, por outro lado, oferece uma operação que permite compreender a vizinhança dos pixels e reduz a necessidade de tantos pesos, pois funciona como um filtro que captura uma região da imagem, gerando uma interpretação dessa região como saída. A figura a seguir mostra de forma simplificada uma sequência de duas convoluções sendo aplicadas.</p>
																	<p class="lead mb-3 text-center" id="link-figura-64"><b>Figura 64</b> - Esquema de um campo receptivo de duas camadas convolucionais</p>
																		<div align="center">
																			<span class="image fit" style="width: 70%;"><img src="images/Figura 64 - Esquema de um campo receptivo de duas camadas convolucionais.png" alt="" /></span>
																			<p class="lead mb-2 text-center"><small>Fonte: Adaptada de <a href="https://www.youtube.com/watch?app=desktop&v=ip2HYPC_T9Q">Deepia, 2024</a>.</small></p>
																		</div>
																	<p class="lead mb-3 text-justify indent">A convolução pode ser aplicada em toda a imagem, reutilizando o mesmo filtro, tornando-se assim muito mais eficiente, em termos de número de parâmetros, do que um MLP. A inspiração para as CNNs vem dos estudos sobre campos receptivos. A descoberta do funcionamento da percepção visual revelou que os sinais gerados pelos olhos são processados em várias camadas de neurônios, criando uma abstração do que está sendo observado. Assim, as CNNs são construídas com uso das convoluções seguidas de um MLP, que realiza a classificação a partir da abstração criada.</p>
																	<p class="lead mb-3 text-justify indent">Apesar das CNNs terem sido introduzidas nos anos 90 foi só com o avanço das RNAs citados anteriormente que passamos a ter CNNs com grande número de camadas. Em 2012 o surgimento da arquitetura chamada AlexNet deu início ao que hoje chamamos de DL. Uma grande arquitetura, treinada em GPU, que combina várias técnicas de otimização e é treinada em um grande volume de dados.</p>
																	<p class="lead mb-3 text-center" id="link-figura-65"><b>Figura 65</b> - Esquema da AlexNet</p>
																		<div align="center">
																			<span class="image fit" style="width: 70%;"><img src="images/Figura 65 - Esquema da AlexNet.png" alt="" /></span>
																			<p class="lead mb-2 text-center"><small>Fonte: Adaptada de <a href="https://www.pinecone.io/learn/series/image-search/imagenet/">Pinecone, 2012</a>.</small></p>
																		</div>
																	<p class="lead mb-3 text-justify indent">A AlexNet contém cinco camadas convolucionais e um MLP com três camadas em sua saída, conforme mostrado na figura anterior, e foi treinada com o conjunto de imagens chamado ImageNet, que contém cerca de 1,2 milhão de imagens obtidas na internet, anotadas em 1000 categorias. O desempenho reportado por essa arquitetura foi muito superior aos métodos tradicionais de visão computacional da época. </p>
																	<p class="lead mb-3 text-center" id="link-figura-66"><b>Figura 66</b> - Exemplo de imagens do ImageNet</p>
																	<div align="center">
																		<span class="image fit" style="width: 70%;"><img src="images/Figura 66.jpg" alt="" /></span>
																		<p class="lead mb-2 text-center"><small>Fonte: Adaptada de <a href="https://cv.gluon.ai/build/examples_datasets/imagenet.html">Gluon, 2012</a>.</small></p>
																	</div>
																		<p class="lead mb-3 text-justify indent">O resultado da AlexNet trouxe grande atenção às redes neurais a partir de 2012, levando ao surgimento de várias outras arquiteturas e avanços nas RNAs. Na visão computacional, surgiram soluções revolucionárias para tarefas como segmentação de imagens, detecção de objetos e descrição de imagens. Grande parte desse avanço se deve à introdução do conceito de Transferência de Aprendizado, conhecido como <i>transfer learning</i> em inglês.</p>
																		<p class="lead mb-3 text-justify indent">A transferência de aprendizado ocorre ao treinar uma CNN em um grande conjunto de dados, como o ImageNet, em uma tarefa mais simples — no caso do ImageNet, a classificação de imagens — e, em seguida, usar os pesos resultantes para iniciar outro treinamento em uma tarefa semelhante, mas com um menor volume de dados disponível. Assim, o primeiro treino passou a ser chamado de pré-treino, enquanto o segundo treinamento é conhecido como ajuste fino, ou <i>fine tuning</i>. Ao retreinar a rede, ela é capaz de trazer consigo o entendimento básico dos objetos do dataset do seu treino inicial, como exemplificado na figura a seguir, e adaptar esse conhecimento prévio para uma nova tarefa.</p>
																		<p class="lead mb-3 text-center" id="link-figura-67"><b>Figura 67</b> - Visualização das convoluções obtidas ao treinar uma CNN</p>
																		<div align="center">
																			<span class="image fit" style="width: 70%;"><img src="images/Figura 67  - Visualização das convoluções obtidas ao treinar uma CNN.png" alt="" /></span>
																			<p class="lead mb-2 text-center"><small>Fonte: Adaptada de <a href="https://arxiv.org/pdf/1311.2901">Zeiler, Fergus, 2013</a>.</small></p>
																		</div>
																	
																		<p class="lead mb-3 text-justify indent">Essa abordagem permitiu o uso de DL em diversos problemas que anteriormente não eram abordados com 
																			RNAs devido à falta de volume de dados. No entanto, as CNNs tratavam majoritariamente de problemas que envolviam imagens como entradas. 
																			Em outros campos, como Linguagem Natural e Processamento de Áudio, as CNNs e o <i>transfer learning</i> ainda enfrentavam dificuldades para 
																			obter bons resultados. A mudança nessas áreas ocorreu com o surgimento da arquitetura <i>Transformer</i>, que introduziu uma operação diferente 
																			tanto do MLP quanto da convolução, permitindo o <i>transfer learning</i> com textos e áudios.</p>
																		<p class="lead mb-3 text-justify indent"></p>
																	<h3 class="mb-0" id="uni11-3-2">11.3.2 <i>Transformer</i></h3>
																	<p class="lead mb-3 text-justify indent">Em 2017 foi introduzida pela equipe da Google a arquitetura chamada <i>Transformer</i>. Inicialmente proposta para 
																		tradução de textos, a arquitetura usa de uma operação chamada “mecanismo de atenção” para processar suas entradas. O mecanismo de atenção é uma 
																		técnica que permite que o modelo foque em partes específicas da entrada enquanto realiza uma tarefa. Ele atribui diferentes pesos a diferentes 
																		partes da entrada, destacando informações mais relevantes, como no exemplo da figura a seguir, melhorando assim a performance em tarefas sequenciais e de PLN.</p>
																		<p class="lead mb-3 text-center" id="link-figura-68"><b>Figura 68</b> - Visualização da atenção em um problema de tradução</p>
																		<div align="center">
																			<span class="image fit" style="width: 70%;"><img src="images/Figura 68 - Visualização da atenção em um problema de tradução.png" alt="" /></span>
																			<p class="lead mb-2 text-center"><small>Fonte: autoria própria.</small></p>
																		</div>
																	
																		<p class="lead mb-3 text-justify indent">Com o uso dos </i>Transformers</i> (transformadores), foi possível realizar um pré-treino eficiente tanto em Linguagem Natural 
																			quanto em Áudio. Utilizando a arquitetura pré-treinada na tarefa de modelagem de linguagem, que consiste em prever a próxima palavra de um texto, surgiram 
																			modelos como BERT, GPT e Llama, que revolucionaram o PLN ao resolverem tarefas anteriormente consideradas complexas. O impacto foi semelhante ao das primeiras 
																			CNNs treinadas com o ImageNet, que, no caso do PLN, introduziu o DL em várias tarefas anteriormente tratadas com métodos clássicos de PLN. No contexto do 
																			processamento de áudio, modelos baseados em <i>Transformers</i> como Whisper, Wav2Vec, HuBERT e Tacotron viabilizaram tarefas complexas, como reconhecimento, transcrição e sintetização de fala.</p>
																	<h3 class="mb-0" id="uni11-3-3">11.3.3 Rede Neurais Generativas</h3>
																	<p class="lead mb-3 text-justify indent">RNAs atualmente passaram a dominar a maior parto do campo da IA devido ao ótimo desempenho em tarefas complexas. A possibilidade de explorar os grandes conjuntos de dados que se formaram a partir da digitalização de processo e do avanço da internet age como combustível em soluções baseadas em RNAs. Com o desenvolvimento das redes neurais generativas e de modelos, o campo testemunhou uma explosão na criação de conteúdo sintético, desde imagens hiper-realistas até música e vídeo. Essas inovações não só melhoraram o desempenho em tarefas tradicionais, mas também abriram novas aplicações e indústrias, como arte digital, realidade aumentada e IA criativa. O contexto atual das RNAs é, portanto, marcado por um ciclo virtuoso de inovação, onde grandes dados alimentam redes mais poderosas, que, por sua vez, geram novos dados e tendências, continuando a impulsionar o progresso tecnológico.</p>
																	
																	<h3 class="mb-0" id="uni11-3-4">11.3.4 <i>Frameworks</i> para DL</h3>
																	<p class="lead mb-3 text-justify indent">Com o avanço das RNAs e o surgimento do DL, foram criados <i>frameworks</i> para viabilizar a implementação de 
																		novas arquiteturas neurais. Inicialmente, as implementações eram feitas usando Nvidia <i>Compute Unified Device Architecture</i> (CUDA), que 
																		permite a programação de GPUs de forma geral, e não apenas para a geração de gráficos. No entanto, devido à complexidade da programação com CUDA, 
																		foram propostos <i>frameworks</i> que servem como interface para o uso das GPUs no treinamento de redes neurais.</p>
																	<p class="lead mb-3 text-justify indent">Entre os vários <i>frameworks</i> que surgiram, os principais são o <i>TensorFlow</i> e o PyTorch. 
																		O <i>TensorFlow</i> foi inicialmente desenvolvido pela Google para uso interno e, em 2015, foi disponibilizado como uma biblioteca de código aberto. 
																		O PyTorch foi lançado pela Meta AI (antigo Facebook) em 2016 e foi desenvolvido a partir do framework Torch. Ambos os <i>frameworks</i> são baseados 
																		principalmente em Python e atuam como uma interface para operações implementadas em CUDA. Essas bibliotecas foram fundamentais para popularizar 
																		a implementação e a criação de novos modelos de DL, facilitando o processo de codificação do treinamento e da inferência.</p>
																
																		<p><span class="image right" style="width: 25%;"><img src="Robozinho/roboCuriosoLupaRoxoEsquerda.png" alt="" /></span></p>
																	<div class="box2">
																		<h3 class="mb-0" id="uni-11-saiba-mais">Saiba mais…</h3>
																		<ul style="margin-left: 1cm;" class="alt4 lead mb-3 text-justify indent">
																		
																		<li>Perceptron - <a class="break-all" href="https://youtu.be/6yYUc6nU3Cw?si=LZGZbtV-Ph0d4IJo">https://youtu.be/6yYUc6nU3Cw?si=LZGZbtV-Ph0d4IJo</a></li>
																		<li>Redes Neurais - <a class="break-all" href="https://www.youtube.com/watch?v=CqOfi41LfDw">https://www.youtube.com/watch?v=CqOfi41LfDw</a></li>
																		<li>Redes Neurais - <a class="break-all" href="https://youtu.be/XxZ0BibMTjw?si=vtO6zjtguK1a95nX">https://youtu.be/XxZ0BibMTjw?si=vtO6zjtguK1a95nX</a></li>
																		<li>Gradiente Descendente - <a class="break-all" href="https://youtu.be/31w-xQX0Z_8?si=dkeqa39mdwSTYzhB">https://youtu.be/31w-xQX0Z_8?si=dkeqa39mdwSTYzhB</a></li>
																		<li>Propagação reversa - <a class="break-all" href="https://www.youtube.com/watch?v=IN2XmBhILt4">https://www.youtube.com/watch?v=IN2XmBhILt4</a></li>
																		<li>Propagação reversa - <a class="break-all" href="https://youtu.be/DGNbd2FGw2s?si=HJMNSUrcfyBsQcG4">https://youtu.be/DGNbd2FGw2s?si=HJMNSUrcfyBsQcG4</a></li>
																		<li>ReLU - <a class="break-all" href="https://www.youtube.com/watch?v=68BZ5f7P94E">https://www.youtube.com/watch?v=68BZ5f7P94E</a></li>
																		<li>RNN - <a class="break-all" href="https://www.youtube.com/watch?v=AsNTP8Kwu80">https://www.youtube.com/watch?v=AsNTP8Kwu80</a></li>
																		<li>LSTM - <a class="break-all" href="https://www.youtube.com/watch?v=YCzL96nL7j0">https://www.youtube.com/watch?v=YCzL96nL7j0</a></li>
																		<li>Transformers - <a class="break-all" href="https://www.youtube.com/watch?v=zxQyTK8quyY">https://www.youtube.com/watch?v=zxQyTK8quyY</a></li>
																		<li>CNN - <a class="break-all" href="https://youtu.be/n4rmrZg1_58?si=NxSTmjKr9Ax0lxaH">https://youtu.be/n4rmrZg1_58?si=NxSTmjKr9Ax0lxaH</a></li>
																		<li>AlexNet and ImageNet: The Birth of Deep Learning: - <a class="break-all" href="https://www.pinecone.io/learn/series/image-search/imagenet/">https://www.pinecone.io/learn/series/image-search/imagenet/</a></li>
																		<li>Tutorial de Pytorch: <a class="break-all" href="https://pytorch.org/tutorials/beginner/basics/intro.html">https://pytorch.org/tutorials/beginner/basics/intro.html</a></li>
																		<li>Tutorial de TensorFlow: <a class="break-all" href="https://www.tensorflow.org/learn?hl=pt-br">https://www.tensorflow.org/learn?hl=pt-br</a></li>
																	</ul>	
																	</div>
																	<p><span class="image left" style="width: 25%;"><img src="Robozinho/roboCuriosoLapisRoxo.png" alt="" /></span></p>
																	<div class="box3">
																		<h3 class="mb-0" id="11-relembrar">Para relembrar…</h3>
																		
																		<p class="alt4 lead mb-3 text-justify"><font color="#19032B">&#10132 </font>Estrutura das Redes Neurais:</p>
																		<ul style="margin-left: 1cm;" class="lead mb-3 text-justify indent">
																			<li>Camada de Entrada: recebe dados brutos</li>
																			<li>Camadas Ocultas: processam e capturam complexidade dos dados</li>
																			<li>Camada de Saída: produz a decisão final ou inferência</li>
																		</ul>
																		<p class="alt4 lead mb-3 text-justify"><font color="#19032B">&#10132 </font>Fluxo de Dados e Treinamento:</p>
																		<ul style="margin-left: 1cm;" class="lead mb-3 text-justify indent">
																			<li><i>Feedforward</i>: propagação direta dos dados da entrada para a saída</li>
																			<li><i>Backpropagation</i>: ajuste de pesos baseado no erro entre saída desejada e produzida</li>
																		</ul>
																		<p class="alt4 lead mb-3 text-justify"><font color="#19032B">&#10132 </font><i>Gradient Descent</i>: algoritmo para minimizar a função de custo</p>
																		<p class="alt4 lead mb-3 text-justify"><font color="#19032B">&#10132 </font>Tipos de Redes Neurais:</p>
																		<ul style="margin-left: 1cm;" class="lead mb-3 text-justify indent">
																			<li><i>Perceptrons</i>: neurônio artificial simples</li>
																			<li>MLP: multiplas camadas de Perceptrons</li>
																			<li>CNNs: para processamento de imagens</li>
																			<li>RNNs: para dados sequenciais (LSTM, GRU)</li>
																			<li><i>Autoencoders</i>: para compressão e geração de dados</li>
																			<li>GANs: para geração de dados realistas</li>
																			
																		</ul>
																	</div>
																
																</section>
																		<hr class="m-0">
																		<section>
																			<div class="image main" id="capa_uni12">
																				<img src="images/6. Unidade_12_Introdução a Machine Learning e Redes Neurais.png" alt="">
																			</div>
																		</section>
																		<hr class="m-0">
																		<section class="resume-section p-3 p-lg-5 d-flex align-items-center">
																			<div class="w-100">
																			<h1 class="mb-0" id="uni12">Unidade XII - Encerramento</h1>
																		</div></header>
																		
																		<h2 class="mb-0" id="uni12-1">12.1 Considerações Finais</h2>
																		<p class="lead mb-3 text-justify indent">A jornada pelas técnicas de ML e redes neurais destaca a complexidade e a interconexão das 
																			diversas etapas envolvidas no desenvolvimento de modelos eficazes. Desde a definição clara e a aplicação prática dos conceitos até a 
																			implementação de algoritmos avançados, cada passo é crucial para alcançar resultados precisos e úteis. A importância de uma boa prática de 
																			pré-processamento, incluindo a extração, seleção e normalização de características, não pode ser subestimada, pois essas etapas formam a base 
																			sobre a qual modelos robustos são construídos. Além disso, a compreensão dos desafios como a maldição da dimensionalidade e o <i>overfitting</i> 
																			(sobreajuste) é vital para criar modelos que não apenas aprendam bem com os dados de treinamento, mas também se generalizem bem para novos dados.</p>
																		<p class="lead mb-3 text-justify indent">Ao longo dessa unidade, discutimos uma série de tópicos cruciais no campo do ML, onde exploramos sua definição, suas aplicações, e as diferenças entre IA, ML e DL. Entendemos que ML é a prática de treinar algoritmos para aprender com dados e fazer previsões ou decisões com base nesses dados. Exploramos como diferentes tipos de ML, como aprendizado supervisionado e não supervisionado, são aplicados em áreas diversas, desde reconhecimento de imagem até previsão de mercado.</p>
																		<p class="lead mb-3 text-justify indent">Voltamos nossa atenção para conceitos como detecção de padrões e anomalias, e as tarefas de detecção, reconhecimento e previsão. Falamos sobre como a detecção de padrões e anomalias pode ser usada para identificar comportamentos esperados e inesperados nos dados, enquanto a detecção, reconhecimento e previsão são fundamentais para a construção de sistemas inteligentes capazes de interpretar dados e antecipar eventos futuros.</p>
																		<p class="lead mb-3 text-justify indent">Foram discutidos os diferentes tipos de aprendizagem: supervisionada, não supervisionada, semi-supervisionada e por reforço. Cada tipo foi explicado tecnicamente, complementado com metáforas para facilitar a compreensão e exemplos práticos para ilustrar sua aplicação. Discutimos a importância de entender os diferentes métodos de aprendizagem de máquina para escolher a abordagem mais adequada para cada situação.</p>
																		<p class="lead mb-3 text-justify indent">Abordamos o processamento e transformação de características, discutindo a extração e seleção de características, a relação entre características e dimensionalidade, a maldição da dimensionalidade, a normalização e transformação do espaço de características, e a redução da dimensionalidade. Vimos como técnicas bem aplicadas podem ajudar a simplificar os dados e melhorar a eficiência computacional, e a importância de normalizar dados para equilibrar a contribuição de diferentes características.</p>
																		<p class="lead mb-3 text-justify indent">Exploramos algumas tarefas clássicas como Regressão, Classificação e Agrupamento, passando por diferentes abordagens e modelos para cada problema. Por fim, estudamos as RNAs que tanto estão em destaque atualmente e o processo de surgimento do DL.</p>
																		<p class="lead mb-3 text-justify indent">Este curso tem como objetivo apresentar os conceitos e ferramentas que fundamentam o ML. Ao passar por todos esses tópicos, esperamos que você tenha construído uma base sólida de conhecimento para navegar pelo universo dos problemas orientados a dados e criar novas soluções.</p>
																		<div align="center" >
																			<div class="image fit" style="width: 40%;"><img src="Robozinho/robotDespedidaRoxoComCubo.png" alt="" /></div>
																		</div>

																		</section>
																			<hr class="m-0">
													<section class="resume-section p-3 p-lg-5 d-flex align-items-center">
														<div class="w-100">
															<h1 class="mb-0" id="referencias">Referências</h1>
														</div></header>
																												
														<p class="lead mb-3 text-justify">AEBERHARD, Stefan; COOMANS, Danny; DE VEL, Olivier. Comparative analysis of statistical pattern recognition 
															methods in high dimensional settings. <b>Pattern Recognition</b>, v. 27, n. 8, p. 1065-1077, 1994.</p>	
														<p class="lead mb-3 text-justify">BELLMAN R.E. Adaptive Control Processes. Princeton: <b>Princeton University Press</b>, 1961.</p>														
															<p class="lead mb-3 text-justify">BISHOP, C. M. Pattern Recognition and Machine Learning. New York: <b>Springer</b>, 2006.</p>
														<p class="lead mb-3 text-justify">CHAPELLE, O.; SCHOLKOPF, B.; ZIEN, A. Semi-Supervised Learning. MIT Press, 2006.</p>
														<p class="lead mb-3 text-justify">CHEN, Tianqi <i>et al</i>. Package ‘xgboost’. R version, v. 90, n. 1-66, p. 40, 2019.</p>
														<p class="lead mb-3 text-justify">ESTER, Martin <i>et al</i>. <b>A density-based algorithm for discovering clusters in large spatial databases with noise</b>. In: kdd. 1996. p. 226-231.</p>
														<p class="lead mb-3 text-justify">FISHER, Ronald A. The use of multiple measurements in taxonomic problems. <b>Annals of eugenics</b>, v. 7, n. 2, p. 179-188, 1936.</p>
														<p class="lead mb-3 text-justify">FIX, Evelyn. Discriminatory analysis: nonparametric discrimination, consistency properties. <b>USAF school of Aviation Medicine</b>, 1985.</p>
														<p class="lead mb-3 text-justify">GÉRON, A. Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems. <b>O'Reilly Media</b>, 2019.</p>
														<p class="lead mb-3 text-justify">GUYON, I.; ELISSEEFF, A. An Introduction to Variable and Feature Selection. <b>Journal of Machine Learning Research</b>, 2003.</p>
														<p class="lead mb-3 text-justify">HASTIE, T.; TIBSHIRANI, R.; FRIEDMAN, J. The Elements of Statistical Learning: Data Mining, Inference, and Prediction. <b>Springer Series in Statistics</b>, 2009.</p>
														<p class="lead mb-3 text-justify">HYNDMAN, R.J.; ATHANASOPOULOS, G. Forecasting: principles and practice. Melbourne, Austrália: <b>O Texts</b>, 2021.</p>
														<p class="lead mb-3 text-justify">KE, Guolin <i>et al</i>. Lightgbm: A highly efficient gradient boosting decision tree. <b>Advances in neural information processing systems</b>, v. 30, 2017.</p>
														<p class="lead mb-3 text-justify">MCKINNEY, W. Python for Data Analysis: Data Wrangling with Pandas, NumPy, and IPython. <b>O'Reilly Media</b>, 2017.</p>
														<p class="lead mb-3 text-justify">MITCHELL, T. M. Machine Learning. <b>McGraw-Hill</b>, 1997.</p>
														<p class="lead mb-3 text-justify">NORVIG, Peter; RUSSELL, Stuart. Inteligência artificial. Rio de Janeiro: <b>Grupo GEN</b>, 2013.</p>
														<p class="lead mb-3 text-justify">STARMER, J. The StatQuest Illustrated Guide to Machine Learning!!! <b>Packt Publishing</b>, 2022.</p>
														<p class="lead mb-3 text-justify">THEODORIDIS, S.; KOUTROUMBAS, K. Nonlinear classifiers. <b>Academic Press</b>, p. 151–260, 2009.</p>
														<p class="lead mb-3 text-justify">VANDERPLAS, J. <b>Python Data Science Handbook: Essential Tools for Working with Data</b>. O'Reilly Media, 2016.</p>
														</section>



														<hr class="m-0">
														<section>
															<div class="image main" id="capa_ultima">
																<img src="images/7. Última página_Introdução a Machine Learning e Redes Neurais.png" alt="">
															</div>
															</section>
									



									<hr class="major" />


								</section>

						</div>
					</div>

				<!-- Sidebar -->
					<div id="sidebar">
						<div class="inner">

							<!-- Search -->
								<!--<section id="search" class="alt">
									
										<form method="post" action="#">
											<input type="text" name="query" id="query" placeholder="Search" />
										</form>
																	
								</section>-->
							
							
								
							<!-- Menu -->
								<nav id="menu">
									<header class="major">
										<h6>Introdução a <i>Machine Learning</i> e Redes Neurais</h6>
									</header>
									<ul>
										<li><a href="#capa">Capa</a></li>
										<li><a href="#sumario">Sumário</a></li>
										<li><a href="#apresentacao">Apresentação</a></li>
										
										<li>
											<span class="opener" href="#uni1">Unidade I - <i>Machine Learning</i></span>
											<ul>
												<li><a href="#uni1-1">1.1 O que é <i>Machine Learning</i>?</a></li>
												<li><a href="#uni1-2">1.2 Aplicações de <i>Machine Learning</i></a></li>
												<li><a href="#uni1-3">1.3 Inteligência Artificial x <i>Machine Learning</i> x <i>Deep Learning</i></a></li>
												
											</ul>
										</li>
										<li>
											<span class="opener" href="#uni2">Unidade II - Detecção, reconhecimento e previsão</span>
											<ul>
												<li><a href="#uni2-1">2.1 Detecção de padrões e anomalias</a></li>
												<li><a href="#uni2-2">2.2 Detecção, Previsão e Reconhecimento</a></li>
												
											</ul>
										</li>											
										<li>
											<span class="opener" href="#uni3">Unidade III - Reconhecimento de padrões</span>
											<ul>
												<li><a href="#uni3-1">3.1 O que é reconhecimento?</a></li>
												<li><a href="#uni3-2">3.2 Padrões</a></li>
											</ul>
										</li>
										<li>
											<span class="opener" href="#uni4">Unidade IV - Tipos de aprendizagem de máquina</span>
											<ul>
												<li><a href="#uni4-1">4.1 Aprendizagem Supervisionada</a></li>
												<li><a href="#uni4-2">4.2 Aprendizagem Não Supervisionada</a></li>
												<li><a href="#uni4-3">4.3 Aprendizagem Semi-Supervisionada</a></li>
												<li><a href="#uni4-4">4.4 Aprendizagem por reforço</a></li>
												
											</ul>
										</li>
										<li>
											<span class="opener" href="#uni5">Unidade V - Espaço de características</span>
											<ul>
												<li><a href="#uni5-1">5.1 Extração de características</a></li>
												<li><a href="#uni5-2">5.2 Seleção de características</a></li>
												<li><a href="#uni5-3">5.3 Características vs. dimensionalidade</a></li>
												<li><a href="#uni5-4">5.4 Maldição da dimensionalidade</a></li>
												<li><a href="#uni5-5">5.5 Normalização do espaço de características</a></li>
												<li><a href="#uni5-6">5.6 Transformação do espaço de características</a></li>
												<li><a href="#uni5-7">5.7 Redução da dimensionalidade</a></li>
												<li><a href="#uni5-8">5.8 Seleção de características vs. redução da dimensionalidade</a></li>
												
											</ul>
										</li>
										<li>
											<span class="opener" href="#uni6">Unidade VI - Funções discriminantes</span>
											<ul>
												<li><a href="#uni6-1">6.1 Introdução</a></li>
												<li><a href="#uni6-2">6.2 Aplicações</a></li>
												<li><a href="#uni6-3">6.3 Conceitos Importantes</a></li>
												<li><a href="#uni6-4">6.4 Principais Algoritmos</a></li>
												<li><a href="#uni6-5">6.5 <i>Notebook Colab</i></a></li>
											</ul>
										</li>
										<li>
											<span class="opener" href="#uni7">Unidade VII - Conjuntos de dados</span>
											<ul>
												<li><a href="#uni7-1">7.1 A Importância dos Dados para a Construção de Modelos de ML</a></li>
												<li><a href="#uni7-2">7.2 Dados Estruturados vs. Dados Não Estruturados</a></li>
												<li><a href="#uni7-3">7.3 Conjuntos de Dados Supervisionados, Não Supervisionados e Semi-supervisionados</a></li>
												<li><a href="#uni7-4">7.4 Limpeza de Dados (Tratamento de Valores Ausentes, <i>Outliers</i>, Erros de Digitação)	</a></li>
												<li><a href="#uni7-5">7.5 Pré-processamento (Normalização, Codificação de Variáveis Categóricas)</a></li>
												<li><a href="#uni7-6">7.6 Seleção e Engenharia de Características (<i>Feature Selection</i> e <i>Feature Engineering</i>)</a></li>
												<li><a href="#uni7-7">7.7  Divisão em Conjuntos de Treino, Validação e Teste</a></li>
												<li><a href="#uni7-8">7.8 Dados Desbalanceados e Técnicas para Balanceamento</a></li>
												<li><a href="#uni7-9">7.9 Subajuste (<i>Underfitting</i>) e Sobreajuste (<i>Overfitting</i>)</a></li>
												<li><a href="#uni7-10">7.10 <i>Notebook Colab</i></a></li>
											</ul>
										</li>
										
											<li>
												<span class="opener" href="#uni8">Unidade VIII - Regressão</span>
												<ul>
													<li><a href="#uni8-1">8.1 Métricas de Avaliação</a></li>
													<li><a href="#uni8-2">8.2 Tipos de Regressão</a></li>
													<li><a href="#uni8-3">8.3 <i>Notebook Colab</i></a></li>
												</ul>
											</li>
											<li>
												<span class="opener" href="#uni9">Unidade IX - Classificação</span>
												<ul>
													<li><a href="#uni9-1">9.1 Classificadores</a></li>
													<li><a href="#uni9-2">9.2 Avaliação de Classificadores</a></li>
													<li><a href="#uni9-3">9.3 Classificadores Modernos</a></li>
													<li><a href="#uni9-4">9.4 <i>Notebook Colab</i></a></li>
													
												</ul>
											</li>
											<li>
												<span class="opener" href="#uni10">Unidade X - Agrupamento</span>
												<ul>
													<li><a href="#uni10-1">10.1 K-Means</a></li>
													<li><a href="#uni10-2">10.2 DBSCAN</a></li>
													<li><a href="#uni10-3">10.3 Avaliação de Agrupamentos</a></li>
													<li><a href="#uni10-4">10.4 <i>Notebook Colab</i></a></li>
												</ul>
											</li>
										<li>
											<span class="opener" href="#uni11">Unidade XI - Redes Neurais</span>
											<ul>
												<li><a href="#uni11-1">11.1 Neurônio Artificial</a></li>
												<li><a href="#uni11-2">11.2 <i>Multi-Layer Perceptron</i></a></li>
												<li><a href="#uni11-3">11.3 <i>Deep Learning</i></a></li>
											</ul>
										</li>
									</li>
									<li>
									<span class="opener" href="#uni12">Unidade XII - Encerramento</span>
									<ul>
										<li><a href="#uni12-1">12.1 Considerações Finais</a></li>
										
									</ul></li>
								</li>
										<li><a href="#referencias">Referências</a></li>
										
									</ul>
								</nav>



						</div>
					</div>

			</div>
			<div vw class="enabled">
				<div vw-access-button class="active"></div>
				<div vw-plugin-wrapper>
				  <div class="vw-plugin-top-wrapper"></div>
				</div>
			</div>
		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>
			<script src="https://vlibras.gov.br/app/vlibras-plugin.js"></script>
			<script>
				new window.VLibras.Widget('https://vlibras.gov.br/app');
			</script>
			<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/highlight.min.js"></script>
												<script>hljs.highlightAll();</script>
	</body>
</html>